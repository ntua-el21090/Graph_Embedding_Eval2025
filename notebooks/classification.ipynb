{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FzyRjdu0fpw","executionInfo":{"status":"ok","timestamp":1769535315695,"user_tz":-120,"elapsed":63654,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}},"outputId":"ce6a86b4-8fe0-45fa-ddbe-63dc8fca164d","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu121.html\n","Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt22cu121)\n","Looking in links: https://data.pyg.org/whl/torch-2.2.0+cu121.html\n","Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt22cu121)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n","Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n","Requirement already satisfied: karateclub in /usr/local/lib/python3.12/dist-packages (1.3.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.12/dist-packages (from karateclub) (4.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from karateclub) (4.67.1)\n","Requirement already satisfied: python-louvain in /usr/local/lib/python3.12/dist-packages (from karateclub) (0.16)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from karateclub) (1.16.3)\n","Requirement already satisfied: pygsp in /usr/local/lib/python3.12/dist-packages (from karateclub) (0.6.1)\n","Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from karateclub) (4.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from karateclub) (1.17.0)\n","Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.12/dist-packages (from karateclub) (0.27.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim>=4.0.0->karateclub) (7.5.0)\n","Requirement already satisfied: Levenshtein==0.27.3 in /usr/local/lib/python3.12/dist-packages (from python-Levenshtein->karateclub) (0.27.3)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim>=4.0.0->karateclub) (2.0.1)\n","Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from Levenshtein==0.27.3->python-Levenshtein->karateclub) (3.14.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Looking in links: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.7.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.1)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n","Requirement already satisfied: karateclub in /usr/local/lib/python3.12/dist-packages (1.3.3)\n","Collecting numpy<1.23.0 (from karateclub)\n","  Using cached numpy-1.22.4.zip (11.5 MB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"]}],"source":["!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.0+cu121.html\n","!pip install torch-sparse  -f https://data.pyg.org/whl/torch-2.2.0+cu121.html\n","!pip install torch-geometric\n","\n","!pip install --use-deprecated=legacy-resolver karateclub networkx numpy pandas matplotlib scikit-learn\n","\n","!pip install torch torchvision torchaudio\n","!pip install torch-geometric \\\n","    -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__)\").html\n","\n","\n","!pip install optuna\n","!pip install karateclub"]},{"cell_type":"code","source":["# get statistics\n","\n","import numpy as np\n","import torch\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.utils import is_undirected\n","\n","def dataset_stats(name, root=\"/content/data\"):\n","    ds = TUDataset(root=root, name=name)\n","\n","    num_graphs = len(ds)\n","    num_classes = ds.num_classes\n","\n","    node_counts = []\n","    edge_counts_undirected = []\n","    edge_counts_raw = []\n","    undirected_flags = []\n","\n","    for g in ds:\n","        n = int(g.num_nodes) if g.num_nodes is not None else 0\n","        e = int(g.num_edges) if g.edge_index is not None else 0  # raw (directed) count in PyG\n","        node_counts.append(n)\n","        edge_counts_raw.append(e)\n","\n","        # Check undirected and convert to \"unique undirected edges\"\n","        if g.edge_index is not None and g.edge_index.numel() > 0:\n","            und = bool(is_undirected(g.edge_index))\n","        else:\n","            und = True\n","        undirected_flags.append(und)\n","\n","        # If undirected, PyG usually stores both directions => divide by 2\n","        e_und = e // 2 if und else e\n","        edge_counts_undirected.append(e_und)\n","\n","    stats = {\n","        \"Dataset\": name,\n","        \"#Graphs\": num_graphs,\n","        \"#Classes\": num_classes,\n","        \"Avg #Nodes\": float(np.mean(node_counts)),\n","        \"Avg #Edges (undirected)\": float(np.mean(edge_counts_undirected)),\n","        \"Pct undirected graphs\": 100.0 * float(np.mean(undirected_flags)),\n","    }\n","    return stats\n","\n","DATASETS = [\"MUTAG\", \"ENZYMES\", \"IMDB-MULTI\"]\n","all_stats = [dataset_stats(d) for d in DATASETS]\n","all_stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHVOpBfKYHG7","executionInfo":{"status":"ok","timestamp":1769535325386,"user_tz":-120,"elapsed":9687,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}},"outputId":"d3cb1d72-f1d2-4fb3-9553-c8a677fbf0fb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cuda.so\n","  import torch_geometric.typing\n","/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cuda.so\n","  import torch_geometric.typing\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'Dataset': 'MUTAG',\n","  '#Graphs': 188,\n","  '#Classes': 2,\n","  'Avg #Nodes': 17.930851063829788,\n","  'Avg #Edges (undirected)': 19.79255319148936,\n","  'Pct undirected graphs': 100.0},\n"," {'Dataset': 'ENZYMES',\n","  '#Graphs': 600,\n","  '#Classes': 6,\n","  'Avg #Nodes': 32.63333333333333,\n","  'Avg #Edges (undirected)': 62.13666666666666,\n","  'Pct undirected graphs': 100.0},\n"," {'Dataset': 'IMDB-MULTI',\n","  '#Graphs': 1500,\n","  '#Classes': 3,\n","  'Avg #Nodes': 13.001333333333333,\n","  'Avg #Edges (undirected)': 65.93533333333333,\n","  'Pct undirected graphs': 100.0}]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"luQxesBgfy04","executionInfo":{"status":"ok","timestamp":1769535329186,"user_tz":-120,"elapsed":3771,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["# Imports\n","import joblib\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear, Sequential, ReLU, BatchNorm1d\n","from torch_geometric.nn import GINConv, global_add_pool\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.loader import DataLoader\n","from sklearn.metrics import accuracy_score, f1_score\n","from torch_geometric.transforms import OneHotDegree\n","import optuna\n","import pandas as pd\n","import time, os, psutil\n","from sklearn.metrics import roc_auc_score\n","import numpy as np\n","from karateclub import NetLSD, Graph2Vec\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from torch_geometric.utils import to_networkx\n","import networkx as nx\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":1747,"status":"ok","timestamp":1769535330947,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"},"user_tz":-120},"id":"-KqwkGwOm_KI","outputId":"ed420b60-9101-4d97-ae6e-fcc112c0a676"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Connect to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","BASE_DIR = \"/content/drive/MyDrive/InformationSystems/Classification\"\n","RESULTS_DIR = f\"{BASE_DIR}/results\"\n","MODELS_DIR = f\"{BASE_DIR}/models\"\n","EMBEDDINGS_DIR = f\"{BASE_DIR}/embeddings\"\n","CLASSIF_RESULTS_DIR = f\"{BASE_DIR}/results/classification\"\n","\n","os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n","os.makedirs(RESULTS_DIR, exist_ok=True)\n","os.makedirs(MODELS_DIR, exist_ok=True)\n","os.makedirs(CLASSIF_RESULTS_DIR, exist_ok=True)\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","source":["def make_deterministic_perm(n: int, seed: int) -> np.ndarray:\n","    \"\"\"Deterministic permutation for dataset ordering (Fix A).\n","\n","    We use this permutation everywhere we need a stable, reproducible graph order\n","    so that saved embeddings/labels can be aligned later (e.g., in stability.py).\n","    \"\"\"\n","    return np.random.RandomState(seed).permutation(n)\n"],"metadata":{"id":"_yfcSwqWVL2B","executionInfo":{"status":"ok","timestamp":1769535330970,"user_tz":-120,"elapsed":20,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"k5NN7KKnpufI","executionInfo":{"status":"ok","timestamp":1769535330973,"user_tz":-120,"elapsed":1,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["def sanitize_embeddings(embeddings: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Replace NaN/Inf values in embeddings and ensure a clean float32 array.\n","    This is useful for karateclub embeddings that may occasionally produce\n","    unstable values on some graphs.\n","    \"\"\"\n","    emb = np.asarray(embeddings, dtype=np.float32)\n","    # Replace NaN and +/- Inf with 0.0\n","    emb = np.nan_to_num(emb, nan=0.0, posinf=0.0, neginf=0.0)\n","    return emb"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"BmVVRkY8pwlP","executionInfo":{"status":"ok","timestamp":1769535330979,"user_tz":-120,"elapsed":2,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["def filter_enzymes_graphs(graphs, labels, min_nodes: int = 3):\n","    \"\"\"\n","    Special handling for ENZYMES: remove very small graphs that can cause\n","    numerical issues for NetLSD / Graph2Vec.\n","    Returns filtered (graphs, labels) and prints how many were removed.\n","    \"\"\"\n","    if len(graphs) == 0:\n","        return graphs, labels\n","\n","    mask = [g.number_of_nodes() >= min_nodes for g in graphs]\n","    if not any(mask):\n","        print(\"WARNING: All ENZYMES graphs would be filtered out. Skipping filtering.\")\n","        return graphs, labels\n","\n","    filtered_graphs = [g for g, keep in zip(graphs, mask) if keep]\n","    if isinstance(labels, np.ndarray):\n","       filtered_labels = labels[np.array(mask)]\n","    else:\n","        filtered_labels = [y for y, keep in zip(labels, mask) if keep]\n","\n","    removed = len(graphs) - len(filtered_graphs)\n","    print(f\"ENZYMES filtering: removed {removed} graphs with < {min_nodes} nodes, kept {len(filtered_graphs)} graphs.\")\n","    return filtered_graphs, filtered_labels"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"boI0A_b4nfci","executionInfo":{"status":"ok","timestamp":1769535331001,"user_tz":-120,"elapsed":16,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["# GIN Model Definition\n","\n","class GIN(torch.nn.Module):\n","    def __init__(self, num_features, hidden_dim, num_classes, num_layers=5, dropout=0.5):\n","        super(GIN, self).__init__()\n","        layers = []\n","        in_dim = num_features\n","        for _ in range(num_layers):\n","            nn = Sequential(Linear(in_dim, hidden_dim), ReLU(), Linear(hidden_dim, hidden_dim))\n","            layers.append(GINConv(nn))\n","            in_dim = hidden_dim\n","        self.convs = torch.nn.ModuleList(layers)\n","        self.bns = torch.nn.ModuleList([BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n","        self.fc1 = Linear(hidden_dim, hidden_dim)\n","        self.fc2 = Linear(hidden_dim, num_classes)\n","        self.dropout = dropout\n","\n","    def forward(self, x, edge_index, batch):\n","        for conv, bn in zip(self.convs, self.bns):\n","            x = F.relu(conv(x, edge_index))\n","            x = bn(x)\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tHDMvRdhnjQm","executionInfo":{"status":"ok","timestamp":1769535331016,"user_tz":-120,"elapsed":8,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["# Training\n","\n","def train(model, loader, optimizer, criterion):\n","    model.train()\n","    total_loss = 0\n","    for data in loader:\n","        data = data.to(DEVICE)\n","        optimizer.zero_grad()\n","        out = model(data.x, data.edge_index, data.batch)\n","        loss = criterion(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","# Evaluation\n","\n","def evaluate(model, loader, criterion):\n","    model.eval()\n","    preds, labels, probs = [], [], []\n","    total_loss = 0.0\n","    num_batches = 0\n","\n","    with torch.no_grad():\n","        for data in loader:\n","            data = data.to(DEVICE)\n","            out = model(data.x, data.edge_index, data.batch)\n","\n","            loss = criterion(out, data.y)\n","            total_loss += loss.item()\n","            num_batches += 1\n","\n","            pred = out.argmax(dim=1)\n","            preds.extend(pred.cpu().numpy())\n","            labels.extend(data.y.cpu().numpy())\n","            probs.extend(F.softmax(out, dim=1).cpu().numpy())  # probabilities for AUC\n","\n","    acc = accuracy_score(labels, preds)\n","    f1 = f1_score(labels, preds, average='weighted')\n","    avg_loss = total_loss / max(1, num_batches)\n","\n","    try:\n","        if len(np.unique(labels)) == 2:\n","            auc = roc_auc_score(labels, np.array(probs)[:, 1])\n","        else:\n","            auc = roc_auc_score(labels, probs, multi_class='ovr')\n","    except ValueError:\n","        auc = np.nan  # if there are not enough samples for AUC\n","\n","    return acc, f1, auc, avg_loss"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NVzRwAdC4P2n","executionInfo":{"status":"ok","timestamp":1769535331078,"user_tz":-120,"elapsed":55,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["def get_gin_embeddings(model, loader):\n","    \"\"\"Return graph-level embeddings (after global_add_pool) and labels.\"\"\"\n","    model.eval()\n","    all_emb = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for data in loader:\n","            data = data.to(DEVICE)\n","            x, edge_index, batch = data.x, data.edge_index, data.batch\n","            # forward μέχρι το pooling\n","            for conv, bn in zip(model.convs, model.bns):\n","                x = F.relu(conv(x, edge_index))\n","                x = bn(x)\n","            x = global_add_pool(x, batch)\n","            all_emb.append(x.cpu().numpy())\n","            all_labels.extend(data.y.cpu().numpy())\n","    embeddings = np.concatenate(all_emb, axis=0)\n","    labels = np.array(all_labels)\n","    return embeddings, labels"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"N7nB1kWECeeA","executionInfo":{"status":"ok","timestamp":1769535331094,"user_tz":-120,"elapsed":15,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["def run_gin_pipeline(\n","    dataset_name,\n","    seed,\n","    use_optuna,\n","    w_acc,\n","    w_f1,\n","    w_auc,\n","    hidden_dim,\n","    epochs,\n","    batch_size=32,\n","    n_trials=15,\n","):\n","\n","    # Experiment ID (used in logs and embeddings path)\n","    experiment_id = str(seed)\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","\n","    # Load dataset (Fix A: deterministic order, no implicit shuffle)\n","    dataset_raw = TUDataset(root='data/TUDataset', name=dataset_name)\n","    perm = make_deterministic_perm(len(dataset_raw), seed)\n","    dataset = dataset_raw[perm.tolist()]\n","\n","    # If no node features use one-hot degree features\n","    if dataset.num_features == 0 or dataset[0].x is None:\n","        print(\"Dataset has no node features. Applying OneHotDegree transform...\")\n","\n","        # Find maximum degree across all graphs\n","        max_degree = 0\n","        for data in dataset:\n","            deg = torch.bincount(data.edge_index[0], minlength=data.num_nodes)\n","            max_degree = max(max_degree, int(deg.max()))\n","\n","        # Apply transform\n","        oh_transform = OneHotDegree(max_degree=max_degree)\n","        dataset_raw = TUDataset(\n","            root='data/TUDataset',\n","            name=dataset_name,\n","            transform=oh_transform\n","        )\n","\n","        # Apply the SAME deterministic permutation so order matches the non-feature case\n","        perm = make_deterministic_perm(len(dataset_raw), seed)\n","        dataset = dataset_raw[perm.tolist()]\n","\n","        num_node_features = max_degree + 1\n","    else:\n","        num_node_features = dataset.num_features\n","\n","    # Train/test split\n","    train_dataset = dataset[:int(0.8 * len(dataset))]\n","    test_dataset = dataset[int(0.8 * len(dataset)):]\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","    print(f\"Loaded dataset {dataset_name}: {len(dataset)} graphs, {num_node_features} node features, {dataset.num_classes} classes\")\n","\n","    def objective(trial):\n","        num_layers = trial.suggest_int(\"num_layers\", 3, 6)\n","        dropout = trial.suggest_float(\"dropout\", 0.0, 0.6)\n","        lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n","        weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n","\n","        model = GIN(num_node_features, hidden_dim, dataset.num_classes, num_layers, dropout).to(DEVICE)\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","        criterion = torch.nn.CrossEntropyLoss()\n","\n","        for epoch in range(5):  # fewer epochs for fast tuning\n","            train(model, train_loader, optimizer, criterion)\n","\n","        acc, f1, auc, _ = evaluate(model, test_loader, criterion)\n","        score = (w_acc * acc) + (w_f1 * f1) + (w_auc * (0 if np.isnan(auc) else auc))\n","        return score\n","\n","    start_generation = time.time()\n","    if use_optuna:\n","        print(\"Running Optuna for hyperparameter tuning...\")\n","        study = optuna.create_study(direction=\"maximize\")\n","        study.optimize(objective, n_trials=n_trials)\n","        best_params = study.best_params\n","        print(f\"Best hyperparameters: {best_params}\")\n","    else:\n","      best_params = { \"num_layers\": 5, \"dropout\": 0.5, \"lr\": 0.001, \"weight_decay\": 1e-4}\n","      print(f\"Using default hyperparameters: {best_params}\")\n","\n","    generation_time = time.time() - start_generation\n","\n","    # Final Training with best parameters\n","\n","    print(\"\\nRunning final training GIN...\")\n","    print(best_params)\n","\n","    model = GIN(num_node_features, hidden_dim, dataset.num_classes,\n","                num_layers=best_params[\"num_layers\"], dropout=best_params[\"dropout\"]).to(DEVICE)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_params[\"lr\"], weight_decay=best_params[\"weight_decay\"])\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","    history = []\n","    start_time = time.time()\n","    eval_acc, eval_f1, eval_auc, eval_loss, eval_epoch = 0, 0, 0, 1e9, 0\n","    best_loss_for_best_epoch = 1e9\n","    for epoch in range(1, epochs + 1):\n","        loss = train(model, train_loader, optimizer, criterion)\n","        acc, f1, auc, e_loss = evaluate(model, test_loader, criterion)\n","        if acc > eval_acc:\n","          #edo mipos to allakso na einai kai edo sindiasmos me weights poy eixe kai sto optuna\n","          eval_acc, eval_f1, eval_auc, eval_loss, eval_epoch = acc, f1, auc, e_loss, epoch\n","          best_loss_for_best_epoch = e_loss\n","\n","        elapsed = time.time() - start_time\n","        print(f\"Epoch {epoch:03d} | Loss={loss:.4f} | TestAcc={acc:.3f} | F1={f1:.3f} | AUC={auc:.3f} | Time={elapsed:.2f}s\")\n","        history.append([epoch, loss, acc, f1, auc, elapsed])\n","\n","    training_time = time.time() - start_time\n","    process = psutil.Process(os.getpid())\n","    memory_usage = process.memory_info().rss / (1024 ** 2)  # in MB\n","\n","\n","    # Save GIN embeddings for the whole dataset\n","\n","    full_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","    gin_embeddings, gin_labels = get_gin_embeddings(model, full_loader)\n","\n","    gin_exp_dir = os.path.join(EMBEDDINGS_DIR, \"GIN\", dataset_name, experiment_id)\n","    os.makedirs(gin_exp_dir, exist_ok=True)\n","    np.save(os.path.join(gin_exp_dir, \"embeddings.npy\"), gin_embeddings)\n","    np.save(os.path.join(gin_exp_dir, \"labels.npy\"), gin_labels)\n","    # Fix: persist the exact graph order used to produce embeddings/labels\n","    np.save(os.path.join(gin_exp_dir, \"order.npy\"), perm)\n","\n","    # Log file save\n","\n","    summary_path = f\"{CLASSIF_RESULTS_DIR}/gin.csv\"\n","    os.makedirs(\"results\", exist_ok=True)\n","\n","\n","    summary_data = {\n","        \"method\": \"GIN\",\n","        \"seed\": seed,\n","        \"dataset\": dataset_name,\n","        \"optimization_enabled\": \"yes\" if use_optuna else \"no\",\n","        \"embedding_dimension\": hidden_dim,\n","        \"objective_weights\": f\"({w_acc},{w_f1},{w_auc})\",\n","        \"num_layers\": best_params[\"num_layers\"],\n","        \"dropout\": best_params[\"dropout\"],\n","        \"lr\": best_params[\"lr\"],\n","        \"weight_decay\": best_params[\"weight_decay\"],\n","        \"epochs\": epochs,\n","        \"best_epoch\": eval_epoch,\n","        \"best_loss\": round(float(best_loss_for_best_epoch), 4),\n","        \"eval_loss\": round(float(eval_loss), 4),\n","        \"eval_acc\": round(eval_acc, 4),\n","        \"eval_f1\": round(eval_f1, 4),\n","        \"eval_auc\": round(eval_auc, 4),\n","        \"training_time (s)\": round(training_time, 2),\n","        \"generation_time (s)\": round(generation_time, 2),\n","        \"memory_usage (MB)\": round(memory_usage, 2)\n","    }\n","\n","    df = pd.DataFrame([summary_data])\n","\n","    # Append mode (keep all trainings)\n","    if os.path.exists(summary_path):\n","        df.to_csv(summary_path, mode='a', index=False, header=False)\n","    else:\n","        df.to_csv(summary_path, index=False)\n","\n","    print(f\"\\nTraining summary stored in : {summary_path}\")\n","    print(df)\n","\n","    # Save best model (weights + metadata)\n","    gin_ckpt = {\n","        \"state_dict\": model.state_dict(),\n","        \"num_node_features\": num_node_features,\n","        \"hidden_dim\": hidden_dim,\n","        \"num_classes\": dataset.num_classes,\n","        \"num_layers\": best_params[\"num_layers\"],\n","        \"dropout\": best_params[\"dropout\"],\n","    }\n","    torch.save(gin_ckpt, f\"{MODELS_DIR}/GIN_{dataset_name}_{experiment_id}.pth\")\n","    print(f\"Saved model: {MODELS_DIR}/GIN_{dataset_name}_{experiment_id}.pth\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"vrpvs2N3qJHQ","executionInfo":{"status":"ok","timestamp":1769535331163,"user_tz":-120,"elapsed":55,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["def run_graph2vec_pipeline(\n","    dataset_name,\n","    seed,\n","    w_acc=0.5,\n","    w_f1=0.3,\n","    w_auc=0.2,\n","    embedding_dim=128,\n","    epochs=50,\n","    test_size=0.2,\n","    use_optuna=True,\n","    n_trials=20,\n","):\n","    \"\"\"\n","    Pipeline for graph classification using Graph2Vec embeddings + SVM,\n","    with optional Optuna-based hyperparameter tuning and special handling\n","    for ENZYMES + embedding sanitization.\n","    \"\"\"\n","    # Experiment ID\n","    experiment_id = str(seed)\n","    np.random.seed(seed)\n","\n","    # Load dataset\n","    # Fix : deterministic dataset order\n","    dataset_raw = TUDataset(root='data/TUDataset', name=dataset_name)\n","    perm = make_deterministic_perm(len(dataset_raw), seed)\n","    dataset = dataset_raw[perm.tolist()]\n","    print(f\"Loaded dataset {dataset_name} for Graph2Vec: {len(dataset)} graphs, {dataset.num_classes} classes\")\n","\n","    # ds_indices[k] is the index in the original (unshuffled) dataset for dataset[k]\n","    ds_indices = perm.copy()\n","\n","\n","    # Convert PyG graphs to NetworkX graphs\n","    graphs = []\n","    labels = []\n","    for data in dataset:\n","        g = to_networkx(data, to_undirected=True)\n","        graphs.append(g)\n","        labels.append(int(data.y.item()))\n","\n","    labels = np.array(labels)\n","    # Positions in the *current* graphs list (used for splitting)\n","    pos = np.arange(len(labels))\n","\n","    # Special handling for ENZYMES (filter very small graphs)\n","    if dataset_name.upper() == \"ENZYMES\":\n","        # Keep original dataset indices aligned with graphs/labels after filtering\n","        mask = np.array([g.number_of_nodes() >= 3 for g in graphs], dtype=bool)\n","        graphs = [g for g, keep in zip(graphs, mask) if keep]\n","        labels = labels[mask]\n","        ds_indices = ds_indices[mask]\n","        pos = np.arange(len(labels))\n","        removed = int(np.sum(~mask))\n","        print(f\"ENZYMES filtering: removed {removed} graphs with < 3 nodes, kept {len(graphs)} graphs.\")\n","\n","    # Outer train/test split on graphs\n","    train_pos, test_pos, y_train, y_test = train_test_split(\n","        pos,\n","        labels,\n","        test_size=test_size,\n","        random_state=seed,\n","        stratify=labels,\n","    )\n","    train_graphs = [graphs[i] for i in train_pos]\n","    test_graphs = [graphs[i] for i in test_pos]\n","\n","    opt_time = 0.0\n","\n","    def objective(trial):\n","        # Hyperparameters for the SVM classifier\n","        C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n","        gamma = trial.suggest_loguniform(\"gamma\", 1e-4, 1e1)\n","\n","        # Inner train/validation split on graphs\n","        inner_tr_idx, inner_val_idx, y_tr, y_val = train_test_split(\n","            np.arange(len(train_graphs)),\n","            y_train,\n","            test_size=0.2,\n","            random_state=seed,\n","            stratify=y_train,\n","        )\n","\n","        inner_tr_graphs = [train_graphs[i] for i in inner_tr_idx]\n","        inner_val_graphs = [train_graphs[i] for i in inner_val_idx]\n","\n","\n","        all_graphs = inner_tr_graphs + inner_val_graphs\n","\n","        # Fit Graph2Vec on all (transductive setting) and slice embeddings\n","        g2v = Graph2Vec(dimensions=embedding_dim, wl_iterations=2, epochs=epochs, workers=os.cpu_count())\n","        g2v.fit(all_graphs)\n","        emb_all = sanitize_embeddings(g2v.get_embedding())\n","\n","        X_tr = emb_all[:len(inner_tr_graphs)]\n","        X_val = emb_all[len(inner_tr_graphs):]\n","\n","        clf = SVC(kernel=\"rbf\", probability=True, C=C, gamma=gamma, random_state=seed)\n","        clf.fit(X_tr, y_tr)\n","        y_pred = clf.predict(X_val)\n","        y_prob = clf.predict_proba(X_val)\n","\n","        acc = accuracy_score(y_val, y_pred)\n","        f1 = f1_score(y_val, y_pred, average=\"weighted\")\n","        try:\n","            if len(np.unique(y_val)) == 2:\n","                auc = roc_auc_score(y_val, y_prob[:, 1])\n","            else:\n","                auc = roc_auc_score(y_val, y_prob, multi_class=\"ovr\")\n","        except ValueError:\n","            auc = np.nan\n","\n","        score = (w_acc * acc) + (w_f1 * f1) + (w_auc * (0 if np.isnan(auc) else auc))\n","        return score\n","\n","    if use_optuna:\n","        print(\"Running Optuna for Graph2Vec+SVM hyperparameter tuning...\")\n","        start_opt = time.time()\n","        study = optuna.create_study(direction=\"maximize\")\n","        study.optimize(objective, n_trials=n_trials)\n","        best_params = study.best_params\n","        opt_time = time.time() - start_opt\n","        print(f\"Best hyperparameters (Graph2Vec+SVM): {best_params}\")\n","    else:\n","        best_params = {\"C\": 1.0, \"gamma\": \"scale\"}\n","        print(f\"Using default SVM hyperparameters: {best_params}\")\n","\n","    # Final embedding + training using best hyperparameters\n","    print(\"Running final Graph2Vec embedding on train+test graphs...\")\n","    all_graphs_final = train_graphs + test_graphs\n","    order_pos = np.concatenate([train_pos, test_pos])\n","    start_embed = time.time()\n","    g2v = Graph2Vec(dimensions=embedding_dim, wl_iterations=2, epochs=epochs, workers=os.cpu_count())\n","    g2v.fit(all_graphs_final)\n","    emb_all = sanitize_embeddings(g2v.get_embedding())\n","    embed_time = time.time() - start_embed\n","\n","    X_train = emb_all[:len(train_graphs)]\n","    X_test = emb_all[len(train_graphs):]\n","\n","    print(\"Training final SVM on Graph2Vec embeddings...\")\n","    start_train = time.time()\n","    clf = SVC(kernel=\"rbf\", probability=True, C=best_params[\"C\"], gamma=best_params[\"gamma\"], random_state=seed)\n","    clf.fit(X_train, y_train)\n","    train_time = time.time() - start_train\n","\n","    # Evaluation on held-out test graphs\n","    y_pred = clf.predict(X_test)\n","    y_prob = clf.predict_proba(X_test)\n","\n","    acc = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n","    try:\n","        if len(np.unique(y_test)) == 2:\n","            auc = roc_auc_score(y_test, y_prob[:, 1])\n","        else:\n","            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\")\n","    except ValueError:\n","        auc = np.nan\n","\n","    score = (w_acc * acc) + (w_f1 * f1) + (w_auc * (0 if np.isnan(auc) else auc))\n","\n","\n","    # Save Graph2Vec embeddings (for all graphs) + labels\n","\n","    g2v_exp_dir = os.path.join(EMBEDDINGS_DIR, \"Graph2Vec\", dataset_name, experiment_id)\n","    os.makedirs(g2v_exp_dir, exist_ok=True)\n","    np.save(os.path.join(g2v_exp_dir, \"embeddings.npy\"), emb_all)\n","    # Save labels in the SAME order as embeddings (train_pos + test_pos)\n","    np.save(os.path.join(g2v_exp_dir, \"labels.npy\"), labels[order_pos])\n","    # Fix: persist ORIGINAL dataset indices (so stability can rebuild graphs correctly)\n","    np.save(os.path.join(g2v_exp_dir, \"order.npy\"), ds_indices[order_pos])\n","\n","    # Save fitted Graph2Vec model\n","    g2v_model_path = f\"{MODELS_DIR}/Graph2Vec_{dataset_name}_{experiment_id}.joblib\"\n","    joblib.dump(g2v, g2v_model_path)\n","\n","    # Save trained SVM classifier\n","    svm_model_path = f\"{MODELS_DIR}/Graph2Vec_SVM_{dataset_name}_{experiment_id}.joblib\"\n","    joblib.dump(clf, svm_model_path)\n","\n","\n","    process = psutil.Process(os.getpid())\n","    memory_usage = process.memory_info().rss / (1024 ** 2)  # in MB\n","\n","    print(f\"Graph2Vec Results on {dataset_name} -> Acc: {acc:.3f}, F1: {f1:.3f}, AUC: {auc:.3f}, Score: {score:.3f}\")\n","    print(f\"Embedding time: {embed_time:.2f}s | SVM training time: {train_time:.2f}s | Optuna time: {opt_time:.2f}s | Memory usage: {memory_usage:.2f} MB\")\n","\n","    # Log summary to CSV\n","    summary_path = f\"{CLASSIF_RESULTS_DIR}/g2v.csv\"\n","\n","    summary_data = {\n","        \"method\": \"Graph2Vec\",\n","        \"seed\": seed,\n","        \"dataset\": dataset_name,\n","        \"embedding_dimension\": embedding_dim,\n","        \"optuna_enabled\": \"yes\" if use_optuna else \"no\",\n","        \"C\": best_params[\"C\"],\n","        \"gamma\": best_params[\"gamma\"],\n","        \"acc\": round(float(acc), 4),\n","        \"f1\": round(float(f1), 4),\n","        \"auc\": round(float(auc) if not np.isnan(auc) else -1, 4),\n","        \"score\": round(float(score), 4),\n","        \"embedding_time (s)\": round(embed_time, 2),\n","        \"svm_training_time (s)\": round(train_time, 2),\n","        \"optuna_time (s)\": round(opt_time, 2),\n","        \"memory_usage (MB)\": round(memory_usage, 2),\n","    }\n","\n","    df = pd.DataFrame([summary_data])\n","    if os.path.exists(summary_path):\n","        df.to_csv(summary_path, mode='a', index=False, header=False)\n","    else:\n","        df.to_csv(summary_path, index=False)\n","\n","    print(f\"Graph2Vec summary stored in: {summary_path}\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"GCpM6Q5cqOwL","executionInfo":{"status":"ok","timestamp":1769535331414,"user_tz":-120,"elapsed":249,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"}}},"outputs":[],"source":["def run_netlsd_pipeline(\n","    dataset_name,\n","    seed,\n","    w_acc=0.5,\n","    w_f1=0.3,\n","    w_auc=0.2,\n","    test_size=0.2,\n","    use_optuna=True,\n","    n_trials=20,\n","):\n","    \"\"\"\n","    Pipeline for graph classification using NetLSD embeddings + SVM,\n","    with optional Optuna-based hyperparameter tuning and ENZYMES filtering.\n","    \"\"\"\n","    # Experiment ID\n","    experiment_id = str(seed)\n","    np.random.seed(seed)\n","    # Fix: deterministic dataset order\n","    dataset_raw = TUDataset(root='data/TUDataset', name=dataset_name)\n","    perm = make_deterministic_perm(len(dataset_raw), seed)\n","    dataset = dataset_raw[perm.tolist()]\n","    print(f\"Loaded dataset {dataset_name} for NetLSD: {len(dataset)} graphs, {dataset.num_classes} classes\")\n","\n","    # ds_indices[k] is the index in the original (unshuffled) dataset for dataset[k]\n","    ds_indices = perm.copy()\n","\n","    # Convert PyG graphs to NetworkX graphs\n","    graphs = []\n","    labels = []\n","    for data in dataset:\n","        g = to_networkx(data, to_undirected=True)\n","        graphs.append(g)\n","        labels.append(int(data.y.item()))\n","\n","    labels = np.array(labels)\n","    pos = np.arange(len(labels))\n","\n","    # Special handling for ENZYMES\n","    if dataset_name.upper() == \"ENZYMES\":\n","        # Keep original dataset indices aligned with graphs/labels after filtering\n","        mask = np.array([g.number_of_nodes() >= 3 for g in graphs], dtype=bool)\n","        graphs = [g for g, keep in zip(graphs, mask) if keep]\n","        labels = labels[mask]\n","        ds_indices = ds_indices[mask]\n","        pos = np.arange(len(labels))\n","        removed = int(np.sum(~mask))\n","        print(f\"ENZYMES filtering: removed {removed} graphs with < 3 nodes, kept {len(graphs)} graphs.\")\n","\n","    # Outer train/test split on graphs\n","    train_pos, test_pos, y_train, y_test = train_test_split(\n","        pos,\n","        labels,\n","        test_size=test_size,\n","        random_state=seed,\n","        stratify=labels,\n","    )\n","    train_graphs = [graphs[i] for i in train_pos]\n","    test_graphs = [graphs[i] for i in test_pos]\n","\n","    opt_time = 0.0\n","\n","    def objective(trial):\n","        # Hyperparameters for the SVM classifier\n","        C = trial.suggest_loguniform(\"C\", 1e-2, 1e2)\n","        gamma = trial.suggest_loguniform(\"gamma\", 1e-4, 1e1)\n","\n","        # Inner train/validation split on graphs\n","        inner_tr_idx, inner_val_idx, y_tr, y_val = train_test_split(\n","            np.arange(len(train_graphs)),\n","            y_train,\n","            test_size=0.2,\n","            random_state=seed,\n","            stratify=y_train,\n","        )\n","\n","        inner_tr_graphs = [train_graphs[i] for i in inner_tr_idx]\n","        inner_val_graphs = [train_graphs[i] for i in inner_val_idx]\n","\n","\n","        all_graphs = inner_tr_graphs + inner_val_graphs\n","\n","        # Fit NetLSD on all and slice embeddings\n","        netlsd = NetLSD()\n","        netlsd.fit(all_graphs)\n","        emb_all = sanitize_embeddings(netlsd.get_embedding())\n","\n","        X_tr = emb_all[:len(inner_tr_graphs)]\n","        X_val = emb_all[len(inner_tr_graphs):]\n","\n","        clf = SVC(kernel=\"rbf\", probability=True, C=C, gamma=gamma, random_state=seed)\n","        clf.fit(X_tr, y_tr)\n","        y_pred = clf.predict(X_val)\n","        y_prob = clf.predict_proba(X_val)\n","\n","        acc = accuracy_score(y_val, y_pred)\n","        f1 = f1_score(y_val, y_pred, average=\"weighted\")\n","        try:\n","            if len(np.unique(y_val)) == 2:\n","                auc = roc_auc_score(y_val, y_prob[:, 1])\n","            else:\n","                auc = roc_auc_score(y_val, y_prob, multi_class=\"ovr\")\n","        except ValueError:\n","            auc = np.nan\n","\n","        score = (w_acc * acc) + (w_f1 * f1) + (w_auc * (0 if np.isnan(auc) else auc))\n","        return score\n","\n","    if use_optuna:\n","        print(\"Running Optuna for NetLSD+SVM hyperparameter tuning...\")\n","        start_opt = time.time()\n","        study = optuna.create_study(direction=\"maximize\")\n","        study.optimize(objective, n_trials=n_trials)\n","        best_params = study.best_params\n","        opt_time = time.time() - start_opt\n","        print(f\"Best hyperparameters (NetLSD+SVM): {best_params}\")\n","    else:\n","        best_params = {\"C\": 1.0, \"gamma\": \"scale\"}\n","        print(f\"Using default SVM hyperparameters: {best_params}\")\n","\n","    # Final embedding + training using best hyperparameters\n","    print(\"Running final NetLSD embedding on train+test graphs...\")\n","    all_graphs_final = train_graphs + test_graphs\n","    order_pos = np.concatenate([train_pos, test_pos])\n","    start_embed = time.time()\n","    netlsd = NetLSD()\n","    netlsd.fit(all_graphs_final)\n","    emb_all = sanitize_embeddings(netlsd.get_embedding())\n","    embed_time = time.time() - start_embed\n","\n","    X_train = emb_all[:len(train_graphs)]\n","    X_test = emb_all[len(train_graphs):]\n","\n","    print(\"Training final SVM on NetLSD embeddings...\")\n","    start_train = time.time()\n","    clf = SVC(kernel=\"rbf\", probability=True, C=best_params[\"C\"], gamma=best_params[\"gamma\"], random_state=seed)\n","    clf.fit(X_train, y_train)\n","    train_time = time.time() - start_train\n","\n","    # Evaluation on held-out test graphs\n","    y_pred = clf.predict(X_test)\n","    y_prob = clf.predict_proba(X_test)\n","\n","    acc = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n","    try:\n","        if len(np.unique(y_test)) == 2:\n","            auc = roc_auc_score(y_test, y_prob[:, 1])\n","        else:\n","            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\")\n","    except ValueError:\n","        auc = np.nan\n","\n","    score = (w_acc * acc) + (w_f1 * f1) + (w_auc * (0 if np.isnan(auc) else auc))\n","\n","\n","    # Save NetLSD embeddings (all graphs) + labels\n","\n","    netlsd_exp_dir = os.path.join(EMBEDDINGS_DIR, \"NetLSD\",dataset_name, experiment_id)\n","    os.makedirs(netlsd_exp_dir, exist_ok=True)\n","    np.save(os.path.join(netlsd_exp_dir, \"embeddings.npy\"), emb_all)\n","    # Save labels in the SAME order as embeddings (train_pos + test_pos)\n","    np.save(os.path.join(netlsd_exp_dir, \"labels.npy\"), labels[order_pos])\n","    # Fix: persist ORIGINAL dataset indices (so stability can rebuild graphs correctly)\n","    np.save(os.path.join(netlsd_exp_dir, \"order.npy\"), ds_indices[order_pos])\n","\n","    # Save fitted NetLSD model\n","    netlsd_model_path = f\"{MODELS_DIR}/NetLSD_{dataset_name}_{experiment_id}.joblib\"\n","    joblib.dump(netlsd, netlsd_model_path)\n","\n","    # Save trained SVM classifier\n","    svm_model_path = f\"{MODELS_DIR}/NetLSD_SVM_{dataset_name}_{experiment_id}.joblib\"\n","    joblib.dump(clf, svm_model_path)\n","\n","\n","    process = psutil.Process(os.getpid())\n","    memory_usage = process.memory_info().rss / (1024 ** 2)  # in MB\n","\n","    print(f\"NetLSD Results on {dataset_name} -> Acc: {acc:.3f}, F1: {f1:.3f}, AUC: {auc:.3f}, Score: {score:.3f}\")\n","    print(f\"Embedding time: {embed_time:.2f}s | SVM training time: {train_time:.2f}s | Optuna time: {opt_time:.2f}s | Memory usage: {memory_usage:.2f} MB\")\n","\n","    # Log summary to CSV\n","    summary_path = f\"{CLASSIF_RESULTS_DIR}/netlsd.csv\"\n","\n","    summary_data = {\n","        \"method\": \"NetLSD\",\n","        \"seed\": seed,\n","        \"optuna_enabled\": \"yes\" if use_optuna else \"no\",\n","        \"C\": best_params[\"C\"],\n","        \"gamma\": best_params[\"gamma\"],\n","        \"acc\": round(float(acc), 4),\n","        \"f1\": round(float(f1), 4),\n","        \"auc\": round(float(auc) if not np.isnan(auc) else -1, 4),\n","        \"score\": round(float(score), 4),\n","        \"embedding_time (s)\": round(embed_time, 2),\n","        \"svm_training_time (s)\": round(train_time, 2),\n","        \"optuna_time (s)\": round(opt_time, 2),\n","        \"memory_usage (MB)\": round(memory_usage, 2),\n","    }\n","\n","    df = pd.DataFrame([summary_data])\n","    if os.path.exists(summary_path):\n","        df.to_csv(summary_path, mode='a', index=False, header=False)\n","    else:\n","        df.to_csv(summary_path, index=False)\n","\n","    print(f\"NetLSD summary stored in: {summary_path}\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":455488,"status":"ok","timestamp":1769535786904,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"},"user_tz":-120},"id":"b5dGElCoqdAr","outputId":"43f15577-9591-4f02-c91c-633cbeff6ef3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset has no node features. Applying OneHotDegree transform...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:35:32,568] A new study created in memory with name: no-name-8916767e-3b86-4f14-b1ca-cd4d2b0ed20f\n"]},{"output_type":"stream","name":"stdout","text":["Loaded dataset IMDB-MULTI: 1500 graphs, 89 node features, 3 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:35:39,782] Trial 0 finished with value: 0.44587087521311447 and parameters: {'num_layers': 4, 'dropout': 0.1789115145273103, 'lr': 0.0003149013649881986, 'weight_decay': 8.035259098640091e-05}. Best is trial 0 with value: 0.44587087521311447.\n","[I 2026-01-27 17:35:44,512] Trial 1 finished with value: 0.4909933557499653 and parameters: {'num_layers': 3, 'dropout': 0.410648645730567, 'lr': 0.0003144417340315641, 'weight_decay': 4.316958953756027e-05}. Best is trial 1 with value: 0.4909933557499653.\n","[I 2026-01-27 17:35:49,423] Trial 2 finished with value: 0.5029612026679156 and parameters: {'num_layers': 3, 'dropout': 0.594114263810321, 'lr': 0.0021316908204075885, 'weight_decay': 3.663522497433119e-05}. Best is trial 2 with value: 0.5029612026679156.\n","[I 2026-01-27 17:35:53,164] Trial 3 finished with value: 0.4055543721413451 and parameters: {'num_layers': 4, 'dropout': 0.168177813512488, 'lr': 0.00017266278603552933, 'weight_decay': 0.0001980061603105917}. Best is trial 2 with value: 0.5029612026679156.\n","[I 2026-01-27 17:35:54,905] Trial 4 finished with value: 0.45780343959039804 and parameters: {'num_layers': 3, 'dropout': 0.49882544267556245, 'lr': 0.000269336402541815, 'weight_decay': 6.655632307232468e-06}. Best is trial 2 with value: 0.5029612026679156.\n","[I 2026-01-27 17:35:57,234] Trial 5 finished with value: 0.3909650345360279 and parameters: {'num_layers': 5, 'dropout': 0.5860006190409123, 'lr': 0.0007556692569961677, 'weight_decay': 8.502655283277578e-06}. Best is trial 2 with value: 0.5029612026679156.\n","[I 2026-01-27 17:35:58,967] Trial 6 finished with value: 0.4847052949600578 and parameters: {'num_layers': 3, 'dropout': 0.23204752142965865, 'lr': 0.0004077743255324274, 'weight_decay': 2.3243351449458112e-05}. Best is trial 2 with value: 0.5029612026679156.\n","[I 2026-01-27 17:36:00,691] Trial 7 finished with value: 0.48156809740231565 and parameters: {'num_layers': 3, 'dropout': 0.425807229924742, 'lr': 0.0002811713294492289, 'weight_decay': 3.524867226933009e-05}. Best is trial 2 with value: 0.5029612026679156.\n","[I 2026-01-27 17:36:03,391] Trial 8 finished with value: 0.4497054049834437 and parameters: {'num_layers': 5, 'dropout': 0.17838722213419356, 'lr': 0.0008037123408153158, 'weight_decay': 3.569385931930181e-05}. Best is trial 2 with value: 0.5029612026679156.\n","[I 2026-01-27 17:36:05,616] Trial 9 finished with value: 0.3982260243686493 and parameters: {'num_layers': 4, 'dropout': 0.12545838498375017, 'lr': 0.0006863480261728928, 'weight_decay': 3.886803463721494e-05}. Best is trial 2 with value: 0.5029612026679156.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 3, 'dropout': 0.594114263810321, 'lr': 0.0021316908204075885, 'weight_decay': 3.663522497433119e-05}\n","\n","Running final training GIN...\n","{'num_layers': 3, 'dropout': 0.594114263810321, 'lr': 0.0021316908204075885, 'weight_decay': 3.663522497433119e-05}\n","Epoch 001 | Loss=2.3996 | TestAcc=0.477 | F1=0.477 | AUC=0.651 | Time=0.35s\n","Epoch 002 | Loss=1.7556 | TestAcc=0.400 | F1=0.348 | AUC=0.611 | Time=0.70s\n","Epoch 003 | Loss=1.4624 | TestAcc=0.420 | F1=0.387 | AUC=0.606 | Time=1.05s\n","Epoch 004 | Loss=1.2173 | TestAcc=0.467 | F1=0.433 | AUC=0.661 | Time=1.40s\n","Epoch 005 | Loss=1.0912 | TestAcc=0.470 | F1=0.461 | AUC=0.654 | Time=1.77s\n","Epoch 006 | Loss=1.0943 | TestAcc=0.460 | F1=0.428 | AUC=0.653 | Time=2.12s\n","Epoch 007 | Loss=1.0525 | TestAcc=0.467 | F1=0.426 | AUC=0.680 | Time=2.46s\n","Epoch 008 | Loss=1.0355 | TestAcc=0.480 | F1=0.449 | AUC=0.671 | Time=2.82s\n","Epoch 009 | Loss=1.0368 | TestAcc=0.487 | F1=0.485 | AUC=0.666 | Time=3.17s\n","Epoch 010 | Loss=1.0314 | TestAcc=0.493 | F1=0.435 | AUC=0.663 | Time=3.52s\n","Epoch 011 | Loss=1.0236 | TestAcc=0.493 | F1=0.460 | AUC=0.673 | Time=3.89s\n","Epoch 012 | Loss=1.0445 | TestAcc=0.490 | F1=0.420 | AUC=0.673 | Time=4.24s\n","Epoch 013 | Loss=1.0075 | TestAcc=0.473 | F1=0.456 | AUC=0.671 | Time=4.58s\n","Epoch 014 | Loss=1.0136 | TestAcc=0.493 | F1=0.458 | AUC=0.677 | Time=4.95s\n","Epoch 015 | Loss=1.0094 | TestAcc=0.480 | F1=0.469 | AUC=0.684 | Time=5.30s\n","Epoch 016 | Loss=0.9867 | TestAcc=0.487 | F1=0.479 | AUC=0.685 | Time=5.66s\n","Epoch 017 | Loss=1.0412 | TestAcc=0.523 | F1=0.520 | AUC=0.691 | Time=6.04s\n","Epoch 018 | Loss=0.9951 | TestAcc=0.477 | F1=0.470 | AUC=0.682 | Time=6.40s\n","Epoch 019 | Loss=0.9979 | TestAcc=0.497 | F1=0.477 | AUC=0.678 | Time=6.76s\n","Epoch 020 | Loss=1.0068 | TestAcc=0.490 | F1=0.482 | AUC=0.665 | Time=7.10s\n","Epoch 021 | Loss=0.9934 | TestAcc=0.453 | F1=0.434 | AUC=0.676 | Time=7.46s\n","Epoch 022 | Loss=0.9942 | TestAcc=0.467 | F1=0.456 | AUC=0.674 | Time=7.81s\n","Epoch 023 | Loss=0.9800 | TestAcc=0.497 | F1=0.488 | AUC=0.681 | Time=8.15s\n","Epoch 024 | Loss=0.9770 | TestAcc=0.457 | F1=0.435 | AUC=0.679 | Time=8.55s\n","Epoch 025 | Loss=0.9953 | TestAcc=0.503 | F1=0.470 | AUC=0.685 | Time=9.04s\n","Epoch 026 | Loss=0.9830 | TestAcc=0.497 | F1=0.466 | AUC=0.674 | Time=9.50s\n","Epoch 027 | Loss=0.9830 | TestAcc=0.493 | F1=0.489 | AUC=0.694 | Time=10.00s\n","Epoch 028 | Loss=0.9769 | TestAcc=0.483 | F1=0.461 | AUC=0.665 | Time=10.47s\n","Epoch 029 | Loss=0.9791 | TestAcc=0.490 | F1=0.478 | AUC=0.690 | Time=10.92s\n","Epoch 030 | Loss=0.9694 | TestAcc=0.480 | F1=0.475 | AUC=0.695 | Time=11.47s\n","Epoch 031 | Loss=0.9974 | TestAcc=0.480 | F1=0.471 | AUC=0.669 | Time=11.86s\n","Epoch 032 | Loss=0.9662 | TestAcc=0.490 | F1=0.486 | AUC=0.684 | Time=12.22s\n","Epoch 033 | Loss=0.9538 | TestAcc=0.453 | F1=0.448 | AUC=0.671 | Time=12.56s\n","Epoch 034 | Loss=0.9819 | TestAcc=0.500 | F1=0.490 | AUC=0.671 | Time=12.90s\n","Epoch 035 | Loss=0.9809 | TestAcc=0.487 | F1=0.472 | AUC=0.669 | Time=13.27s\n","Epoch 036 | Loss=0.9769 | TestAcc=0.497 | F1=0.475 | AUC=0.668 | Time=13.62s\n","Epoch 037 | Loss=0.9893 | TestAcc=0.513 | F1=0.492 | AUC=0.692 | Time=13.97s\n","Epoch 038 | Loss=0.9623 | TestAcc=0.483 | F1=0.466 | AUC=0.677 | Time=14.34s\n","Epoch 039 | Loss=0.9732 | TestAcc=0.507 | F1=0.487 | AUC=0.674 | Time=14.69s\n","Epoch 040 | Loss=0.9573 | TestAcc=0.520 | F1=0.499 | AUC=0.681 | Time=15.03s\n","Epoch 041 | Loss=0.9548 | TestAcc=0.510 | F1=0.487 | AUC=0.676 | Time=15.40s\n","Epoch 042 | Loss=0.9897 | TestAcc=0.523 | F1=0.519 | AUC=0.687 | Time=15.77s\n","Epoch 043 | Loss=0.9637 | TestAcc=0.517 | F1=0.502 | AUC=0.684 | Time=16.12s\n","Epoch 044 | Loss=0.9517 | TestAcc=0.503 | F1=0.502 | AUC=0.688 | Time=16.48s\n","Epoch 045 | Loss=0.9715 | TestAcc=0.517 | F1=0.501 | AUC=0.687 | Time=16.83s\n","Epoch 046 | Loss=0.9502 | TestAcc=0.467 | F1=0.463 | AUC=0.695 | Time=17.17s\n","Epoch 047 | Loss=0.9500 | TestAcc=0.410 | F1=0.408 | AUC=0.667 | Time=17.52s\n","Epoch 048 | Loss=0.9584 | TestAcc=0.420 | F1=0.425 | AUC=0.676 | Time=17.86s\n","Epoch 049 | Loss=0.9545 | TestAcc=0.490 | F1=0.470 | AUC=0.671 | Time=18.22s\n","Epoch 050 | Loss=0.9489 | TestAcc=0.480 | F1=0.466 | AUC=0.659 | Time=18.58s\n","Epoch 051 | Loss=0.9417 | TestAcc=0.490 | F1=0.476 | AUC=0.674 | Time=18.92s\n","Epoch 052 | Loss=0.9445 | TestAcc=0.527 | F1=0.513 | AUC=0.682 | Time=19.26s\n","Epoch 053 | Loss=0.9579 | TestAcc=0.490 | F1=0.469 | AUC=0.652 | Time=19.62s\n","Epoch 054 | Loss=0.9435 | TestAcc=0.527 | F1=0.509 | AUC=0.675 | Time=19.97s\n","Epoch 055 | Loss=0.9578 | TestAcc=0.517 | F1=0.505 | AUC=0.678 | Time=20.33s\n","Epoch 056 | Loss=0.9187 | TestAcc=0.507 | F1=0.494 | AUC=0.668 | Time=20.69s\n","Epoch 057 | Loss=0.9618 | TestAcc=0.517 | F1=0.494 | AUC=0.688 | Time=21.04s\n","Epoch 058 | Loss=0.9243 | TestAcc=0.530 | F1=0.519 | AUC=0.679 | Time=21.40s\n","Epoch 059 | Loss=0.9247 | TestAcc=0.473 | F1=0.453 | AUC=0.680 | Time=21.84s\n","Epoch 060 | Loss=0.9471 | TestAcc=0.503 | F1=0.474 | AUC=0.677 | Time=22.29s\n","Epoch 061 | Loss=0.9568 | TestAcc=0.473 | F1=0.447 | AUC=0.675 | Time=22.78s\n","Epoch 062 | Loss=0.9180 | TestAcc=0.500 | F1=0.496 | AUC=0.677 | Time=23.30s\n","Epoch 063 | Loss=0.9257 | TestAcc=0.510 | F1=0.487 | AUC=0.680 | Time=23.77s\n","Epoch 064 | Loss=0.9348 | TestAcc=0.500 | F1=0.471 | AUC=0.692 | Time=24.24s\n","Epoch 065 | Loss=0.9414 | TestAcc=0.513 | F1=0.483 | AUC=0.663 | Time=24.77s\n","Epoch 066 | Loss=0.9436 | TestAcc=0.517 | F1=0.494 | AUC=0.670 | Time=25.13s\n","Epoch 067 | Loss=0.9338 | TestAcc=0.517 | F1=0.504 | AUC=0.682 | Time=25.47s\n","Epoch 068 | Loss=0.9254 | TestAcc=0.520 | F1=0.495 | AUC=0.664 | Time=25.84s\n","Epoch 069 | Loss=0.9370 | TestAcc=0.503 | F1=0.487 | AUC=0.666 | Time=26.19s\n","Epoch 070 | Loss=0.9252 | TestAcc=0.527 | F1=0.516 | AUC=0.676 | Time=26.54s\n","Epoch 071 | Loss=0.9112 | TestAcc=0.510 | F1=0.497 | AUC=0.665 | Time=26.90s\n","Epoch 072 | Loss=0.9136 | TestAcc=0.507 | F1=0.468 | AUC=0.663 | Time=27.25s\n","Epoch 073 | Loss=0.9187 | TestAcc=0.533 | F1=0.505 | AUC=0.684 | Time=27.60s\n","Epoch 074 | Loss=0.9201 | TestAcc=0.473 | F1=0.436 | AUC=0.636 | Time=27.97s\n","Epoch 075 | Loss=0.9298 | TestAcc=0.527 | F1=0.519 | AUC=0.676 | Time=28.32s\n","Epoch 076 | Loss=0.9090 | TestAcc=0.493 | F1=0.470 | AUC=0.652 | Time=28.67s\n","Epoch 077 | Loss=0.9349 | TestAcc=0.507 | F1=0.481 | AUC=0.661 | Time=29.04s\n","Epoch 078 | Loss=0.9342 | TestAcc=0.517 | F1=0.499 | AUC=0.662 | Time=29.39s\n","Epoch 079 | Loss=0.9196 | TestAcc=0.520 | F1=0.507 | AUC=0.676 | Time=29.74s\n","Epoch 080 | Loss=0.9291 | TestAcc=0.440 | F1=0.420 | AUC=0.675 | Time=30.10s\n","Epoch 081 | Loss=0.8994 | TestAcc=0.527 | F1=0.512 | AUC=0.668 | Time=30.45s\n","Epoch 082 | Loss=0.8870 | TestAcc=0.517 | F1=0.499 | AUC=0.673 | Time=30.81s\n","Epoch 083 | Loss=0.8952 | TestAcc=0.513 | F1=0.469 | AUC=0.662 | Time=31.16s\n","Epoch 084 | Loss=0.9150 | TestAcc=0.517 | F1=0.494 | AUC=0.669 | Time=31.50s\n","Epoch 085 | Loss=0.9122 | TestAcc=0.500 | F1=0.455 | AUC=0.666 | Time=31.87s\n","Epoch 086 | Loss=0.9035 | TestAcc=0.497 | F1=0.451 | AUC=0.640 | Time=32.21s\n","Epoch 087 | Loss=0.9272 | TestAcc=0.490 | F1=0.475 | AUC=0.671 | Time=32.55s\n","Epoch 088 | Loss=0.9128 | TestAcc=0.497 | F1=0.474 | AUC=0.671 | Time=32.92s\n","Epoch 089 | Loss=0.9302 | TestAcc=0.500 | F1=0.469 | AUC=0.668 | Time=33.27s\n","Epoch 090 | Loss=0.9197 | TestAcc=0.470 | F1=0.448 | AUC=0.661 | Time=33.61s\n","Epoch 091 | Loss=0.9144 | TestAcc=0.500 | F1=0.478 | AUC=0.656 | Time=33.98s\n","Epoch 092 | Loss=0.9089 | TestAcc=0.503 | F1=0.489 | AUC=0.671 | Time=34.32s\n","Epoch 093 | Loss=0.9333 | TestAcc=0.523 | F1=0.516 | AUC=0.667 | Time=34.67s\n","Epoch 094 | Loss=0.9153 | TestAcc=0.507 | F1=0.477 | AUC=0.649 | Time=35.16s\n","Epoch 095 | Loss=0.8992 | TestAcc=0.443 | F1=0.427 | AUC=0.671 | Time=35.61s\n","Epoch 096 | Loss=0.8978 | TestAcc=0.473 | F1=0.457 | AUC=0.656 | Time=36.13s\n","Epoch 097 | Loss=0.9242 | TestAcc=0.503 | F1=0.483 | AUC=0.681 | Time=36.59s\n","Epoch 098 | Loss=0.8891 | TestAcc=0.517 | F1=0.494 | AUC=0.665 | Time=37.05s\n","Epoch 099 | Loss=0.9000 | TestAcc=0.487 | F1=0.469 | AUC=0.648 | Time=37.55s\n","Epoch 100 | Loss=0.8906 | TestAcc=0.500 | F1=0.471 | AUC=0.667 | Time=38.02s\n","Epoch 101 | Loss=0.9104 | TestAcc=0.463 | F1=0.440 | AUC=0.634 | Time=38.38s\n","Epoch 102 | Loss=0.9066 | TestAcc=0.440 | F1=0.407 | AUC=0.648 | Time=38.72s\n","Epoch 103 | Loss=0.9187 | TestAcc=0.500 | F1=0.497 | AUC=0.679 | Time=39.07s\n","Epoch 104 | Loss=0.9246 | TestAcc=0.500 | F1=0.487 | AUC=0.687 | Time=39.43s\n","Epoch 105 | Loss=0.9489 | TestAcc=0.507 | F1=0.479 | AUC=0.653 | Time=39.78s\n","Epoch 106 | Loss=0.9128 | TestAcc=0.503 | F1=0.487 | AUC=0.667 | Time=40.13s\n","Epoch 107 | Loss=0.8890 | TestAcc=0.493 | F1=0.473 | AUC=0.676 | Time=40.49s\n","Epoch 108 | Loss=0.8951 | TestAcc=0.500 | F1=0.477 | AUC=0.664 | Time=40.84s\n","Epoch 109 | Loss=0.9462 | TestAcc=0.500 | F1=0.462 | AUC=0.655 | Time=41.20s\n","Epoch 110 | Loss=0.9145 | TestAcc=0.520 | F1=0.508 | AUC=0.679 | Time=41.57s\n","Epoch 111 | Loss=0.9018 | TestAcc=0.510 | F1=0.475 | AUC=0.676 | Time=41.91s\n","Epoch 112 | Loss=0.8927 | TestAcc=0.510 | F1=0.497 | AUC=0.684 | Time=42.27s\n","Epoch 113 | Loss=0.8988 | TestAcc=0.550 | F1=0.544 | AUC=0.700 | Time=42.60s\n","Epoch 114 | Loss=0.9215 | TestAcc=0.500 | F1=0.464 | AUC=0.674 | Time=42.95s\n","Epoch 115 | Loss=0.9045 | TestAcc=0.477 | F1=0.443 | AUC=0.697 | Time=43.31s\n","Epoch 116 | Loss=0.8971 | TestAcc=0.523 | F1=0.511 | AUC=0.679 | Time=43.66s\n","Epoch 117 | Loss=0.9296 | TestAcc=0.523 | F1=0.512 | AUC=0.694 | Time=44.01s\n","Epoch 118 | Loss=0.9212 | TestAcc=0.500 | F1=0.473 | AUC=0.669 | Time=44.38s\n","Epoch 119 | Loss=0.8725 | TestAcc=0.507 | F1=0.482 | AUC=0.653 | Time=44.72s\n","Epoch 120 | Loss=0.9069 | TestAcc=0.490 | F1=0.480 | AUC=0.650 | Time=45.08s\n","Epoch 121 | Loss=0.9064 | TestAcc=0.513 | F1=0.487 | AUC=0.663 | Time=45.45s\n","Epoch 122 | Loss=0.8937 | TestAcc=0.523 | F1=0.504 | AUC=0.670 | Time=45.80s\n","Epoch 123 | Loss=0.8993 | TestAcc=0.510 | F1=0.494 | AUC=0.675 | Time=46.15s\n","Epoch 124 | Loss=0.8728 | TestAcc=0.523 | F1=0.504 | AUC=0.670 | Time=46.51s\n","Epoch 125 | Loss=0.8840 | TestAcc=0.497 | F1=0.460 | AUC=0.667 | Time=46.86s\n","Epoch 126 | Loss=0.9067 | TestAcc=0.503 | F1=0.483 | AUC=0.670 | Time=47.20s\n","Epoch 127 | Loss=0.8920 | TestAcc=0.500 | F1=0.487 | AUC=0.673 | Time=47.56s\n","Epoch 128 | Loss=0.8962 | TestAcc=0.480 | F1=0.457 | AUC=0.670 | Time=47.90s\n","Epoch 129 | Loss=0.8877 | TestAcc=0.527 | F1=0.510 | AUC=0.670 | Time=48.40s\n","Epoch 130 | Loss=0.9102 | TestAcc=0.490 | F1=0.473 | AUC=0.667 | Time=48.85s\n","Epoch 131 | Loss=0.8902 | TestAcc=0.500 | F1=0.488 | AUC=0.684 | Time=49.35s\n","Epoch 132 | Loss=0.8823 | TestAcc=0.473 | F1=0.449 | AUC=0.662 | Time=49.85s\n","Epoch 133 | Loss=0.8780 | TestAcc=0.493 | F1=0.488 | AUC=0.667 | Time=50.29s\n","Epoch 134 | Loss=0.9032 | TestAcc=0.480 | F1=0.471 | AUC=0.655 | Time=50.83s\n","Epoch 135 | Loss=0.8905 | TestAcc=0.483 | F1=0.472 | AUC=0.659 | Time=51.25s\n","Epoch 136 | Loss=0.8807 | TestAcc=0.493 | F1=0.482 | AUC=0.673 | Time=51.60s\n","Epoch 137 | Loss=0.8538 | TestAcc=0.510 | F1=0.504 | AUC=0.669 | Time=51.95s\n","Epoch 138 | Loss=0.8891 | TestAcc=0.433 | F1=0.396 | AUC=0.661 | Time=52.29s\n","Epoch 139 | Loss=0.8722 | TestAcc=0.473 | F1=0.457 | AUC=0.651 | Time=52.64s\n","Epoch 140 | Loss=0.8775 | TestAcc=0.510 | F1=0.475 | AUC=0.663 | Time=53.00s\n","Epoch 141 | Loss=0.8790 | TestAcc=0.507 | F1=0.488 | AUC=0.668 | Time=53.38s\n","Epoch 142 | Loss=0.8661 | TestAcc=0.527 | F1=0.503 | AUC=0.679 | Time=53.72s\n","Epoch 143 | Loss=0.8867 | TestAcc=0.523 | F1=0.489 | AUC=0.683 | Time=54.08s\n","Epoch 144 | Loss=0.8937 | TestAcc=0.517 | F1=0.503 | AUC=0.666 | Time=54.42s\n","Epoch 145 | Loss=0.8905 | TestAcc=0.527 | F1=0.491 | AUC=0.658 | Time=54.76s\n","Epoch 146 | Loss=0.8931 | TestAcc=0.510 | F1=0.489 | AUC=0.678 | Time=55.12s\n","Epoch 147 | Loss=0.8883 | TestAcc=0.517 | F1=0.506 | AUC=0.684 | Time=55.46s\n","Epoch 148 | Loss=0.8655 | TestAcc=0.450 | F1=0.447 | AUC=0.648 | Time=55.82s\n","Epoch 149 | Loss=0.8999 | TestAcc=0.507 | F1=0.498 | AUC=0.665 | Time=56.17s\n","Epoch 150 | Loss=0.8619 | TestAcc=0.520 | F1=0.490 | AUC=0.672 | Time=56.52s\n","Epoch 151 | Loss=0.8499 | TestAcc=0.530 | F1=0.506 | AUC=0.686 | Time=56.87s\n","Epoch 152 | Loss=0.8688 | TestAcc=0.523 | F1=0.498 | AUC=0.694 | Time=57.22s\n","Epoch 153 | Loss=0.8627 | TestAcc=0.523 | F1=0.496 | AUC=0.687 | Time=57.57s\n","Epoch 154 | Loss=0.8593 | TestAcc=0.530 | F1=0.512 | AUC=0.675 | Time=57.94s\n","Epoch 155 | Loss=0.8796 | TestAcc=0.520 | F1=0.495 | AUC=0.683 | Time=58.29s\n","Epoch 156 | Loss=0.8987 | TestAcc=0.523 | F1=0.503 | AUC=0.678 | Time=58.64s\n","Epoch 157 | Loss=0.8686 | TestAcc=0.513 | F1=0.492 | AUC=0.672 | Time=58.99s\n","Epoch 158 | Loss=0.8852 | TestAcc=0.510 | F1=0.480 | AUC=0.677 | Time=59.34s\n","Epoch 159 | Loss=0.8346 | TestAcc=0.510 | F1=0.483 | AUC=0.662 | Time=59.69s\n","Epoch 160 | Loss=0.8438 | TestAcc=0.497 | F1=0.477 | AUC=0.657 | Time=60.05s\n","Epoch 161 | Loss=0.8569 | TestAcc=0.490 | F1=0.477 | AUC=0.669 | Time=60.39s\n","Epoch 162 | Loss=0.8574 | TestAcc=0.507 | F1=0.479 | AUC=0.674 | Time=60.74s\n","Epoch 163 | Loss=0.8457 | TestAcc=0.527 | F1=0.501 | AUC=0.671 | Time=61.16s\n","Epoch 164 | Loss=0.8624 | TestAcc=0.510 | F1=0.494 | AUC=0.663 | Time=61.64s\n","Epoch 165 | Loss=0.8644 | TestAcc=0.510 | F1=0.503 | AUC=0.679 | Time=62.12s\n","Epoch 166 | Loss=0.8434 | TestAcc=0.510 | F1=0.495 | AUC=0.666 | Time=62.60s\n","Epoch 167 | Loss=0.8475 | TestAcc=0.523 | F1=0.511 | AUC=0.670 | Time=63.06s\n","Epoch 168 | Loss=0.8674 | TestAcc=0.493 | F1=0.471 | AUC=0.653 | Time=63.55s\n","Epoch 169 | Loss=0.8344 | TestAcc=0.540 | F1=0.522 | AUC=0.688 | Time=64.08s\n","Epoch 170 | Loss=0.8449 | TestAcc=0.510 | F1=0.500 | AUC=0.673 | Time=64.44s\n","Epoch 171 | Loss=0.8612 | TestAcc=0.527 | F1=0.513 | AUC=0.685 | Time=64.78s\n","Epoch 172 | Loss=0.8555 | TestAcc=0.530 | F1=0.513 | AUC=0.685 | Time=65.13s\n","Epoch 173 | Loss=0.8479 | TestAcc=0.527 | F1=0.517 | AUC=0.663 | Time=65.48s\n","Epoch 174 | Loss=0.8411 | TestAcc=0.523 | F1=0.507 | AUC=0.674 | Time=65.84s\n","Epoch 175 | Loss=0.8440 | TestAcc=0.530 | F1=0.524 | AUC=0.684 | Time=66.22s\n","Epoch 176 | Loss=0.8551 | TestAcc=0.527 | F1=0.503 | AUC=0.676 | Time=66.57s\n","Epoch 177 | Loss=0.8489 | TestAcc=0.467 | F1=0.437 | AUC=0.665 | Time=66.91s\n","Epoch 178 | Loss=0.8517 | TestAcc=0.510 | F1=0.488 | AUC=0.670 | Time=67.28s\n","Epoch 179 | Loss=0.8577 | TestAcc=0.517 | F1=0.510 | AUC=0.677 | Time=67.63s\n","Epoch 180 | Loss=0.8455 | TestAcc=0.523 | F1=0.492 | AUC=0.680 | Time=67.98s\n","Epoch 181 | Loss=0.8585 | TestAcc=0.493 | F1=0.470 | AUC=0.668 | Time=68.35s\n","Epoch 182 | Loss=0.8416 | TestAcc=0.473 | F1=0.454 | AUC=0.659 | Time=68.70s\n","Epoch 183 | Loss=0.8373 | TestAcc=0.477 | F1=0.456 | AUC=0.667 | Time=69.05s\n","Epoch 184 | Loss=0.8445 | TestAcc=0.487 | F1=0.468 | AUC=0.670 | Time=69.42s\n","Epoch 185 | Loss=0.8327 | TestAcc=0.507 | F1=0.487 | AUC=0.667 | Time=69.78s\n","Epoch 186 | Loss=0.8394 | TestAcc=0.523 | F1=0.509 | AUC=0.666 | Time=70.14s\n","Epoch 187 | Loss=0.8530 | TestAcc=0.493 | F1=0.479 | AUC=0.656 | Time=70.51s\n","Epoch 188 | Loss=0.8470 | TestAcc=0.507 | F1=0.492 | AUC=0.655 | Time=70.85s\n","Epoch 189 | Loss=0.8312 | TestAcc=0.527 | F1=0.502 | AUC=0.669 | Time=71.22s\n","Epoch 190 | Loss=0.8271 | TestAcc=0.520 | F1=0.501 | AUC=0.668 | Time=71.59s\n","Epoch 191 | Loss=0.8349 | TestAcc=0.490 | F1=0.469 | AUC=0.650 | Time=71.93s\n","Epoch 192 | Loss=0.8373 | TestAcc=0.517 | F1=0.497 | AUC=0.668 | Time=72.28s\n","Epoch 193 | Loss=0.8475 | TestAcc=0.510 | F1=0.488 | AUC=0.667 | Time=72.63s\n","Epoch 194 | Loss=0.8624 | TestAcc=0.513 | F1=0.484 | AUC=0.680 | Time=72.97s\n","Epoch 195 | Loss=0.8724 | TestAcc=0.513 | F1=0.478 | AUC=0.665 | Time=73.31s\n","Epoch 196 | Loss=0.8468 | TestAcc=0.513 | F1=0.487 | AUC=0.671 | Time=73.67s\n","Epoch 197 | Loss=0.8500 | TestAcc=0.517 | F1=0.493 | AUC=0.684 | Time=74.02s\n","Epoch 198 | Loss=0.8581 | TestAcc=0.493 | F1=0.477 | AUC=0.661 | Time=74.50s\n","Epoch 199 | Loss=0.8624 | TestAcc=0.497 | F1=0.482 | AUC=0.657 | Time=74.96s\n","Epoch 200 | Loss=0.8457 | TestAcc=0.500 | F1=0.483 | AUC=0.663 | Time=76.11s\n","\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed     dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    42  IMDB-MULTI                  yes                   64   \n","\n","  objective_weights  num_layers   dropout        lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           3  0.594114  0.002132      0.000037     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0         113     1.2166     1.2166      0.55   0.5439    0.7001   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              76.11                33.05             1431.4  \n","Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_IMDB-MULTI_42.pth\n","Dataset has no node features. Applying OneHotDegree transform...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:37:23,648] A new study created in memory with name: no-name-949a25ca-1005-4894-a4ae-f8df6a54014b\n"]},{"output_type":"stream","name":"stdout","text":["Loaded dataset IMDB-MULTI: 1500 graphs, 89 node features, 3 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:37:25,714] Trial 0 finished with value: 0.43206978756071074 and parameters: {'num_layers': 4, 'dropout': 0.048554786682629976, 'lr': 0.000821332771808136, 'weight_decay': 4.832262236849303e-06}. Best is trial 0 with value: 0.43206978756071074.\n","[I 2026-01-27 17:37:27,825] Trial 1 finished with value: 0.3783728866217536 and parameters: {'num_layers': 5, 'dropout': 0.3874049602254113, 'lr': 0.00012492159714514201, 'weight_decay': 1.3679448601761318e-05}. Best is trial 0 with value: 0.43206978756071074.\n","[I 2026-01-27 17:37:29,598] Trial 2 finished with value: 0.5342208278192756 and parameters: {'num_layers': 3, 'dropout': 0.05643184068150653, 'lr': 0.008682711243659175, 'weight_decay': 0.00037285376000681814}. Best is trial 2 with value: 0.5342208278192756.\n","[I 2026-01-27 17:37:31,787] Trial 3 finished with value: 0.4724744971595624 and parameters: {'num_layers': 5, 'dropout': 0.17050826567546176, 'lr': 0.0071286997532850555, 'weight_decay': 0.0008886845293093101}. Best is trial 2 with value: 0.5342208278192756.\n","[I 2026-01-27 17:37:33,938] Trial 4 finished with value: 0.47678174844271426 and parameters: {'num_layers': 4, 'dropout': 0.30009263608338793, 'lr': 0.006832877957096507, 'weight_decay': 0.00010440753732243263}. Best is trial 2 with value: 0.5342208278192756.\n","[I 2026-01-27 17:37:36,712] Trial 5 finished with value: 0.43578652643544047 and parameters: {'num_layers': 5, 'dropout': 0.4161553305297893, 'lr': 0.0035074620248527993, 'weight_decay': 2.156357053929227e-05}. Best is trial 2 with value: 0.5342208278192756.\n","[I 2026-01-27 17:37:39,231] Trial 6 finished with value: 0.47918558381155607 and parameters: {'num_layers': 6, 'dropout': 0.5508186715520265, 'lr': 0.0066949548863283114, 'weight_decay': 1.667491089646899e-05}. Best is trial 2 with value: 0.5342208278192756.\n","[I 2026-01-27 17:37:40,938] Trial 7 finished with value: 0.5305947658557407 and parameters: {'num_layers': 3, 'dropout': 0.02503535392943317, 'lr': 0.0008565258125112432, 'weight_decay': 1.079320607526698e-06}. Best is trial 2 with value: 0.5342208278192756.\n","[I 2026-01-27 17:37:43,026] Trial 8 finished with value: 0.47333662502465923 and parameters: {'num_layers': 5, 'dropout': 0.5523844433047241, 'lr': 0.0002983030364421358, 'weight_decay': 2.0428272747253573e-05}. Best is trial 2 with value: 0.5342208278192756.\n","[I 2026-01-27 17:37:45,272] Trial 9 finished with value: 0.39842017171463096 and parameters: {'num_layers': 6, 'dropout': 0.15218278771408747, 'lr': 0.00015184608497035106, 'weight_decay': 1.7688642327421545e-05}. Best is trial 2 with value: 0.5342208278192756.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 3, 'dropout': 0.05643184068150653, 'lr': 0.008682711243659175, 'weight_decay': 0.00037285376000681814}\n","\n","Running final training GIN...\n","{'num_layers': 3, 'dropout': 0.05643184068150653, 'lr': 0.008682711243659175, 'weight_decay': 0.00037285376000681814}\n","Epoch 001 | Loss=1.9572 | TestAcc=0.387 | F1=0.359 | AUC=0.536 | Time=0.35s\n","Epoch 002 | Loss=1.2050 | TestAcc=0.430 | F1=0.397 | AUC=0.673 | Time=0.71s\n","Epoch 003 | Loss=1.0640 | TestAcc=0.490 | F1=0.483 | AUC=0.667 | Time=1.20s\n","Epoch 004 | Loss=1.0338 | TestAcc=0.443 | F1=0.425 | AUC=0.653 | Time=1.66s\n","Epoch 005 | Loss=1.0372 | TestAcc=0.457 | F1=0.393 | AUC=0.661 | Time=2.16s\n","Epoch 006 | Loss=1.0126 | TestAcc=0.443 | F1=0.408 | AUC=0.675 | Time=2.62s\n","Epoch 007 | Loss=1.0088 | TestAcc=0.507 | F1=0.436 | AUC=0.667 | Time=3.08s\n","Epoch 008 | Loss=1.0285 | TestAcc=0.457 | F1=0.454 | AUC=0.642 | Time=3.58s\n","Epoch 009 | Loss=1.0154 | TestAcc=0.433 | F1=0.385 | AUC=0.654 | Time=4.04s\n","Epoch 010 | Loss=0.9963 | TestAcc=0.483 | F1=0.474 | AUC=0.671 | Time=4.40s\n","Epoch 011 | Loss=1.0039 | TestAcc=0.517 | F1=0.488 | AUC=0.678 | Time=4.74s\n","Epoch 012 | Loss=1.0061 | TestAcc=0.497 | F1=0.443 | AUC=0.672 | Time=5.09s\n","Epoch 013 | Loss=1.0127 | TestAcc=0.493 | F1=0.407 | AUC=0.663 | Time=5.46s\n","Epoch 014 | Loss=0.9900 | TestAcc=0.497 | F1=0.463 | AUC=0.682 | Time=5.81s\n","Epoch 015 | Loss=0.9960 | TestAcc=0.493 | F1=0.481 | AUC=0.687 | Time=6.17s\n","Epoch 016 | Loss=0.9909 | TestAcc=0.480 | F1=0.427 | AUC=0.686 | Time=6.52s\n","Epoch 017 | Loss=0.9797 | TestAcc=0.477 | F1=0.478 | AUC=0.721 | Time=6.86s\n","Epoch 018 | Loss=1.0002 | TestAcc=0.493 | F1=0.494 | AUC=0.696 | Time=7.22s\n","Epoch 019 | Loss=0.9723 | TestAcc=0.410 | F1=0.408 | AUC=0.645 | Time=7.58s\n","Epoch 020 | Loss=0.9824 | TestAcc=0.507 | F1=0.467 | AUC=0.700 | Time=7.92s\n","Epoch 021 | Loss=0.9851 | TestAcc=0.510 | F1=0.471 | AUC=0.683 | Time=8.28s\n","Epoch 022 | Loss=0.9869 | TestAcc=0.490 | F1=0.425 | AUC=0.688 | Time=8.65s\n","Epoch 023 | Loss=0.9904 | TestAcc=0.533 | F1=0.522 | AUC=0.713 | Time=8.99s\n","Epoch 024 | Loss=0.9864 | TestAcc=0.507 | F1=0.487 | AUC=0.691 | Time=9.36s\n","Epoch 025 | Loss=0.9820 | TestAcc=0.450 | F1=0.410 | AUC=0.664 | Time=9.72s\n","Epoch 026 | Loss=0.9850 | TestAcc=0.537 | F1=0.520 | AUC=0.695 | Time=10.08s\n","Epoch 027 | Loss=0.9798 | TestAcc=0.463 | F1=0.442 | AUC=0.680 | Time=10.48s\n","Epoch 028 | Loss=0.9615 | TestAcc=0.520 | F1=0.513 | AUC=0.687 | Time=10.83s\n","Epoch 029 | Loss=0.9673 | TestAcc=0.490 | F1=0.491 | AUC=0.687 | Time=11.17s\n","Epoch 030 | Loss=0.9647 | TestAcc=0.523 | F1=0.509 | AUC=0.704 | Time=11.53s\n","Epoch 031 | Loss=0.9924 | TestAcc=0.503 | F1=0.437 | AUC=0.693 | Time=11.88s\n","Epoch 032 | Loss=0.9766 | TestAcc=0.483 | F1=0.473 | AUC=0.699 | Time=12.22s\n","Epoch 033 | Loss=0.9928 | TestAcc=0.497 | F1=0.473 | AUC=0.682 | Time=12.58s\n","Epoch 034 | Loss=0.9887 | TestAcc=0.493 | F1=0.440 | AUC=0.667 | Time=12.93s\n","Epoch 035 | Loss=1.0054 | TestAcc=0.453 | F1=0.453 | AUC=0.677 | Time=13.28s\n","Epoch 036 | Loss=0.9872 | TestAcc=0.483 | F1=0.464 | AUC=0.683 | Time=13.63s\n","Epoch 037 | Loss=0.9862 | TestAcc=0.493 | F1=0.432 | AUC=0.696 | Time=14.05s\n","Epoch 038 | Loss=0.9611 | TestAcc=0.487 | F1=0.477 | AUC=0.675 | Time=14.54s\n","Epoch 039 | Loss=0.9597 | TestAcc=0.453 | F1=0.434 | AUC=0.655 | Time=14.98s\n","Epoch 040 | Loss=0.9741 | TestAcc=0.460 | F1=0.440 | AUC=0.669 | Time=15.49s\n","Epoch 041 | Loss=0.9801 | TestAcc=0.517 | F1=0.505 | AUC=0.684 | Time=15.97s\n","Epoch 042 | Loss=0.9535 | TestAcc=0.480 | F1=0.424 | AUC=0.690 | Time=16.42s\n","Epoch 043 | Loss=0.9926 | TestAcc=0.520 | F1=0.473 | AUC=0.691 | Time=16.95s\n","Epoch 044 | Loss=0.9479 | TestAcc=0.477 | F1=0.470 | AUC=0.689 | Time=17.37s\n","Epoch 045 | Loss=0.9534 | TestAcc=0.503 | F1=0.487 | AUC=0.672 | Time=17.74s\n","Epoch 046 | Loss=0.9524 | TestAcc=0.497 | F1=0.446 | AUC=0.693 | Time=18.08s\n","Epoch 047 | Loss=0.9563 | TestAcc=0.517 | F1=0.486 | AUC=0.704 | Time=18.43s\n","Epoch 048 | Loss=0.9436 | TestAcc=0.500 | F1=0.491 | AUC=0.690 | Time=18.80s\n","Epoch 049 | Loss=0.9826 | TestAcc=0.470 | F1=0.453 | AUC=0.672 | Time=19.14s\n","Epoch 050 | Loss=0.9526 | TestAcc=0.487 | F1=0.420 | AUC=0.690 | Time=19.48s\n","Epoch 051 | Loss=0.9401 | TestAcc=0.463 | F1=0.383 | AUC=0.690 | Time=19.84s\n","Epoch 052 | Loss=0.9742 | TestAcc=0.487 | F1=0.403 | AUC=0.654 | Time=20.18s\n","Epoch 053 | Loss=0.9691 | TestAcc=0.483 | F1=0.439 | AUC=0.675 | Time=20.53s\n","Epoch 054 | Loss=0.9552 | TestAcc=0.527 | F1=0.500 | AUC=0.716 | Time=20.89s\n","Epoch 055 | Loss=0.9665 | TestAcc=0.497 | F1=0.452 | AUC=0.687 | Time=21.23s\n","Epoch 056 | Loss=0.9693 | TestAcc=0.527 | F1=0.518 | AUC=0.714 | Time=21.57s\n","Epoch 057 | Loss=0.9444 | TestAcc=0.500 | F1=0.483 | AUC=0.689 | Time=21.95s\n","Epoch 058 | Loss=0.9498 | TestAcc=0.510 | F1=0.506 | AUC=0.677 | Time=22.28s\n","Epoch 059 | Loss=0.9435 | TestAcc=0.480 | F1=0.476 | AUC=0.682 | Time=22.62s\n","Epoch 060 | Loss=0.9634 | TestAcc=0.500 | F1=0.487 | AUC=0.699 | Time=22.98s\n","Epoch 061 | Loss=0.9318 | TestAcc=0.513 | F1=0.497 | AUC=0.693 | Time=23.33s\n","Epoch 062 | Loss=0.9535 | TestAcc=0.533 | F1=0.517 | AUC=0.694 | Time=23.69s\n","Epoch 063 | Loss=0.9688 | TestAcc=0.497 | F1=0.493 | AUC=0.683 | Time=24.05s\n","Epoch 064 | Loss=0.9402 | TestAcc=0.537 | F1=0.524 | AUC=0.697 | Time=24.39s\n","Epoch 065 | Loss=0.9389 | TestAcc=0.523 | F1=0.490 | AUC=0.712 | Time=24.74s\n","Epoch 066 | Loss=0.9345 | TestAcc=0.517 | F1=0.502 | AUC=0.691 | Time=25.09s\n","Epoch 067 | Loss=0.9493 | TestAcc=0.533 | F1=0.525 | AUC=0.684 | Time=25.43s\n","Epoch 068 | Loss=0.9447 | TestAcc=0.477 | F1=0.453 | AUC=0.681 | Time=25.78s\n","Epoch 069 | Loss=0.9411 | TestAcc=0.497 | F1=0.494 | AUC=0.657 | Time=26.15s\n","Epoch 070 | Loss=0.9379 | TestAcc=0.510 | F1=0.479 | AUC=0.690 | Time=26.50s\n","Epoch 071 | Loss=0.9349 | TestAcc=0.537 | F1=0.520 | AUC=0.701 | Time=26.85s\n","Epoch 072 | Loss=0.9299 | TestAcc=0.527 | F1=0.521 | AUC=0.707 | Time=27.26s\n","Epoch 073 | Loss=0.9212 | TestAcc=0.503 | F1=0.456 | AUC=0.691 | Time=27.73s\n","Epoch 074 | Loss=0.9241 | TestAcc=0.507 | F1=0.492 | AUC=0.693 | Time=28.20s\n","Epoch 075 | Loss=0.9294 | TestAcc=0.527 | F1=0.511 | AUC=0.709 | Time=28.69s\n","Epoch 076 | Loss=0.9640 | TestAcc=0.510 | F1=0.469 | AUC=0.695 | Time=29.17s\n","Epoch 077 | Loss=0.9247 | TestAcc=0.503 | F1=0.492 | AUC=0.693 | Time=29.61s\n","Epoch 078 | Loss=0.9132 | TestAcc=0.517 | F1=0.490 | AUC=0.710 | Time=30.17s\n","Epoch 079 | Loss=0.9509 | TestAcc=0.507 | F1=0.481 | AUC=0.694 | Time=30.55s\n","Epoch 080 | Loss=0.9283 | TestAcc=0.530 | F1=0.513 | AUC=0.706 | Time=30.90s\n","Epoch 081 | Loss=0.9273 | TestAcc=0.493 | F1=0.465 | AUC=0.689 | Time=31.26s\n","Epoch 082 | Loss=0.9550 | TestAcc=0.510 | F1=0.477 | AUC=0.685 | Time=31.61s\n","Epoch 083 | Loss=0.9217 | TestAcc=0.483 | F1=0.479 | AUC=0.649 | Time=31.96s\n","Epoch 084 | Loss=0.9470 | TestAcc=0.503 | F1=0.463 | AUC=0.682 | Time=32.32s\n","Epoch 085 | Loss=0.9439 | TestAcc=0.513 | F1=0.465 | AUC=0.694 | Time=32.67s\n","Epoch 086 | Loss=0.9501 | TestAcc=0.510 | F1=0.491 | AUC=0.710 | Time=33.03s\n","Epoch 087 | Loss=0.9392 | TestAcc=0.523 | F1=0.500 | AUC=0.721 | Time=33.38s\n","Epoch 088 | Loss=0.9607 | TestAcc=0.487 | F1=0.481 | AUC=0.696 | Time=33.73s\n","Epoch 089 | Loss=0.9433 | TestAcc=0.460 | F1=0.459 | AUC=0.686 | Time=34.32s\n","Epoch 090 | Loss=0.9335 | TestAcc=0.523 | F1=0.516 | AUC=0.701 | Time=34.93s\n","Epoch 091 | Loss=0.9424 | TestAcc=0.510 | F1=0.469 | AUC=0.715 | Time=35.73s\n","Epoch 092 | Loss=0.9200 | TestAcc=0.520 | F1=0.487 | AUC=0.705 | Time=36.18s\n","Epoch 093 | Loss=0.9321 | TestAcc=0.497 | F1=0.497 | AUC=0.677 | Time=36.54s\n","Epoch 094 | Loss=0.9392 | TestAcc=0.473 | F1=0.468 | AUC=0.663 | Time=36.88s\n","Epoch 095 | Loss=0.9356 | TestAcc=0.473 | F1=0.440 | AUC=0.682 | Time=37.22s\n","Epoch 096 | Loss=0.9835 | TestAcc=0.480 | F1=0.477 | AUC=0.673 | Time=37.57s\n","Epoch 097 | Loss=0.9457 | TestAcc=0.423 | F1=0.335 | AUC=0.661 | Time=37.91s\n","Epoch 098 | Loss=0.9630 | TestAcc=0.513 | F1=0.486 | AUC=0.710 | Time=38.25s\n","Epoch 099 | Loss=0.9501 | TestAcc=0.547 | F1=0.535 | AUC=0.727 | Time=38.63s\n","Epoch 100 | Loss=0.9458 | TestAcc=0.483 | F1=0.446 | AUC=0.712 | Time=38.99s\n","Epoch 101 | Loss=0.9128 | TestAcc=0.493 | F1=0.484 | AUC=0.686 | Time=39.33s\n","Epoch 102 | Loss=0.9375 | TestAcc=0.520 | F1=0.469 | AUC=0.713 | Time=39.69s\n","Epoch 103 | Loss=0.9467 | TestAcc=0.510 | F1=0.479 | AUC=0.702 | Time=40.05s\n","Epoch 104 | Loss=0.9621 | TestAcc=0.503 | F1=0.488 | AUC=0.721 | Time=40.48s\n","Epoch 105 | Loss=0.9458 | TestAcc=0.497 | F1=0.482 | AUC=0.703 | Time=40.96s\n","Epoch 106 | Loss=0.9481 | TestAcc=0.487 | F1=0.452 | AUC=0.683 | Time=41.43s\n","Epoch 107 | Loss=0.9507 | TestAcc=0.507 | F1=0.490 | AUC=0.687 | Time=41.92s\n","Epoch 108 | Loss=0.9380 | TestAcc=0.493 | F1=0.456 | AUC=0.712 | Time=42.37s\n","Epoch 109 | Loss=0.9397 | TestAcc=0.533 | F1=0.527 | AUC=0.713 | Time=42.87s\n","Epoch 110 | Loss=0.9422 | TestAcc=0.517 | F1=0.504 | AUC=0.701 | Time=43.40s\n","Epoch 111 | Loss=0.9366 | TestAcc=0.543 | F1=0.532 | AUC=0.720 | Time=43.76s\n","Epoch 112 | Loss=0.9304 | TestAcc=0.503 | F1=0.480 | AUC=0.704 | Time=44.10s\n","Epoch 113 | Loss=0.9450 | TestAcc=0.493 | F1=0.494 | AUC=0.659 | Time=44.45s\n","Epoch 114 | Loss=0.9458 | TestAcc=0.500 | F1=0.485 | AUC=0.699 | Time=44.84s\n","Epoch 115 | Loss=0.9410 | TestAcc=0.537 | F1=0.525 | AUC=0.703 | Time=45.19s\n","Epoch 116 | Loss=0.9212 | TestAcc=0.487 | F1=0.470 | AUC=0.680 | Time=45.56s\n","Epoch 117 | Loss=0.9369 | TestAcc=0.513 | F1=0.507 | AUC=0.680 | Time=45.92s\n","Epoch 118 | Loss=0.9263 | TestAcc=0.483 | F1=0.447 | AUC=0.678 | Time=46.28s\n","Epoch 119 | Loss=0.9573 | TestAcc=0.477 | F1=0.467 | AUC=0.664 | Time=46.63s\n","Epoch 120 | Loss=0.9939 | TestAcc=0.493 | F1=0.481 | AUC=0.679 | Time=46.99s\n","Epoch 121 | Loss=0.9800 | TestAcc=0.507 | F1=0.464 | AUC=0.677 | Time=47.33s\n","Epoch 122 | Loss=0.9819 | TestAcc=0.440 | F1=0.396 | AUC=0.686 | Time=47.68s\n","Epoch 123 | Loss=0.9591 | TestAcc=0.523 | F1=0.500 | AUC=0.688 | Time=48.04s\n","Epoch 124 | Loss=0.9593 | TestAcc=0.513 | F1=0.454 | AUC=0.665 | Time=48.39s\n","Epoch 125 | Loss=0.9498 | TestAcc=0.510 | F1=0.489 | AUC=0.693 | Time=48.75s\n","Epoch 126 | Loss=0.9397 | TestAcc=0.430 | F1=0.434 | AUC=0.675 | Time=49.11s\n","Epoch 127 | Loss=0.9435 | TestAcc=0.500 | F1=0.475 | AUC=0.666 | Time=49.45s\n","Epoch 128 | Loss=0.9488 | TestAcc=0.527 | F1=0.499 | AUC=0.711 | Time=49.80s\n","Epoch 129 | Loss=0.9196 | TestAcc=0.450 | F1=0.426 | AUC=0.694 | Time=50.16s\n","Epoch 130 | Loss=0.9276 | TestAcc=0.510 | F1=0.485 | AUC=0.697 | Time=50.52s\n","Epoch 131 | Loss=0.9386 | TestAcc=0.507 | F1=0.473 | AUC=0.677 | Time=50.86s\n","Epoch 132 | Loss=0.9461 | TestAcc=0.523 | F1=0.478 | AUC=0.694 | Time=51.22s\n","Epoch 133 | Loss=0.9364 | TestAcc=0.497 | F1=0.491 | AUC=0.696 | Time=51.58s\n","Epoch 134 | Loss=0.9156 | TestAcc=0.487 | F1=0.475 | AUC=0.688 | Time=51.92s\n","Epoch 135 | Loss=0.9242 | TestAcc=0.490 | F1=0.467 | AUC=0.675 | Time=52.27s\n","Epoch 136 | Loss=0.9267 | TestAcc=0.497 | F1=0.470 | AUC=0.696 | Time=52.62s\n","Epoch 137 | Loss=0.9408 | TestAcc=0.470 | F1=0.469 | AUC=0.652 | Time=52.97s\n","Epoch 138 | Loss=0.9281 | TestAcc=0.507 | F1=0.486 | AUC=0.690 | Time=53.33s\n","Epoch 139 | Loss=0.9418 | TestAcc=0.473 | F1=0.476 | AUC=0.675 | Time=53.82s\n","Epoch 140 | Loss=0.9430 | TestAcc=0.467 | F1=0.465 | AUC=0.687 | Time=54.29s\n","Epoch 141 | Loss=0.9277 | TestAcc=0.490 | F1=0.473 | AUC=0.680 | Time=54.78s\n","Epoch 142 | Loss=0.9432 | TestAcc=0.517 | F1=0.496 | AUC=0.701 | Time=55.26s\n","Epoch 143 | Loss=0.9572 | TestAcc=0.520 | F1=0.505 | AUC=0.688 | Time=55.71s\n","Epoch 144 | Loss=0.9215 | TestAcc=0.443 | F1=0.440 | AUC=0.657 | Time=56.23s\n","Epoch 145 | Loss=0.9234 | TestAcc=0.520 | F1=0.500 | AUC=0.693 | Time=56.71s\n","Epoch 146 | Loss=0.9252 | TestAcc=0.433 | F1=0.438 | AUC=0.669 | Time=57.07s\n","Epoch 147 | Loss=0.9138 | TestAcc=0.497 | F1=0.478 | AUC=0.684 | Time=57.42s\n","Epoch 148 | Loss=0.9568 | TestAcc=0.500 | F1=0.446 | AUC=0.726 | Time=57.77s\n","Epoch 149 | Loss=0.9335 | TestAcc=0.547 | F1=0.512 | AUC=0.729 | Time=58.11s\n","Epoch 150 | Loss=0.9397 | TestAcc=0.453 | F1=0.447 | AUC=0.693 | Time=58.48s\n","Epoch 151 | Loss=0.9402 | TestAcc=0.440 | F1=0.414 | AUC=0.641 | Time=58.83s\n","Epoch 152 | Loss=0.9504 | TestAcc=0.503 | F1=0.487 | AUC=0.706 | Time=59.18s\n","Epoch 153 | Loss=0.9102 | TestAcc=0.497 | F1=0.474 | AUC=0.683 | Time=59.54s\n","Epoch 154 | Loss=0.9121 | TestAcc=0.500 | F1=0.479 | AUC=0.677 | Time=59.88s\n","Epoch 155 | Loss=0.9092 | TestAcc=0.470 | F1=0.421 | AUC=0.695 | Time=60.23s\n","Epoch 156 | Loss=0.9275 | TestAcc=0.527 | F1=0.510 | AUC=0.710 | Time=60.59s\n","Epoch 157 | Loss=0.9355 | TestAcc=0.510 | F1=0.507 | AUC=0.693 | Time=60.95s\n","Epoch 158 | Loss=0.9208 | TestAcc=0.487 | F1=0.481 | AUC=0.699 | Time=61.30s\n","Epoch 159 | Loss=0.9288 | TestAcc=0.507 | F1=0.458 | AUC=0.723 | Time=61.66s\n","Epoch 160 | Loss=0.9271 | TestAcc=0.523 | F1=0.508 | AUC=0.703 | Time=62.01s\n","Epoch 161 | Loss=0.9541 | TestAcc=0.530 | F1=0.459 | AUC=0.715 | Time=62.36s\n","Epoch 162 | Loss=0.9936 | TestAcc=0.473 | F1=0.453 | AUC=0.680 | Time=62.72s\n","Epoch 163 | Loss=0.9495 | TestAcc=0.523 | F1=0.509 | AUC=0.706 | Time=63.07s\n","Epoch 164 | Loss=0.9231 | TestAcc=0.510 | F1=0.494 | AUC=0.700 | Time=63.41s\n","Epoch 165 | Loss=0.9792 | TestAcc=0.500 | F1=0.480 | AUC=0.689 | Time=63.77s\n","Epoch 166 | Loss=0.9821 | TestAcc=0.487 | F1=0.469 | AUC=0.699 | Time=64.12s\n","Epoch 167 | Loss=0.9658 | TestAcc=0.490 | F1=0.474 | AUC=0.703 | Time=64.47s\n","Epoch 168 | Loss=0.9943 | TestAcc=0.497 | F1=0.468 | AUC=0.676 | Time=64.82s\n","Epoch 169 | Loss=0.9791 | TestAcc=0.483 | F1=0.478 | AUC=0.672 | Time=65.17s\n","Epoch 170 | Loss=0.9832 | TestAcc=0.477 | F1=0.471 | AUC=0.681 | Time=65.52s\n","Epoch 171 | Loss=1.0114 | TestAcc=0.467 | F1=0.444 | AUC=0.685 | Time=65.89s\n","Epoch 172 | Loss=0.9614 | TestAcc=0.523 | F1=0.505 | AUC=0.720 | Time=66.24s\n","Epoch 173 | Loss=0.9578 | TestAcc=0.510 | F1=0.500 | AUC=0.689 | Time=66.59s\n","Epoch 174 | Loss=0.9559 | TestAcc=0.500 | F1=0.447 | AUC=0.695 | Time=67.10s\n","Epoch 175 | Loss=0.9493 | TestAcc=0.483 | F1=0.467 | AUC=0.683 | Time=67.55s\n","Epoch 176 | Loss=0.9401 | TestAcc=0.503 | F1=0.484 | AUC=0.663 | Time=68.07s\n","Epoch 177 | Loss=0.9639 | TestAcc=0.480 | F1=0.416 | AUC=0.663 | Time=68.54s\n","Epoch 178 | Loss=0.9427 | TestAcc=0.520 | F1=0.489 | AUC=0.675 | Time=69.00s\n","Epoch 179 | Loss=0.9328 | TestAcc=0.517 | F1=0.489 | AUC=0.684 | Time=69.51s\n","Epoch 180 | Loss=0.9326 | TestAcc=0.510 | F1=0.472 | AUC=0.682 | Time=69.94s\n","Epoch 181 | Loss=0.9390 | TestAcc=0.463 | F1=0.454 | AUC=0.656 | Time=70.30s\n","Epoch 182 | Loss=0.9378 | TestAcc=0.490 | F1=0.483 | AUC=0.655 | Time=70.65s\n","Epoch 183 | Loss=0.9370 | TestAcc=0.493 | F1=0.477 | AUC=0.689 | Time=71.01s\n","Epoch 184 | Loss=0.9197 | TestAcc=0.493 | F1=0.470 | AUC=0.705 | Time=71.36s\n","Epoch 185 | Loss=0.9288 | TestAcc=0.483 | F1=0.474 | AUC=0.686 | Time=71.70s\n","Epoch 186 | Loss=0.9194 | TestAcc=0.493 | F1=0.475 | AUC=0.702 | Time=72.06s\n","Epoch 187 | Loss=0.9135 | TestAcc=0.503 | F1=0.495 | AUC=0.690 | Time=72.41s\n","Epoch 188 | Loss=0.9076 | TestAcc=0.480 | F1=0.461 | AUC=0.666 | Time=72.76s\n","Epoch 189 | Loss=0.9008 | TestAcc=0.493 | F1=0.484 | AUC=0.685 | Time=73.12s\n","Epoch 190 | Loss=0.9011 | TestAcc=0.517 | F1=0.482 | AUC=0.695 | Time=73.46s\n","Epoch 191 | Loss=0.9089 | TestAcc=0.513 | F1=0.500 | AUC=0.716 | Time=73.80s\n","Epoch 192 | Loss=0.9206 | TestAcc=0.503 | F1=0.493 | AUC=0.702 | Time=74.16s\n","Epoch 193 | Loss=0.9190 | TestAcc=0.483 | F1=0.473 | AUC=0.686 | Time=74.50s\n","Epoch 194 | Loss=0.9352 | TestAcc=0.517 | F1=0.499 | AUC=0.678 | Time=74.88s\n","Epoch 195 | Loss=0.9047 | TestAcc=0.497 | F1=0.468 | AUC=0.694 | Time=75.24s\n","Epoch 196 | Loss=0.9108 | TestAcc=0.527 | F1=0.515 | AUC=0.717 | Time=75.59s\n","Epoch 197 | Loss=0.8983 | TestAcc=0.473 | F1=0.454 | AUC=0.677 | Time=75.93s\n","Epoch 198 | Loss=0.8972 | TestAcc=0.500 | F1=0.491 | AUC=0.689 | Time=76.30s\n","Epoch 199 | Loss=0.9132 | TestAcc=0.497 | F1=0.489 | AUC=0.701 | Time=76.65s\n","Epoch 200 | Loss=0.9190 | TestAcc=0.507 | F1=0.486 | AUC=0.718 | Time=77.03s\n","\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed     dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    43  IMDB-MULTI                  yes                   64   \n","\n","  objective_weights  num_layers   dropout        lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           3  0.056432  0.008683      0.000373     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0          99     0.9475     0.9475    0.5467   0.5345    0.7269   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              77.03                21.63            1439.51  \n","Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_IMDB-MULTI_43.pth\n","Dataset has no node features. Applying OneHotDegree transform...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:39:03,281] A new study created in memory with name: no-name-0d9f1599-b179-460a-86c2-6fa7c391153e\n"]},{"output_type":"stream","name":"stdout","text":["Loaded dataset IMDB-MULTI: 1500 graphs, 89 node features, 3 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:39:06,004] Trial 0 finished with value: 0.4306182605538637 and parameters: {'num_layers': 5, 'dropout': 0.4763631702042135, 'lr': 0.0002269960719596284, 'weight_decay': 2.3180445433799735e-06}. Best is trial 0 with value: 0.4306182605538637.\n","[I 2026-01-27 17:39:08,439] Trial 1 finished with value: 0.5381627622386819 and parameters: {'num_layers': 3, 'dropout': 0.5295522006031206, 'lr': 0.001402970913782123, 'weight_decay': 1.6657985859816478e-05}. Best is trial 1 with value: 0.5381627622386819.\n","[I 2026-01-27 17:39:10,402] Trial 2 finished with value: 0.4835180044966748 and parameters: {'num_layers': 4, 'dropout': 0.07496566305421304, 'lr': 0.008380475116089586, 'weight_decay': 1.7625175119050873e-06}. Best is trial 1 with value: 0.5381627622386819.\n","[I 2026-01-27 17:39:12,542] Trial 3 finished with value: 0.4494693455867373 and parameters: {'num_layers': 5, 'dropout': 0.48627301764635655, 'lr': 0.0001690178788740342, 'weight_decay': 0.00039599025739748026}. Best is trial 1 with value: 0.5381627622386819.\n","[I 2026-01-27 17:39:14,491] Trial 4 finished with value: 0.5033921679705688 and parameters: {'num_layers': 4, 'dropout': 0.2914853526649851, 'lr': 0.0011078028922340774, 'weight_decay': 1.300612180069019e-06}. Best is trial 1 with value: 0.5381627622386819.\n","[I 2026-01-27 17:39:16,806] Trial 5 finished with value: 0.4666118424611306 and parameters: {'num_layers': 6, 'dropout': 0.5784016360893833, 'lr': 0.0036129335388196907, 'weight_decay': 1.5482071331927722e-06}. Best is trial 1 with value: 0.5381627622386819.\n","[I 2026-01-27 17:39:18,904] Trial 6 finished with value: 0.4184457061713205 and parameters: {'num_layers': 4, 'dropout': 0.4473326163142868, 'lr': 0.00011882393557935961, 'weight_decay': 4.362187235784385e-05}. Best is trial 1 with value: 0.5381627622386819.\n","[I 2026-01-27 17:39:21,337] Trial 7 finished with value: 0.4309511611854896 and parameters: {'num_layers': 3, 'dropout': 0.28740128233876316, 'lr': 0.004190235703312603, 'weight_decay': 0.0002590344331948222}. Best is trial 1 with value: 0.5381627622386819.\n","[I 2026-01-27 17:39:23,400] Trial 8 finished with value: 0.4855865680903678 and parameters: {'num_layers': 3, 'dropout': 0.09089360368697282, 'lr': 0.00027839386672055474, 'weight_decay': 0.00015830382170142627}. Best is trial 1 with value: 0.5381627622386819.\n","[I 2026-01-27 17:39:25,532] Trial 9 finished with value: 0.45576299481280685 and parameters: {'num_layers': 5, 'dropout': 0.3971314494995338, 'lr': 0.0017068557222336496, 'weight_decay': 1.2323163066685185e-06}. Best is trial 1 with value: 0.5381627622386819.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 3, 'dropout': 0.5295522006031206, 'lr': 0.001402970913782123, 'weight_decay': 1.6657985859816478e-05}\n","\n","Running final training GIN...\n","{'num_layers': 3, 'dropout': 0.5295522006031206, 'lr': 0.001402970913782123, 'weight_decay': 1.6657985859816478e-05}\n","Epoch 001 | Loss=2.1836 | TestAcc=0.413 | F1=0.323 | AUC=0.683 | Time=0.36s\n","Epoch 002 | Loss=1.6860 | TestAcc=0.477 | F1=0.467 | AUC=0.647 | Time=0.70s\n","Epoch 003 | Loss=1.4860 | TestAcc=0.503 | F1=0.503 | AUC=0.686 | Time=1.07s\n","Epoch 004 | Loss=1.2259 | TestAcc=0.473 | F1=0.450 | AUC=0.670 | Time=1.43s\n","Epoch 005 | Loss=1.1583 | TestAcc=0.500 | F1=0.489 | AUC=0.691 | Time=1.77s\n","Epoch 006 | Loss=1.1131 | TestAcc=0.483 | F1=0.471 | AUC=0.667 | Time=2.13s\n","Epoch 007 | Loss=1.0683 | TestAcc=0.487 | F1=0.481 | AUC=0.689 | Time=2.48s\n","Epoch 008 | Loss=1.0422 | TestAcc=0.480 | F1=0.447 | AUC=0.673 | Time=2.84s\n","Epoch 009 | Loss=1.0608 | TestAcc=0.477 | F1=0.429 | AUC=0.676 | Time=3.21s\n","Epoch 010 | Loss=0.9960 | TestAcc=0.503 | F1=0.495 | AUC=0.685 | Time=3.57s\n","Epoch 011 | Loss=1.0097 | TestAcc=0.487 | F1=0.439 | AUC=0.682 | Time=3.94s\n","Epoch 012 | Loss=1.0006 | TestAcc=0.463 | F1=0.421 | AUC=0.666 | Time=4.29s\n","Epoch 013 | Loss=1.0102 | TestAcc=0.477 | F1=0.460 | AUC=0.685 | Time=4.65s\n","Epoch 014 | Loss=0.9802 | TestAcc=0.493 | F1=0.486 | AUC=0.682 | Time=5.05s\n","Epoch 015 | Loss=0.9753 | TestAcc=0.513 | F1=0.509 | AUC=0.687 | Time=5.41s\n","Epoch 016 | Loss=0.9804 | TestAcc=0.483 | F1=0.437 | AUC=0.675 | Time=5.77s\n","Epoch 017 | Loss=0.9906 | TestAcc=0.467 | F1=0.433 | AUC=0.688 | Time=6.28s\n","Epoch 018 | Loss=0.9633 | TestAcc=0.487 | F1=0.482 | AUC=0.687 | Time=6.74s\n","Epoch 019 | Loss=0.9772 | TestAcc=0.487 | F1=0.475 | AUC=0.681 | Time=7.27s\n","Epoch 020 | Loss=0.9907 | TestAcc=0.477 | F1=0.470 | AUC=0.670 | Time=7.75s\n","Epoch 021 | Loss=0.9731 | TestAcc=0.463 | F1=0.444 | AUC=0.679 | Time=8.24s\n","Epoch 022 | Loss=0.9552 | TestAcc=0.460 | F1=0.428 | AUC=0.672 | Time=8.75s\n","Epoch 023 | Loss=0.9721 | TestAcc=0.467 | F1=0.454 | AUC=0.682 | Time=9.25s\n","Epoch 024 | Loss=0.9601 | TestAcc=0.463 | F1=0.464 | AUC=0.677 | Time=9.60s\n","Epoch 025 | Loss=0.9533 | TestAcc=0.480 | F1=0.469 | AUC=0.682 | Time=9.96s\n","Epoch 026 | Loss=0.9509 | TestAcc=0.463 | F1=0.451 | AUC=0.678 | Time=10.33s\n","Epoch 027 | Loss=0.9427 | TestAcc=0.500 | F1=0.496 | AUC=0.704 | Time=10.69s\n","Epoch 028 | Loss=0.9635 | TestAcc=0.477 | F1=0.460 | AUC=0.693 | Time=11.04s\n","Epoch 029 | Loss=0.9404 | TestAcc=0.507 | F1=0.504 | AUC=0.691 | Time=11.41s\n","Epoch 030 | Loss=0.9511 | TestAcc=0.470 | F1=0.439 | AUC=0.702 | Time=11.78s\n","Epoch 031 | Loss=0.9417 | TestAcc=0.477 | F1=0.450 | AUC=0.690 | Time=12.13s\n","Epoch 032 | Loss=0.9318 | TestAcc=0.477 | F1=0.463 | AUC=0.699 | Time=12.49s\n","Epoch 033 | Loss=0.9554 | TestAcc=0.503 | F1=0.500 | AUC=0.693 | Time=12.85s\n","Epoch 034 | Loss=0.9340 | TestAcc=0.473 | F1=0.462 | AUC=0.695 | Time=13.20s\n","Epoch 035 | Loss=0.9278 | TestAcc=0.490 | F1=0.473 | AUC=0.693 | Time=13.56s\n","Epoch 036 | Loss=0.9329 | TestAcc=0.490 | F1=0.482 | AUC=0.695 | Time=13.92s\n","Epoch 037 | Loss=0.9392 | TestAcc=0.483 | F1=0.474 | AUC=0.690 | Time=14.28s\n","Epoch 038 | Loss=0.9242 | TestAcc=0.480 | F1=0.468 | AUC=0.699 | Time=14.65s\n","Epoch 039 | Loss=0.9292 | TestAcc=0.500 | F1=0.492 | AUC=0.689 | Time=15.00s\n","Epoch 040 | Loss=0.9350 | TestAcc=0.483 | F1=0.452 | AUC=0.695 | Time=15.36s\n","Epoch 041 | Loss=0.9348 | TestAcc=0.457 | F1=0.452 | AUC=0.681 | Time=15.73s\n","Epoch 042 | Loss=0.9105 | TestAcc=0.507 | F1=0.502 | AUC=0.695 | Time=16.09s\n","Epoch 043 | Loss=0.9416 | TestAcc=0.517 | F1=0.505 | AUC=0.698 | Time=16.46s\n","Epoch 044 | Loss=0.9207 | TestAcc=0.477 | F1=0.460 | AUC=0.683 | Time=16.81s\n","Epoch 045 | Loss=0.9190 | TestAcc=0.457 | F1=0.444 | AUC=0.654 | Time=17.17s\n","Epoch 046 | Loss=0.9378 | TestAcc=0.483 | F1=0.474 | AUC=0.674 | Time=17.53s\n","Epoch 047 | Loss=0.9164 | TestAcc=0.473 | F1=0.426 | AUC=0.673 | Time=17.88s\n","Epoch 048 | Loss=0.8980 | TestAcc=0.457 | F1=0.443 | AUC=0.683 | Time=18.23s\n","Epoch 049 | Loss=0.9210 | TestAcc=0.483 | F1=0.472 | AUC=0.678 | Time=18.59s\n","Epoch 050 | Loss=0.9217 | TestAcc=0.460 | F1=0.435 | AUC=0.683 | Time=18.94s\n","Epoch 051 | Loss=0.9103 | TestAcc=0.477 | F1=0.451 | AUC=0.688 | Time=19.40s\n","Epoch 052 | Loss=0.8948 | TestAcc=0.467 | F1=0.436 | AUC=0.675 | Time=19.88s\n","Epoch 053 | Loss=0.9304 | TestAcc=0.480 | F1=0.470 | AUC=0.675 | Time=20.38s\n","Epoch 054 | Loss=0.9164 | TestAcc=0.460 | F1=0.452 | AUC=0.664 | Time=20.87s\n","Epoch 055 | Loss=0.9035 | TestAcc=0.460 | F1=0.440 | AUC=0.670 | Time=21.33s\n","Epoch 056 | Loss=0.9121 | TestAcc=0.480 | F1=0.472 | AUC=0.688 | Time=21.82s\n","Epoch 057 | Loss=0.9228 | TestAcc=0.473 | F1=0.462 | AUC=0.663 | Time=22.34s\n","Epoch 058 | Loss=0.9124 | TestAcc=0.480 | F1=0.462 | AUC=0.671 | Time=22.69s\n","Epoch 059 | Loss=0.9549 | TestAcc=0.430 | F1=0.418 | AUC=0.674 | Time=23.05s\n","Epoch 060 | Loss=0.9460 | TestAcc=0.477 | F1=0.459 | AUC=0.672 | Time=23.39s\n","Epoch 061 | Loss=0.9295 | TestAcc=0.473 | F1=0.444 | AUC=0.662 | Time=23.74s\n","Epoch 062 | Loss=0.9286 | TestAcc=0.493 | F1=0.478 | AUC=0.683 | Time=24.11s\n","Epoch 063 | Loss=0.9159 | TestAcc=0.460 | F1=0.428 | AUC=0.662 | Time=24.47s\n","Epoch 064 | Loss=0.9498 | TestAcc=0.477 | F1=0.448 | AUC=0.678 | Time=24.81s\n","Epoch 065 | Loss=0.9471 | TestAcc=0.470 | F1=0.440 | AUC=0.681 | Time=25.17s\n","Epoch 066 | Loss=0.9437 | TestAcc=0.460 | F1=0.421 | AUC=0.652 | Time=25.53s\n","Epoch 067 | Loss=0.9243 | TestAcc=0.487 | F1=0.476 | AUC=0.666 | Time=25.90s\n","Epoch 068 | Loss=0.9255 | TestAcc=0.390 | F1=0.377 | AUC=0.662 | Time=26.25s\n","Epoch 069 | Loss=0.9115 | TestAcc=0.500 | F1=0.498 | AUC=0.688 | Time=26.60s\n","Epoch 070 | Loss=0.9267 | TestAcc=0.513 | F1=0.506 | AUC=0.670 | Time=26.96s\n","Epoch 071 | Loss=0.8990 | TestAcc=0.500 | F1=0.490 | AUC=0.670 | Time=27.30s\n","Epoch 072 | Loss=0.9184 | TestAcc=0.493 | F1=0.477 | AUC=0.678 | Time=27.66s\n","Epoch 073 | Loss=0.9024 | TestAcc=0.460 | F1=0.440 | AUC=0.673 | Time=28.02s\n","Epoch 074 | Loss=0.8984 | TestAcc=0.487 | F1=0.448 | AUC=0.679 | Time=28.39s\n","Epoch 075 | Loss=0.9093 | TestAcc=0.483 | F1=0.468 | AUC=0.679 | Time=28.76s\n","Epoch 076 | Loss=0.8871 | TestAcc=0.470 | F1=0.451 | AUC=0.654 | Time=29.11s\n","Epoch 077 | Loss=0.9307 | TestAcc=0.463 | F1=0.456 | AUC=0.669 | Time=29.45s\n","Epoch 078 | Loss=0.8916 | TestAcc=0.493 | F1=0.484 | AUC=0.675 | Time=29.80s\n","Epoch 079 | Loss=0.8925 | TestAcc=0.497 | F1=0.483 | AUC=0.670 | Time=30.19s\n","Epoch 080 | Loss=0.8913 | TestAcc=0.483 | F1=0.451 | AUC=0.677 | Time=30.53s\n","Epoch 081 | Loss=0.8943 | TestAcc=0.500 | F1=0.483 | AUC=0.673 | Time=30.88s\n","Epoch 082 | Loss=0.8789 | TestAcc=0.473 | F1=0.456 | AUC=0.662 | Time=31.24s\n","Epoch 083 | Loss=0.8794 | TestAcc=0.473 | F1=0.447 | AUC=0.663 | Time=31.60s\n","Epoch 084 | Loss=0.9079 | TestAcc=0.483 | F1=0.469 | AUC=0.660 | Time=31.95s\n","Epoch 085 | Loss=0.9053 | TestAcc=0.487 | F1=0.480 | AUC=0.683 | Time=32.33s\n","Epoch 086 | Loss=0.8844 | TestAcc=0.503 | F1=0.488 | AUC=0.685 | Time=32.81s\n","Epoch 087 | Loss=0.8602 | TestAcc=0.487 | F1=0.468 | AUC=0.677 | Time=33.28s\n","Epoch 088 | Loss=0.8802 | TestAcc=0.500 | F1=0.473 | AUC=0.660 | Time=33.78s\n","Epoch 089 | Loss=0.8876 | TestAcc=0.487 | F1=0.474 | AUC=0.664 | Time=34.26s\n","Epoch 090 | Loss=0.8807 | TestAcc=0.493 | F1=0.468 | AUC=0.662 | Time=34.71s\n","Epoch 091 | Loss=0.8815 | TestAcc=0.490 | F1=0.480 | AUC=0.664 | Time=35.28s\n","Epoch 092 | Loss=0.8718 | TestAcc=0.473 | F1=0.460 | AUC=0.652 | Time=35.70s\n","Epoch 093 | Loss=0.8888 | TestAcc=0.480 | F1=0.467 | AUC=0.667 | Time=36.05s\n","Epoch 094 | Loss=0.8945 | TestAcc=0.490 | F1=0.477 | AUC=0.662 | Time=36.41s\n","Epoch 095 | Loss=0.9236 | TestAcc=0.483 | F1=0.475 | AUC=0.658 | Time=36.76s\n","Epoch 096 | Loss=0.9117 | TestAcc=0.483 | F1=0.475 | AUC=0.654 | Time=37.15s\n","Epoch 097 | Loss=0.9141 | TestAcc=0.437 | F1=0.436 | AUC=0.646 | Time=37.53s\n","Epoch 098 | Loss=0.8979 | TestAcc=0.477 | F1=0.465 | AUC=0.661 | Time=37.88s\n","Epoch 099 | Loss=0.9053 | TestAcc=0.493 | F1=0.479 | AUC=0.672 | Time=38.23s\n","Epoch 100 | Loss=0.8721 | TestAcc=0.443 | F1=0.422 | AUC=0.631 | Time=38.60s\n","Epoch 101 | Loss=0.9193 | TestAcc=0.507 | F1=0.492 | AUC=0.668 | Time=38.94s\n","Epoch 102 | Loss=0.8920 | TestAcc=0.473 | F1=0.462 | AUC=0.666 | Time=39.29s\n","Epoch 103 | Loss=0.8915 | TestAcc=0.467 | F1=0.451 | AUC=0.657 | Time=39.66s\n","Epoch 104 | Loss=0.8886 | TestAcc=0.483 | F1=0.479 | AUC=0.663 | Time=40.01s\n","Epoch 105 | Loss=0.8729 | TestAcc=0.517 | F1=0.500 | AUC=0.690 | Time=40.36s\n","Epoch 106 | Loss=0.8550 | TestAcc=0.487 | F1=0.481 | AUC=0.671 | Time=40.72s\n","Epoch 107 | Loss=0.8957 | TestAcc=0.437 | F1=0.430 | AUC=0.666 | Time=41.06s\n","Epoch 108 | Loss=0.8856 | TestAcc=0.423 | F1=0.423 | AUC=0.654 | Time=41.41s\n","Epoch 109 | Loss=0.8786 | TestAcc=0.473 | F1=0.453 | AUC=0.666 | Time=41.78s\n","Epoch 110 | Loss=0.8698 | TestAcc=0.483 | F1=0.470 | AUC=0.661 | Time=42.12s\n","Epoch 111 | Loss=0.8726 | TestAcc=0.450 | F1=0.416 | AUC=0.653 | Time=42.48s\n","Epoch 112 | Loss=0.9071 | TestAcc=0.477 | F1=0.456 | AUC=0.674 | Time=42.84s\n","Epoch 113 | Loss=0.8696 | TestAcc=0.490 | F1=0.483 | AUC=0.669 | Time=43.18s\n","Epoch 114 | Loss=0.9043 | TestAcc=0.500 | F1=0.494 | AUC=0.676 | Time=43.53s\n","Epoch 115 | Loss=0.8922 | TestAcc=0.493 | F1=0.485 | AUC=0.673 | Time=43.89s\n","Epoch 116 | Loss=0.8865 | TestAcc=0.497 | F1=0.490 | AUC=0.678 | Time=44.24s\n","Epoch 117 | Loss=0.8690 | TestAcc=0.507 | F1=0.500 | AUC=0.670 | Time=44.60s\n","Epoch 118 | Loss=0.8526 | TestAcc=0.467 | F1=0.455 | AUC=0.667 | Time=44.95s\n","Epoch 119 | Loss=0.8450 | TestAcc=0.473 | F1=0.462 | AUC=0.650 | Time=45.31s\n","Epoch 120 | Loss=0.8743 | TestAcc=0.493 | F1=0.482 | AUC=0.668 | Time=45.79s\n","Epoch 121 | Loss=0.8674 | TestAcc=0.483 | F1=0.476 | AUC=0.678 | Time=46.26s\n","Epoch 122 | Loss=0.8688 | TestAcc=0.487 | F1=0.483 | AUC=0.677 | Time=46.76s\n","Epoch 123 | Loss=0.8602 | TestAcc=0.487 | F1=0.462 | AUC=0.658 | Time=47.24s\n","Epoch 124 | Loss=0.8561 | TestAcc=0.473 | F1=0.452 | AUC=0.663 | Time=47.70s\n","Epoch 125 | Loss=0.8457 | TestAcc=0.483 | F1=0.466 | AUC=0.661 | Time=48.21s\n","Epoch 126 | Loss=0.8909 | TestAcc=0.473 | F1=0.454 | AUC=0.650 | Time=48.73s\n","Epoch 127 | Loss=0.8726 | TestAcc=0.460 | F1=0.448 | AUC=0.668 | Time=49.09s\n","Epoch 128 | Loss=0.8589 | TestAcc=0.483 | F1=0.470 | AUC=0.660 | Time=49.44s\n","Epoch 129 | Loss=0.8342 | TestAcc=0.460 | F1=0.435 | AUC=0.658 | Time=49.80s\n","Epoch 130 | Loss=0.8324 | TestAcc=0.483 | F1=0.455 | AUC=0.659 | Time=50.16s\n","Epoch 131 | Loss=0.8582 | TestAcc=0.473 | F1=0.442 | AUC=0.654 | Time=50.50s\n","Epoch 132 | Loss=0.8627 | TestAcc=0.470 | F1=0.445 | AUC=0.671 | Time=50.85s\n","Epoch 133 | Loss=0.8877 | TestAcc=0.477 | F1=0.461 | AUC=0.654 | Time=51.21s\n","Epoch 134 | Loss=0.8554 | TestAcc=0.490 | F1=0.468 | AUC=0.663 | Time=51.55s\n","Epoch 135 | Loss=0.8775 | TestAcc=0.490 | F1=0.478 | AUC=0.671 | Time=51.90s\n","Epoch 136 | Loss=0.8552 | TestAcc=0.470 | F1=0.456 | AUC=0.671 | Time=52.26s\n","Epoch 137 | Loss=0.8368 | TestAcc=0.443 | F1=0.439 | AUC=0.654 | Time=52.62s\n","Epoch 138 | Loss=0.8553 | TestAcc=0.463 | F1=0.454 | AUC=0.647 | Time=52.98s\n","Epoch 139 | Loss=0.8595 | TestAcc=0.493 | F1=0.476 | AUC=0.667 | Time=53.33s\n","Epoch 140 | Loss=0.8491 | TestAcc=0.487 | F1=0.477 | AUC=0.656 | Time=53.68s\n","Epoch 141 | Loss=0.8505 | TestAcc=0.493 | F1=0.484 | AUC=0.662 | Time=54.04s\n","Epoch 142 | Loss=0.8837 | TestAcc=0.463 | F1=0.447 | AUC=0.642 | Time=54.39s\n","Epoch 143 | Loss=0.8677 | TestAcc=0.473 | F1=0.467 | AUC=0.660 | Time=54.73s\n","Epoch 144 | Loss=0.8499 | TestAcc=0.410 | F1=0.392 | AUC=0.640 | Time=55.09s\n","Epoch 145 | Loss=0.8468 | TestAcc=0.463 | F1=0.460 | AUC=0.667 | Time=55.44s\n","Epoch 146 | Loss=0.8456 | TestAcc=0.467 | F1=0.455 | AUC=0.645 | Time=55.78s\n","Epoch 147 | Loss=0.8665 | TestAcc=0.467 | F1=0.446 | AUC=0.641 | Time=56.15s\n","Epoch 148 | Loss=0.8884 | TestAcc=0.503 | F1=0.494 | AUC=0.679 | Time=56.50s\n","Epoch 149 | Loss=0.8818 | TestAcc=0.480 | F1=0.475 | AUC=0.651 | Time=56.83s\n","Epoch 150 | Loss=0.8487 | TestAcc=0.473 | F1=0.456 | AUC=0.652 | Time=57.18s\n","Epoch 151 | Loss=0.8572 | TestAcc=0.490 | F1=0.484 | AUC=0.658 | Time=57.52s\n","Epoch 152 | Loss=0.8552 | TestAcc=0.467 | F1=0.450 | AUC=0.663 | Time=57.87s\n","Epoch 153 | Loss=0.8680 | TestAcc=0.490 | F1=0.474 | AUC=0.663 | Time=58.26s\n","Epoch 154 | Loss=0.8413 | TestAcc=0.493 | F1=0.487 | AUC=0.677 | Time=58.61s\n","Epoch 155 | Loss=0.8605 | TestAcc=0.463 | F1=0.455 | AUC=0.657 | Time=59.09s\n","Epoch 156 | Loss=0.8557 | TestAcc=0.467 | F1=0.447 | AUC=0.665 | Time=59.55s\n","Epoch 157 | Loss=0.8621 | TestAcc=0.430 | F1=0.418 | AUC=0.680 | Time=60.05s\n","Epoch 158 | Loss=0.8400 | TestAcc=0.467 | F1=0.441 | AUC=0.657 | Time=60.54s\n","Epoch 159 | Loss=0.8462 | TestAcc=0.467 | F1=0.441 | AUC=0.664 | Time=60.99s\n","Epoch 160 | Loss=0.8458 | TestAcc=0.467 | F1=0.453 | AUC=0.647 | Time=61.51s\n","Epoch 161 | Loss=0.8356 | TestAcc=0.457 | F1=0.442 | AUC=0.650 | Time=61.97s\n","Epoch 162 | Loss=0.8471 | TestAcc=0.500 | F1=0.490 | AUC=0.668 | Time=62.32s\n","Epoch 163 | Loss=0.8603 | TestAcc=0.483 | F1=0.469 | AUC=0.663 | Time=62.68s\n","Epoch 164 | Loss=0.8475 | TestAcc=0.497 | F1=0.489 | AUC=0.670 | Time=63.02s\n","Epoch 165 | Loss=0.8336 | TestAcc=0.487 | F1=0.471 | AUC=0.674 | Time=63.37s\n","Epoch 166 | Loss=0.8240 | TestAcc=0.470 | F1=0.453 | AUC=0.660 | Time=63.74s\n","Epoch 167 | Loss=0.8683 | TestAcc=0.467 | F1=0.458 | AUC=0.644 | Time=64.09s\n","Epoch 168 | Loss=0.8428 | TestAcc=0.497 | F1=0.480 | AUC=0.653 | Time=64.48s\n","Epoch 169 | Loss=0.8452 | TestAcc=0.473 | F1=0.462 | AUC=0.661 | Time=64.85s\n","Epoch 170 | Loss=0.8359 | TestAcc=0.507 | F1=0.497 | AUC=0.667 | Time=65.19s\n","Epoch 171 | Loss=0.8580 | TestAcc=0.473 | F1=0.447 | AUC=0.672 | Time=65.57s\n","Epoch 172 | Loss=0.8465 | TestAcc=0.490 | F1=0.467 | AUC=0.656 | Time=65.93s\n","Epoch 173 | Loss=0.8618 | TestAcc=0.493 | F1=0.473 | AUC=0.650 | Time=66.29s\n","Epoch 174 | Loss=0.8478 | TestAcc=0.483 | F1=0.476 | AUC=0.667 | Time=66.68s\n","Epoch 175 | Loss=0.8478 | TestAcc=0.480 | F1=0.450 | AUC=0.654 | Time=67.04s\n","Epoch 176 | Loss=0.8597 | TestAcc=0.460 | F1=0.444 | AUC=0.638 | Time=67.41s\n","Epoch 177 | Loss=0.8345 | TestAcc=0.473 | F1=0.463 | AUC=0.665 | Time=67.79s\n","Epoch 178 | Loss=0.8524 | TestAcc=0.470 | F1=0.460 | AUC=0.651 | Time=68.15s\n","Epoch 179 | Loss=0.8387 | TestAcc=0.480 | F1=0.465 | AUC=0.663 | Time=68.52s\n","Epoch 180 | Loss=0.8441 | TestAcc=0.483 | F1=0.462 | AUC=0.651 | Time=68.89s\n","Epoch 181 | Loss=0.8786 | TestAcc=0.477 | F1=0.462 | AUC=0.673 | Time=69.23s\n","Epoch 182 | Loss=0.8632 | TestAcc=0.467 | F1=0.443 | AUC=0.647 | Time=69.59s\n","Epoch 183 | Loss=0.8276 | TestAcc=0.473 | F1=0.463 | AUC=0.665 | Time=69.96s\n","Epoch 184 | Loss=0.8275 | TestAcc=0.490 | F1=0.481 | AUC=0.681 | Time=70.32s\n","Epoch 185 | Loss=0.8281 | TestAcc=0.473 | F1=0.451 | AUC=0.650 | Time=70.67s\n","Epoch 186 | Loss=0.8600 | TestAcc=0.500 | F1=0.480 | AUC=0.677 | Time=71.06s\n","Epoch 187 | Loss=0.8266 | TestAcc=0.473 | F1=0.462 | AUC=0.652 | Time=71.42s\n","Epoch 188 | Loss=0.8363 | TestAcc=0.470 | F1=0.459 | AUC=0.655 | Time=71.80s\n","Epoch 189 | Loss=0.8695 | TestAcc=0.423 | F1=0.420 | AUC=0.647 | Time=72.32s\n","Epoch 190 | Loss=0.8310 | TestAcc=0.483 | F1=0.463 | AUC=0.669 | Time=72.79s\n","Epoch 191 | Loss=0.8384 | TestAcc=0.480 | F1=0.463 | AUC=0.659 | Time=73.32s\n","Epoch 192 | Loss=0.8294 | TestAcc=0.480 | F1=0.455 | AUC=0.668 | Time=73.78s\n","Epoch 193 | Loss=0.8480 | TestAcc=0.470 | F1=0.459 | AUC=0.664 | Time=74.26s\n","Epoch 194 | Loss=0.8326 | TestAcc=0.507 | F1=0.492 | AUC=0.676 | Time=74.81s\n","Epoch 195 | Loss=0.8216 | TestAcc=0.477 | F1=0.458 | AUC=0.654 | Time=75.30s\n","Epoch 196 | Loss=0.8251 | TestAcc=0.487 | F1=0.472 | AUC=0.668 | Time=75.67s\n","Epoch 197 | Loss=0.8263 | TestAcc=0.480 | F1=0.474 | AUC=0.667 | Time=76.05s\n","Epoch 198 | Loss=0.8409 | TestAcc=0.460 | F1=0.433 | AUC=0.640 | Time=76.41s\n","Epoch 199 | Loss=0.8351 | TestAcc=0.453 | F1=0.430 | AUC=0.639 | Time=76.76s\n","Epoch 200 | Loss=0.8197 | TestAcc=0.363 | F1=0.365 | AUC=0.594 | Time=77.13s\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:40:43,316] A new study created in memory with name: no-name-cb13f198-5b92-4ab5-a0c2-df56d64ffe11\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed     dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    44  IMDB-MULTI                  yes                   64   \n","\n","  objective_weights  num_layers   dropout        lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           3  0.529552  0.001403      0.000017     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0          43     0.9866     0.9866    0.5167   0.5053    0.6976   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              77.13                22.25            1439.54  \n","Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_IMDB-MULTI_44.pth\n","Loaded dataset ENZYMES: 600 graphs, 3 node features, 6 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:40:43,898] Trial 0 finished with value: 0.4199344509413244 and parameters: {'num_layers': 3, 'dropout': 0.4563099640429195, 'lr': 0.0002369663745664236, 'weight_decay': 1.743115535469026e-06}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:44,655] Trial 1 finished with value: 0.2960375728009135 and parameters: {'num_layers': 6, 'dropout': 0.03402302916868094, 'lr': 0.00040852628267223657, 'weight_decay': 3.6067791832750497e-06}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:45,420] Trial 2 finished with value: 0.3253178476619162 and parameters: {'num_layers': 6, 'dropout': 0.47528987901045194, 'lr': 0.0017429046280163054, 'weight_decay': 0.0002496555959941857}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:46,098] Trial 3 finished with value: 0.31223354436626766 and parameters: {'num_layers': 5, 'dropout': 0.4472487973925237, 'lr': 0.009734329664710882, 'weight_decay': 7.344675573906255e-06}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:46,683] Trial 4 finished with value: 0.3787094858532223 and parameters: {'num_layers': 4, 'dropout': 0.41700515101887076, 'lr': 0.0010674009442593762, 'weight_decay': 1.1196759542655981e-05}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:47,365] Trial 5 finished with value: 0.29508157357078074 and parameters: {'num_layers': 5, 'dropout': 0.19174172143805915, 'lr': 0.002424791371206927, 'weight_decay': 0.0008858604203789561}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:47,884] Trial 6 finished with value: 0.3160853261583741 and parameters: {'num_layers': 3, 'dropout': 0.19068270789507993, 'lr': 0.0001952007882961724, 'weight_decay': 6.043337932271067e-05}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:48,564] Trial 7 finished with value: 0.2893232379118528 and parameters: {'num_layers': 5, 'dropout': 0.27336591880274286, 'lr': 0.0003542681184563124, 'weight_decay': 0.0007129892417709087}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:49,247] Trial 8 finished with value: 0.330534363453458 and parameters: {'num_layers': 5, 'dropout': 0.4166087863059612, 'lr': 0.00013341841300970023, 'weight_decay': 1.8723251511322504e-05}. Best is trial 0 with value: 0.4199344509413244.\n","[I 2026-01-27 17:40:49,776] Trial 9 finished with value: 0.4099223890310356 and parameters: {'num_layers': 3, 'dropout': 0.11179360085063221, 'lr': 0.006261167522992893, 'weight_decay': 6.275441934554912e-05}. Best is trial 0 with value: 0.4199344509413244.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 3, 'dropout': 0.4563099640429195, 'lr': 0.0002369663745664236, 'weight_decay': 1.743115535469026e-06}\n","\n","Running final training GIN...\n","{'num_layers': 3, 'dropout': 0.4563099640429195, 'lr': 0.0002369663745664236, 'weight_decay': 1.743115535469026e-06}\n","Epoch 001 | Loss=6.2745 | TestAcc=0.200 | F1=0.081 | AUC=0.442 | Time=0.13s\n","Epoch 002 | Loss=4.5059 | TestAcc=0.208 | F1=0.120 | AUC=0.489 | Time=0.27s\n","Epoch 003 | Loss=3.7881 | TestAcc=0.242 | F1=0.188 | AUC=0.541 | Time=0.39s\n","Epoch 004 | Loss=3.8170 | TestAcc=0.250 | F1=0.220 | AUC=0.589 | Time=0.52s\n","Epoch 005 | Loss=3.1320 | TestAcc=0.267 | F1=0.265 | AUC=0.637 | Time=0.63s\n","Epoch 006 | Loss=3.2751 | TestAcc=0.308 | F1=0.290 | AUC=0.636 | Time=0.75s\n","Epoch 007 | Loss=3.0374 | TestAcc=0.300 | F1=0.277 | AUC=0.667 | Time=0.87s\n","Epoch 008 | Loss=2.9440 | TestAcc=0.325 | F1=0.313 | AUC=0.665 | Time=0.99s\n","Epoch 009 | Loss=2.7353 | TestAcc=0.317 | F1=0.307 | AUC=0.659 | Time=1.15s\n","Epoch 010 | Loss=2.5742 | TestAcc=0.333 | F1=0.335 | AUC=0.680 | Time=1.34s\n","Epoch 011 | Loss=2.2149 | TestAcc=0.325 | F1=0.318 | AUC=0.701 | Time=1.51s\n","Epoch 012 | Loss=2.4750 | TestAcc=0.308 | F1=0.297 | AUC=0.670 | Time=1.67s\n","Epoch 013 | Loss=2.3792 | TestAcc=0.350 | F1=0.328 | AUC=0.682 | Time=1.83s\n","Epoch 014 | Loss=2.2554 | TestAcc=0.350 | F1=0.328 | AUC=0.706 | Time=1.99s\n","Epoch 015 | Loss=2.2042 | TestAcc=0.367 | F1=0.357 | AUC=0.723 | Time=2.16s\n","Epoch 016 | Loss=2.1894 | TestAcc=0.375 | F1=0.357 | AUC=0.717 | Time=2.36s\n","Epoch 017 | Loss=1.9835 | TestAcc=0.367 | F1=0.364 | AUC=0.698 | Time=2.54s\n","Epoch 018 | Loss=2.0479 | TestAcc=0.375 | F1=0.369 | AUC=0.701 | Time=2.71s\n","Epoch 019 | Loss=1.9519 | TestAcc=0.358 | F1=0.347 | AUC=0.690 | Time=2.86s\n","Epoch 020 | Loss=1.9696 | TestAcc=0.342 | F1=0.341 | AUC=0.686 | Time=3.02s\n","Epoch 021 | Loss=1.9659 | TestAcc=0.300 | F1=0.292 | AUC=0.710 | Time=3.19s\n","Epoch 022 | Loss=1.8610 | TestAcc=0.400 | F1=0.392 | AUC=0.710 | Time=3.36s\n","Epoch 023 | Loss=2.0052 | TestAcc=0.375 | F1=0.377 | AUC=0.689 | Time=3.52s\n","Epoch 024 | Loss=1.8349 | TestAcc=0.342 | F1=0.337 | AUC=0.695 | Time=3.67s\n","Epoch 025 | Loss=1.8060 | TestAcc=0.317 | F1=0.315 | AUC=0.694 | Time=3.85s\n","Epoch 026 | Loss=1.7945 | TestAcc=0.375 | F1=0.369 | AUC=0.705 | Time=4.03s\n","Epoch 027 | Loss=1.7180 | TestAcc=0.383 | F1=0.380 | AUC=0.718 | Time=4.22s\n","Epoch 028 | Loss=1.7037 | TestAcc=0.308 | F1=0.299 | AUC=0.719 | Time=4.39s\n","Epoch 029 | Loss=1.7545 | TestAcc=0.358 | F1=0.352 | AUC=0.700 | Time=4.53s\n","Epoch 030 | Loss=1.6277 | TestAcc=0.367 | F1=0.370 | AUC=0.703 | Time=4.65s\n","Epoch 031 | Loss=1.5734 | TestAcc=0.367 | F1=0.365 | AUC=0.701 | Time=4.77s\n","Epoch 032 | Loss=1.6126 | TestAcc=0.358 | F1=0.351 | AUC=0.680 | Time=4.89s\n","Epoch 033 | Loss=1.5989 | TestAcc=0.375 | F1=0.370 | AUC=0.725 | Time=5.01s\n","Epoch 034 | Loss=1.5296 | TestAcc=0.400 | F1=0.401 | AUC=0.714 | Time=5.13s\n","Epoch 035 | Loss=1.6646 | TestAcc=0.392 | F1=0.376 | AUC=0.713 | Time=5.25s\n","Epoch 036 | Loss=1.5979 | TestAcc=0.417 | F1=0.412 | AUC=0.718 | Time=5.37s\n","Epoch 037 | Loss=1.5266 | TestAcc=0.367 | F1=0.359 | AUC=0.708 | Time=5.50s\n","Epoch 038 | Loss=1.5257 | TestAcc=0.358 | F1=0.354 | AUC=0.692 | Time=5.62s\n","Epoch 039 | Loss=1.6063 | TestAcc=0.392 | F1=0.383 | AUC=0.701 | Time=5.73s\n","Epoch 040 | Loss=1.5369 | TestAcc=0.392 | F1=0.378 | AUC=0.723 | Time=5.86s\n","Epoch 041 | Loss=1.4713 | TestAcc=0.367 | F1=0.365 | AUC=0.718 | Time=5.99s\n","Epoch 042 | Loss=1.5238 | TestAcc=0.333 | F1=0.338 | AUC=0.680 | Time=6.12s\n","Epoch 043 | Loss=1.5289 | TestAcc=0.342 | F1=0.346 | AUC=0.702 | Time=6.24s\n","Epoch 044 | Loss=1.5214 | TestAcc=0.325 | F1=0.312 | AUC=0.697 | Time=6.37s\n","Epoch 045 | Loss=1.4995 | TestAcc=0.375 | F1=0.357 | AUC=0.717 | Time=6.50s\n","Epoch 046 | Loss=1.4460 | TestAcc=0.417 | F1=0.416 | AUC=0.728 | Time=6.62s\n","Epoch 047 | Loss=1.4395 | TestAcc=0.392 | F1=0.387 | AUC=0.706 | Time=6.74s\n","Epoch 048 | Loss=1.3427 | TestAcc=0.408 | F1=0.411 | AUC=0.734 | Time=6.85s\n","Epoch 049 | Loss=1.4566 | TestAcc=0.317 | F1=0.311 | AUC=0.715 | Time=6.96s\n","Epoch 050 | Loss=1.5013 | TestAcc=0.408 | F1=0.396 | AUC=0.707 | Time=7.08s\n","Epoch 051 | Loss=1.4213 | TestAcc=0.442 | F1=0.432 | AUC=0.705 | Time=7.20s\n","Epoch 052 | Loss=1.3298 | TestAcc=0.400 | F1=0.399 | AUC=0.732 | Time=7.33s\n","Epoch 053 | Loss=1.3862 | TestAcc=0.375 | F1=0.366 | AUC=0.702 | Time=7.45s\n","Epoch 054 | Loss=1.3782 | TestAcc=0.375 | F1=0.372 | AUC=0.720 | Time=7.58s\n","Epoch 055 | Loss=1.4043 | TestAcc=0.383 | F1=0.387 | AUC=0.716 | Time=7.70s\n","Epoch 056 | Loss=1.2668 | TestAcc=0.425 | F1=0.421 | AUC=0.727 | Time=7.81s\n","Epoch 057 | Loss=1.3134 | TestAcc=0.392 | F1=0.393 | AUC=0.740 | Time=7.92s\n","Epoch 058 | Loss=1.2956 | TestAcc=0.392 | F1=0.388 | AUC=0.731 | Time=8.04s\n","Epoch 059 | Loss=1.2748 | TestAcc=0.442 | F1=0.435 | AUC=0.727 | Time=8.16s\n","Epoch 060 | Loss=1.4129 | TestAcc=0.400 | F1=0.387 | AUC=0.725 | Time=8.28s\n","Epoch 061 | Loss=1.2485 | TestAcc=0.367 | F1=0.365 | AUC=0.703 | Time=8.40s\n","Epoch 062 | Loss=1.2630 | TestAcc=0.392 | F1=0.396 | AUC=0.720 | Time=8.51s\n","Epoch 063 | Loss=1.3477 | TestAcc=0.392 | F1=0.390 | AUC=0.715 | Time=8.64s\n","Epoch 064 | Loss=1.2702 | TestAcc=0.408 | F1=0.405 | AUC=0.732 | Time=8.76s\n","Epoch 065 | Loss=1.2678 | TestAcc=0.442 | F1=0.441 | AUC=0.726 | Time=8.87s\n","Epoch 066 | Loss=1.3194 | TestAcc=0.408 | F1=0.415 | AUC=0.743 | Time=8.98s\n","Epoch 067 | Loss=1.2372 | TestAcc=0.400 | F1=0.400 | AUC=0.731 | Time=9.10s\n","Epoch 068 | Loss=1.2937 | TestAcc=0.442 | F1=0.426 | AUC=0.741 | Time=9.22s\n","Epoch 069 | Loss=1.2729 | TestAcc=0.458 | F1=0.449 | AUC=0.742 | Time=9.33s\n","Epoch 070 | Loss=1.2874 | TestAcc=0.375 | F1=0.376 | AUC=0.727 | Time=9.45s\n","Epoch 071 | Loss=1.2157 | TestAcc=0.417 | F1=0.410 | AUC=0.726 | Time=9.57s\n","Epoch 072 | Loss=1.2472 | TestAcc=0.425 | F1=0.426 | AUC=0.741 | Time=9.69s\n","Epoch 073 | Loss=1.2220 | TestAcc=0.392 | F1=0.395 | AUC=0.733 | Time=9.81s\n","Epoch 074 | Loss=1.2208 | TestAcc=0.400 | F1=0.399 | AUC=0.734 | Time=9.93s\n","Epoch 075 | Loss=1.2467 | TestAcc=0.483 | F1=0.479 | AUC=0.741 | Time=10.05s\n","Epoch 076 | Loss=1.2665 | TestAcc=0.417 | F1=0.418 | AUC=0.737 | Time=10.17s\n","Epoch 077 | Loss=1.1934 | TestAcc=0.442 | F1=0.444 | AUC=0.755 | Time=10.28s\n","Epoch 078 | Loss=1.2238 | TestAcc=0.425 | F1=0.418 | AUC=0.736 | Time=10.40s\n","Epoch 079 | Loss=1.1434 | TestAcc=0.442 | F1=0.438 | AUC=0.748 | Time=10.52s\n","Epoch 080 | Loss=1.1459 | TestAcc=0.392 | F1=0.394 | AUC=0.746 | Time=10.65s\n","Epoch 081 | Loss=1.1471 | TestAcc=0.425 | F1=0.418 | AUC=0.730 | Time=10.76s\n","Epoch 082 | Loss=1.1192 | TestAcc=0.433 | F1=0.431 | AUC=0.727 | Time=10.88s\n","Epoch 083 | Loss=1.2064 | TestAcc=0.425 | F1=0.419 | AUC=0.741 | Time=11.00s\n","Epoch 084 | Loss=1.1420 | TestAcc=0.425 | F1=0.427 | AUC=0.728 | Time=11.12s\n","Epoch 085 | Loss=1.1543 | TestAcc=0.375 | F1=0.371 | AUC=0.740 | Time=11.23s\n","Epoch 086 | Loss=1.2273 | TestAcc=0.433 | F1=0.433 | AUC=0.738 | Time=11.35s\n","Epoch 087 | Loss=1.1736 | TestAcc=0.392 | F1=0.392 | AUC=0.725 | Time=11.46s\n","Epoch 088 | Loss=1.2244 | TestAcc=0.367 | F1=0.345 | AUC=0.676 | Time=11.59s\n","Epoch 089 | Loss=1.1335 | TestAcc=0.400 | F1=0.395 | AUC=0.730 | Time=11.72s\n","Epoch 090 | Loss=1.0964 | TestAcc=0.367 | F1=0.371 | AUC=0.710 | Time=11.84s\n","Epoch 091 | Loss=1.1854 | TestAcc=0.308 | F1=0.311 | AUC=0.696 | Time=11.95s\n","Epoch 092 | Loss=1.1614 | TestAcc=0.425 | F1=0.406 | AUC=0.710 | Time=12.07s\n","Epoch 093 | Loss=1.1318 | TestAcc=0.450 | F1=0.441 | AUC=0.742 | Time=12.19s\n","Epoch 094 | Loss=1.1195 | TestAcc=0.450 | F1=0.445 | AUC=0.736 | Time=12.30s\n","Epoch 095 | Loss=1.1903 | TestAcc=0.467 | F1=0.454 | AUC=0.727 | Time=12.42s\n","Epoch 096 | Loss=1.1076 | TestAcc=0.408 | F1=0.411 | AUC=0.732 | Time=12.56s\n","Epoch 097 | Loss=1.1034 | TestAcc=0.417 | F1=0.404 | AUC=0.738 | Time=12.68s\n","Epoch 098 | Loss=1.1179 | TestAcc=0.408 | F1=0.399 | AUC=0.759 | Time=12.81s\n","Epoch 099 | Loss=1.0902 | TestAcc=0.458 | F1=0.455 | AUC=0.726 | Time=12.92s\n","Epoch 100 | Loss=1.0758 | TestAcc=0.383 | F1=0.358 | AUC=0.667 | Time=13.03s\n","Epoch 101 | Loss=1.0830 | TestAcc=0.442 | F1=0.440 | AUC=0.735 | Time=13.14s\n","Epoch 102 | Loss=1.1961 | TestAcc=0.433 | F1=0.429 | AUC=0.714 | Time=13.25s\n","Epoch 103 | Loss=1.0719 | TestAcc=0.417 | F1=0.419 | AUC=0.726 | Time=13.36s\n","Epoch 104 | Loss=1.1288 | TestAcc=0.408 | F1=0.402 | AUC=0.718 | Time=13.48s\n","Epoch 105 | Loss=1.1596 | TestAcc=0.383 | F1=0.379 | AUC=0.699 | Time=13.59s\n","Epoch 106 | Loss=1.0969 | TestAcc=0.458 | F1=0.454 | AUC=0.755 | Time=13.71s\n","Epoch 107 | Loss=1.1355 | TestAcc=0.475 | F1=0.463 | AUC=0.765 | Time=13.84s\n","Epoch 108 | Loss=1.0631 | TestAcc=0.433 | F1=0.433 | AUC=0.740 | Time=13.95s\n","Epoch 109 | Loss=1.1132 | TestAcc=0.400 | F1=0.399 | AUC=0.718 | Time=14.06s\n","Epoch 110 | Loss=1.0416 | TestAcc=0.383 | F1=0.384 | AUC=0.729 | Time=14.18s\n","Epoch 111 | Loss=1.1033 | TestAcc=0.392 | F1=0.395 | AUC=0.740 | Time=14.30s\n","Epoch 112 | Loss=1.1040 | TestAcc=0.450 | F1=0.440 | AUC=0.744 | Time=14.44s\n","Epoch 113 | Loss=1.0387 | TestAcc=0.425 | F1=0.413 | AUC=0.722 | Time=14.60s\n","Epoch 114 | Loss=1.0721 | TestAcc=0.442 | F1=0.437 | AUC=0.748 | Time=14.76s\n","Epoch 115 | Loss=1.0159 | TestAcc=0.433 | F1=0.420 | AUC=0.735 | Time=14.93s\n","Epoch 116 | Loss=1.0885 | TestAcc=0.442 | F1=0.428 | AUC=0.745 | Time=15.08s\n","Epoch 117 | Loss=1.0073 | TestAcc=0.433 | F1=0.438 | AUC=0.748 | Time=15.23s\n","Epoch 118 | Loss=1.0751 | TestAcc=0.383 | F1=0.379 | AUC=0.721 | Time=15.40s\n","Epoch 119 | Loss=1.0022 | TestAcc=0.367 | F1=0.356 | AUC=0.718 | Time=15.57s\n","Epoch 120 | Loss=1.0120 | TestAcc=0.392 | F1=0.384 | AUC=0.748 | Time=15.73s\n","Epoch 121 | Loss=1.0382 | TestAcc=0.408 | F1=0.412 | AUC=0.734 | Time=15.90s\n","Epoch 122 | Loss=1.0117 | TestAcc=0.442 | F1=0.427 | AUC=0.756 | Time=16.06s\n","Epoch 123 | Loss=1.0197 | TestAcc=0.417 | F1=0.412 | AUC=0.751 | Time=16.21s\n","Epoch 124 | Loss=0.9907 | TestAcc=0.400 | F1=0.386 | AUC=0.739 | Time=16.37s\n","Epoch 125 | Loss=1.0179 | TestAcc=0.450 | F1=0.452 | AUC=0.755 | Time=16.52s\n","Epoch 126 | Loss=1.0164 | TestAcc=0.417 | F1=0.401 | AUC=0.726 | Time=16.67s\n","Epoch 127 | Loss=0.9561 | TestAcc=0.408 | F1=0.406 | AUC=0.737 | Time=16.83s\n","Epoch 128 | Loss=0.9469 | TestAcc=0.367 | F1=0.333 | AUC=0.721 | Time=17.00s\n","Epoch 129 | Loss=1.0172 | TestAcc=0.417 | F1=0.417 | AUC=0.768 | Time=17.18s\n","Epoch 130 | Loss=0.9525 | TestAcc=0.425 | F1=0.417 | AUC=0.753 | Time=17.36s\n","Epoch 131 | Loss=0.8954 | TestAcc=0.475 | F1=0.470 | AUC=0.753 | Time=17.51s\n","Epoch 132 | Loss=0.8741 | TestAcc=0.442 | F1=0.433 | AUC=0.744 | Time=17.62s\n","Epoch 133 | Loss=0.9397 | TestAcc=0.433 | F1=0.431 | AUC=0.757 | Time=17.74s\n","Epoch 134 | Loss=0.9338 | TestAcc=0.417 | F1=0.393 | AUC=0.739 | Time=17.85s\n","Epoch 135 | Loss=0.9907 | TestAcc=0.358 | F1=0.359 | AUC=0.712 | Time=17.96s\n","Epoch 136 | Loss=0.9439 | TestAcc=0.425 | F1=0.431 | AUC=0.776 | Time=18.09s\n","Epoch 137 | Loss=0.9535 | TestAcc=0.425 | F1=0.419 | AUC=0.723 | Time=18.20s\n","Epoch 138 | Loss=0.9958 | TestAcc=0.383 | F1=0.376 | AUC=0.743 | Time=18.31s\n","Epoch 139 | Loss=0.9427 | TestAcc=0.383 | F1=0.358 | AUC=0.735 | Time=18.42s\n","Epoch 140 | Loss=0.8813 | TestAcc=0.417 | F1=0.392 | AUC=0.716 | Time=18.54s\n","Epoch 141 | Loss=0.8689 | TestAcc=0.392 | F1=0.390 | AUC=0.737 | Time=18.65s\n","Epoch 142 | Loss=0.9346 | TestAcc=0.425 | F1=0.406 | AUC=0.744 | Time=18.77s\n","Epoch 143 | Loss=0.8981 | TestAcc=0.400 | F1=0.391 | AUC=0.730 | Time=18.88s\n","Epoch 144 | Loss=0.9689 | TestAcc=0.450 | F1=0.446 | AUC=0.755 | Time=18.99s\n","Epoch 145 | Loss=0.9540 | TestAcc=0.392 | F1=0.388 | AUC=0.741 | Time=19.13s\n","Epoch 146 | Loss=0.9315 | TestAcc=0.458 | F1=0.458 | AUC=0.742 | Time=19.24s\n","Epoch 147 | Loss=0.9980 | TestAcc=0.458 | F1=0.447 | AUC=0.743 | Time=19.36s\n","Epoch 148 | Loss=1.0054 | TestAcc=0.442 | F1=0.433 | AUC=0.736 | Time=19.47s\n","Epoch 149 | Loss=0.9293 | TestAcc=0.442 | F1=0.418 | AUC=0.729 | Time=19.59s\n","Epoch 150 | Loss=0.8877 | TestAcc=0.375 | F1=0.373 | AUC=0.732 | Time=19.70s\n","Epoch 151 | Loss=0.9418 | TestAcc=0.442 | F1=0.444 | AUC=0.763 | Time=19.81s\n","Epoch 152 | Loss=0.9039 | TestAcc=0.417 | F1=0.411 | AUC=0.733 | Time=19.92s\n","Epoch 153 | Loss=0.8873 | TestAcc=0.492 | F1=0.495 | AUC=0.745 | Time=20.04s\n","Epoch 154 | Loss=0.9363 | TestAcc=0.408 | F1=0.405 | AUC=0.743 | Time=20.16s\n","Epoch 155 | Loss=0.9578 | TestAcc=0.450 | F1=0.438 | AUC=0.721 | Time=20.27s\n","Epoch 156 | Loss=0.8950 | TestAcc=0.367 | F1=0.345 | AUC=0.702 | Time=20.39s\n","Epoch 157 | Loss=0.9396 | TestAcc=0.425 | F1=0.430 | AUC=0.723 | Time=20.50s\n","Epoch 158 | Loss=0.9041 | TestAcc=0.400 | F1=0.391 | AUC=0.735 | Time=20.61s\n","Epoch 159 | Loss=0.9362 | TestAcc=0.458 | F1=0.447 | AUC=0.748 | Time=20.72s\n","Epoch 160 | Loss=0.9239 | TestAcc=0.442 | F1=0.440 | AUC=0.745 | Time=20.84s\n","Epoch 161 | Loss=0.8460 | TestAcc=0.450 | F1=0.431 | AUC=0.743 | Time=20.95s\n","Epoch 162 | Loss=0.7917 | TestAcc=0.442 | F1=0.442 | AUC=0.760 | Time=21.07s\n","Epoch 163 | Loss=0.8697 | TestAcc=0.467 | F1=0.461 | AUC=0.761 | Time=21.19s\n","Epoch 164 | Loss=0.7837 | TestAcc=0.392 | F1=0.384 | AUC=0.744 | Time=21.31s\n","Epoch 165 | Loss=0.8638 | TestAcc=0.433 | F1=0.423 | AUC=0.741 | Time=21.42s\n","Epoch 166 | Loss=0.8270 | TestAcc=0.450 | F1=0.456 | AUC=0.769 | Time=21.54s\n","Epoch 167 | Loss=0.8158 | TestAcc=0.458 | F1=0.453 | AUC=0.756 | Time=21.65s\n","Epoch 168 | Loss=0.8146 | TestAcc=0.500 | F1=0.493 | AUC=0.754 | Time=21.78s\n","Epoch 169 | Loss=0.8016 | TestAcc=0.442 | F1=0.446 | AUC=0.742 | Time=21.89s\n","Epoch 170 | Loss=0.8065 | TestAcc=0.467 | F1=0.465 | AUC=0.761 | Time=22.01s\n","Epoch 171 | Loss=0.7902 | TestAcc=0.442 | F1=0.431 | AUC=0.742 | Time=22.13s\n","Epoch 172 | Loss=0.8483 | TestAcc=0.417 | F1=0.412 | AUC=0.741 | Time=22.25s\n","Epoch 173 | Loss=0.8818 | TestAcc=0.433 | F1=0.429 | AUC=0.743 | Time=22.37s\n","Epoch 174 | Loss=0.8068 | TestAcc=0.442 | F1=0.445 | AUC=0.764 | Time=22.49s\n","Epoch 175 | Loss=0.7874 | TestAcc=0.467 | F1=0.456 | AUC=0.759 | Time=22.60s\n","Epoch 176 | Loss=0.8087 | TestAcc=0.425 | F1=0.418 | AUC=0.751 | Time=22.71s\n","Epoch 177 | Loss=0.7933 | TestAcc=0.442 | F1=0.446 | AUC=0.775 | Time=22.83s\n","Epoch 178 | Loss=0.8646 | TestAcc=0.433 | F1=0.417 | AUC=0.723 | Time=22.94s\n","Epoch 179 | Loss=0.7999 | TestAcc=0.433 | F1=0.424 | AUC=0.739 | Time=23.06s\n","Epoch 180 | Loss=0.8149 | TestAcc=0.458 | F1=0.454 | AUC=0.731 | Time=23.19s\n","Epoch 181 | Loss=0.7741 | TestAcc=0.492 | F1=0.479 | AUC=0.768 | Time=23.31s\n","Epoch 182 | Loss=0.8109 | TestAcc=0.467 | F1=0.456 | AUC=0.762 | Time=23.43s\n","Epoch 183 | Loss=0.7464 | TestAcc=0.458 | F1=0.460 | AUC=0.764 | Time=23.56s\n","Epoch 184 | Loss=0.7951 | TestAcc=0.425 | F1=0.434 | AUC=0.781 | Time=23.68s\n","Epoch 185 | Loss=0.7971 | TestAcc=0.425 | F1=0.420 | AUC=0.743 | Time=23.80s\n","Epoch 186 | Loss=0.7315 | TestAcc=0.458 | F1=0.453 | AUC=0.740 | Time=23.91s\n","Epoch 187 | Loss=0.7892 | TestAcc=0.425 | F1=0.424 | AUC=0.762 | Time=24.02s\n","Epoch 188 | Loss=0.7983 | TestAcc=0.433 | F1=0.419 | AUC=0.734 | Time=24.13s\n","Epoch 189 | Loss=0.8144 | TestAcc=0.475 | F1=0.474 | AUC=0.756 | Time=24.26s\n","Epoch 190 | Loss=0.7624 | TestAcc=0.417 | F1=0.390 | AUC=0.718 | Time=24.37s\n","Epoch 191 | Loss=0.7724 | TestAcc=0.492 | F1=0.493 | AUC=0.772 | Time=24.48s\n","Epoch 192 | Loss=0.8217 | TestAcc=0.425 | F1=0.425 | AUC=0.759 | Time=24.60s\n","Epoch 193 | Loss=0.7373 | TestAcc=0.425 | F1=0.424 | AUC=0.751 | Time=24.71s\n","Epoch 194 | Loss=0.7588 | TestAcc=0.450 | F1=0.433 | AUC=0.753 | Time=24.83s\n","Epoch 195 | Loss=0.7956 | TestAcc=0.433 | F1=0.424 | AUC=0.769 | Time=24.94s\n","Epoch 196 | Loss=0.6511 | TestAcc=0.375 | F1=0.357 | AUC=0.698 | Time=25.06s\n","Epoch 197 | Loss=0.7531 | TestAcc=0.408 | F1=0.410 | AUC=0.740 | Time=25.17s\n","Epoch 198 | Loss=0.7399 | TestAcc=0.492 | F1=0.478 | AUC=0.760 | Time=25.30s\n","Epoch 199 | Loss=0.7080 | TestAcc=0.458 | F1=0.461 | AUC=0.776 | Time=25.41s\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:41:15,415] A new study created in memory with name: no-name-3959f14b-f743-47e8-b602-764ce9a16daa\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 200 | Loss=0.7432 | TestAcc=0.458 | F1=0.448 | AUC=0.765 | Time=25.53s\n","\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed  dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    42  ENZYMES                  yes                   64   \n","\n","  objective_weights  num_layers  dropout        lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           3  0.45631  0.000237      0.000002     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0         168     1.9766     1.9766       0.5   0.4931    0.7544   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              25.53                 6.46            1439.98  \n","Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_ENZYMES_42.pth\n","Loaded dataset ENZYMES: 600 graphs, 3 node features, 6 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:41:16,032] Trial 0 finished with value: 0.35443880888484125 and parameters: {'num_layers': 4, 'dropout': 0.5604097484488613, 'lr': 0.0066450224044829476, 'weight_decay': 1.3707562001964826e-06}. Best is trial 0 with value: 0.35443880888484125.\n","[I 2026-01-27 17:41:16,542] Trial 1 finished with value: 0.43284084853988736 and parameters: {'num_layers': 3, 'dropout': 0.4354013924885559, 'lr': 0.007466931275764762, 'weight_decay': 1.5011746425889494e-05}. Best is trial 1 with value: 0.43284084853988736.\n","[I 2026-01-27 17:41:17,118] Trial 2 finished with value: 0.31680439285312945 and parameters: {'num_layers': 4, 'dropout': 0.35022985310079247, 'lr': 0.0009386814273596195, 'weight_decay': 4.729975358157199e-05}. Best is trial 1 with value: 0.43284084853988736.\n","[I 2026-01-27 17:41:17,774] Trial 3 finished with value: 0.4059906716489484 and parameters: {'num_layers': 3, 'dropout': 0.023967277965709587, 'lr': 0.0008901192405249095, 'weight_decay': 0.0007434705363991491}. Best is trial 1 with value: 0.43284084853988736.\n","[I 2026-01-27 17:41:18,758] Trial 4 finished with value: 0.365674572053865 and parameters: {'num_layers': 6, 'dropout': 0.3357479181116731, 'lr': 0.001900149077461945, 'weight_decay': 1.9120850403075257e-06}. Best is trial 1 with value: 0.43284084853988736.\n","[I 2026-01-27 17:41:19,513] Trial 5 finished with value: 0.28959180668341833 and parameters: {'num_layers': 4, 'dropout': 0.5748362550277859, 'lr': 0.0009522158590186083, 'weight_decay': 1.0913570501507625e-05}. Best is trial 1 with value: 0.43284084853988736.\n","[I 2026-01-27 17:41:20,351] Trial 6 finished with value: 0.3645954181252327 and parameters: {'num_layers': 4, 'dropout': 0.5924810469186659, 'lr': 0.005777930047729694, 'weight_decay': 2.650718907300183e-06}. Best is trial 1 with value: 0.43284084853988736.\n","[I 2026-01-27 17:41:21,057] Trial 7 finished with value: 0.2604660553960538 and parameters: {'num_layers': 6, 'dropout': 0.543818779956073, 'lr': 0.008585532510826796, 'weight_decay': 2.684900826891318e-06}. Best is trial 1 with value: 0.43284084853988736.\n","[I 2026-01-27 17:41:21,650] Trial 8 finished with value: 0.42256194707103145 and parameters: {'num_layers': 4, 'dropout': 0.21662724622458954, 'lr': 0.006786698009873789, 'weight_decay': 6.13456631389431e-05}. Best is trial 1 with value: 0.43284084853988736.\n","[I 2026-01-27 17:41:22,298] Trial 9 finished with value: 0.3324626851022636 and parameters: {'num_layers': 5, 'dropout': 0.15308869137435469, 'lr': 0.0037750920566431254, 'weight_decay': 7.449449683622758e-05}. Best is trial 1 with value: 0.43284084853988736.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 3, 'dropout': 0.4354013924885559, 'lr': 0.007466931275764762, 'weight_decay': 1.5011746425889494e-05}\n","\n","Running final training GIN...\n","{'num_layers': 3, 'dropout': 0.4354013924885559, 'lr': 0.007466931275764762, 'weight_decay': 1.5011746425889494e-05}\n","Epoch 001 | Loss=5.7944 | TestAcc=0.250 | F1=0.166 | AUC=0.621 | Time=0.13s\n","Epoch 002 | Loss=3.2729 | TestAcc=0.200 | F1=0.173 | AUC=0.661 | Time=0.24s\n","Epoch 003 | Loss=2.3372 | TestAcc=0.267 | F1=0.230 | AUC=0.652 | Time=0.36s\n","Epoch 004 | Loss=1.9782 | TestAcc=0.242 | F1=0.241 | AUC=0.618 | Time=0.48s\n","Epoch 005 | Loss=1.7695 | TestAcc=0.300 | F1=0.307 | AUC=0.654 | Time=0.59s\n","Epoch 006 | Loss=1.6871 | TestAcc=0.317 | F1=0.310 | AUC=0.665 | Time=0.70s\n","Epoch 007 | Loss=1.6441 | TestAcc=0.283 | F1=0.265 | AUC=0.657 | Time=0.82s\n","Epoch 008 | Loss=1.6105 | TestAcc=0.367 | F1=0.351 | AUC=0.732 | Time=0.93s\n","Epoch 009 | Loss=1.5885 | TestAcc=0.317 | F1=0.294 | AUC=0.670 | Time=1.04s\n","Epoch 010 | Loss=1.5864 | TestAcc=0.358 | F1=0.345 | AUC=0.712 | Time=1.17s\n","Epoch 011 | Loss=1.6053 | TestAcc=0.375 | F1=0.364 | AUC=0.684 | Time=1.29s\n","Epoch 012 | Loss=1.5923 | TestAcc=0.350 | F1=0.354 | AUC=0.684 | Time=1.41s\n","Epoch 013 | Loss=1.6156 | TestAcc=0.350 | F1=0.331 | AUC=0.714 | Time=1.53s\n","Epoch 014 | Loss=1.5718 | TestAcc=0.308 | F1=0.283 | AUC=0.667 | Time=1.66s\n","Epoch 015 | Loss=1.5536 | TestAcc=0.417 | F1=0.423 | AUC=0.731 | Time=1.78s\n","Epoch 016 | Loss=1.5951 | TestAcc=0.317 | F1=0.298 | AUC=0.662 | Time=1.89s\n","Epoch 017 | Loss=1.5813 | TestAcc=0.375 | F1=0.362 | AUC=0.721 | Time=2.00s\n","Epoch 018 | Loss=1.5595 | TestAcc=0.333 | F1=0.308 | AUC=0.688 | Time=2.13s\n","Epoch 019 | Loss=1.5956 | TestAcc=0.350 | F1=0.330 | AUC=0.645 | Time=2.24s\n","Epoch 020 | Loss=1.6310 | TestAcc=0.242 | F1=0.244 | AUC=0.616 | Time=2.35s\n","Epoch 021 | Loss=1.5999 | TestAcc=0.275 | F1=0.263 | AUC=0.651 | Time=2.47s\n","Epoch 022 | Loss=1.5952 | TestAcc=0.408 | F1=0.392 | AUC=0.716 | Time=2.58s\n","Epoch 023 | Loss=1.5857 | TestAcc=0.292 | F1=0.266 | AUC=0.646 | Time=2.69s\n","Epoch 024 | Loss=1.6628 | TestAcc=0.375 | F1=0.374 | AUC=0.737 | Time=2.81s\n","Epoch 025 | Loss=1.6245 | TestAcc=0.325 | F1=0.317 | AUC=0.675 | Time=2.92s\n","Epoch 026 | Loss=1.6530 | TestAcc=0.292 | F1=0.261 | AUC=0.667 | Time=3.03s\n","Epoch 027 | Loss=1.6432 | TestAcc=0.317 | F1=0.295 | AUC=0.667 | Time=3.16s\n","Epoch 028 | Loss=1.6123 | TestAcc=0.292 | F1=0.260 | AUC=0.626 | Time=3.28s\n","Epoch 029 | Loss=1.5787 | TestAcc=0.267 | F1=0.247 | AUC=0.600 | Time=3.39s\n","Epoch 030 | Loss=1.6457 | TestAcc=0.317 | F1=0.305 | AUC=0.655 | Time=3.51s\n","Epoch 031 | Loss=1.6428 | TestAcc=0.275 | F1=0.245 | AUC=0.645 | Time=3.62s\n","Epoch 032 | Loss=1.6169 | TestAcc=0.283 | F1=0.272 | AUC=0.649 | Time=3.76s\n","Epoch 033 | Loss=1.6452 | TestAcc=0.300 | F1=0.299 | AUC=0.617 | Time=3.88s\n","Epoch 034 | Loss=1.6341 | TestAcc=0.275 | F1=0.272 | AUC=0.668 | Time=3.99s\n","Epoch 035 | Loss=1.6163 | TestAcc=0.300 | F1=0.283 | AUC=0.649 | Time=4.10s\n","Epoch 036 | Loss=1.6050 | TestAcc=0.283 | F1=0.259 | AUC=0.646 | Time=4.23s\n","Epoch 037 | Loss=1.5846 | TestAcc=0.250 | F1=0.222 | AUC=0.626 | Time=4.34s\n","Epoch 038 | Loss=1.5920 | TestAcc=0.308 | F1=0.302 | AUC=0.676 | Time=4.46s\n","Epoch 039 | Loss=1.6135 | TestAcc=0.258 | F1=0.260 | AUC=0.616 | Time=4.57s\n","Epoch 040 | Loss=1.6356 | TestAcc=0.283 | F1=0.270 | AUC=0.686 | Time=4.68s\n","Epoch 041 | Loss=1.5997 | TestAcc=0.317 | F1=0.292 | AUC=0.654 | Time=4.80s\n","Epoch 042 | Loss=1.6091 | TestAcc=0.317 | F1=0.320 | AUC=0.658 | Time=4.91s\n","Epoch 043 | Loss=1.6221 | TestAcc=0.283 | F1=0.279 | AUC=0.647 | Time=5.02s\n","Epoch 044 | Loss=1.6377 | TestAcc=0.342 | F1=0.330 | AUC=0.697 | Time=5.13s\n","Epoch 045 | Loss=1.5780 | TestAcc=0.292 | F1=0.282 | AUC=0.678 | Time=5.26s\n","Epoch 046 | Loss=1.6314 | TestAcc=0.283 | F1=0.243 | AUC=0.613 | Time=5.37s\n","Epoch 047 | Loss=1.5797 | TestAcc=0.325 | F1=0.312 | AUC=0.657 | Time=5.49s\n","Epoch 048 | Loss=1.6638 | TestAcc=0.242 | F1=0.205 | AUC=0.659 | Time=5.60s\n","Epoch 049 | Loss=1.6526 | TestAcc=0.292 | F1=0.298 | AUC=0.659 | Time=5.72s\n","Epoch 050 | Loss=1.6314 | TestAcc=0.233 | F1=0.224 | AUC=0.600 | Time=5.84s\n","Epoch 051 | Loss=1.6487 | TestAcc=0.292 | F1=0.282 | AUC=0.617 | Time=5.96s\n","Epoch 052 | Loss=1.6340 | TestAcc=0.375 | F1=0.359 | AUC=0.682 | Time=6.08s\n","Epoch 053 | Loss=1.5579 | TestAcc=0.283 | F1=0.264 | AUC=0.634 | Time=6.19s\n","Epoch 054 | Loss=1.6083 | TestAcc=0.300 | F1=0.296 | AUC=0.660 | Time=6.32s\n","Epoch 055 | Loss=1.5715 | TestAcc=0.333 | F1=0.328 | AUC=0.670 | Time=6.43s\n","Epoch 056 | Loss=1.5319 | TestAcc=0.342 | F1=0.341 | AUC=0.674 | Time=6.54s\n","Epoch 057 | Loss=1.5684 | TestAcc=0.308 | F1=0.281 | AUC=0.665 | Time=6.65s\n","Epoch 058 | Loss=1.6044 | TestAcc=0.233 | F1=0.188 | AUC=0.613 | Time=6.77s\n","Epoch 059 | Loss=1.6518 | TestAcc=0.267 | F1=0.232 | AUC=0.595 | Time=6.88s\n","Epoch 060 | Loss=1.6148 | TestAcc=0.325 | F1=0.302 | AUC=0.619 | Time=6.99s\n","Epoch 061 | Loss=1.5715 | TestAcc=0.283 | F1=0.256 | AUC=0.622 | Time=7.10s\n","Epoch 062 | Loss=1.5491 | TestAcc=0.317 | F1=0.304 | AUC=0.622 | Time=7.22s\n","Epoch 063 | Loss=1.5643 | TestAcc=0.300 | F1=0.295 | AUC=0.655 | Time=7.34s\n","Epoch 064 | Loss=1.6263 | TestAcc=0.300 | F1=0.281 | AUC=0.636 | Time=7.46s\n","Epoch 065 | Loss=1.6228 | TestAcc=0.308 | F1=0.297 | AUC=0.641 | Time=7.58s\n","Epoch 066 | Loss=1.5998 | TestAcc=0.300 | F1=0.268 | AUC=0.609 | Time=7.69s\n","Epoch 067 | Loss=1.5705 | TestAcc=0.317 | F1=0.297 | AUC=0.656 | Time=7.80s\n","Epoch 068 | Loss=1.5822 | TestAcc=0.333 | F1=0.303 | AUC=0.657 | Time=7.91s\n","Epoch 069 | Loss=1.5575 | TestAcc=0.242 | F1=0.234 | AUC=0.579 | Time=8.03s\n","Epoch 070 | Loss=1.5610 | TestAcc=0.342 | F1=0.347 | AUC=0.669 | Time=8.18s\n","Epoch 071 | Loss=1.6145 | TestAcc=0.317 | F1=0.285 | AUC=0.674 | Time=8.35s\n","Epoch 072 | Loss=1.5752 | TestAcc=0.317 | F1=0.310 | AUC=0.643 | Time=8.51s\n","Epoch 073 | Loss=1.5603 | TestAcc=0.275 | F1=0.265 | AUC=0.632 | Time=8.67s\n","Epoch 074 | Loss=1.5424 | TestAcc=0.333 | F1=0.329 | AUC=0.673 | Time=8.82s\n","Epoch 075 | Loss=1.5631 | TestAcc=0.317 | F1=0.321 | AUC=0.659 | Time=8.98s\n","Epoch 076 | Loss=1.5852 | TestAcc=0.300 | F1=0.283 | AUC=0.676 | Time=9.15s\n","Epoch 077 | Loss=1.5384 | TestAcc=0.325 | F1=0.307 | AUC=0.663 | Time=9.32s\n","Epoch 078 | Loss=1.5710 | TestAcc=0.358 | F1=0.350 | AUC=0.652 | Time=9.51s\n","Epoch 079 | Loss=1.5756 | TestAcc=0.350 | F1=0.342 | AUC=0.664 | Time=9.67s\n","Epoch 080 | Loss=1.5660 | TestAcc=0.358 | F1=0.350 | AUC=0.683 | Time=9.83s\n","Epoch 081 | Loss=1.5206 | TestAcc=0.292 | F1=0.283 | AUC=0.659 | Time=9.98s\n","Epoch 082 | Loss=1.5244 | TestAcc=0.358 | F1=0.327 | AUC=0.671 | Time=10.14s\n","Epoch 083 | Loss=1.5034 | TestAcc=0.283 | F1=0.265 | AUC=0.626 | Time=10.29s\n","Epoch 084 | Loss=1.5021 | TestAcc=0.308 | F1=0.278 | AUC=0.638 | Time=10.45s\n","Epoch 085 | Loss=1.5162 | TestAcc=0.275 | F1=0.276 | AUC=0.636 | Time=10.61s\n","Epoch 086 | Loss=1.5968 | TestAcc=0.333 | F1=0.312 | AUC=0.614 | Time=10.79s\n","Epoch 087 | Loss=1.5208 | TestAcc=0.317 | F1=0.297 | AUC=0.615 | Time=10.96s\n","Epoch 088 | Loss=1.5249 | TestAcc=0.275 | F1=0.229 | AUC=0.601 | Time=11.14s\n","Epoch 089 | Loss=1.5291 | TestAcc=0.317 | F1=0.312 | AUC=0.614 | Time=11.32s\n","Epoch 090 | Loss=1.5544 | TestAcc=0.342 | F1=0.342 | AUC=0.641 | Time=11.44s\n","Epoch 091 | Loss=1.5441 | TestAcc=0.233 | F1=0.169 | AUC=0.606 | Time=11.56s\n","Epoch 092 | Loss=1.8047 | TestAcc=0.225 | F1=0.170 | AUC=0.578 | Time=11.69s\n","Epoch 093 | Loss=1.6837 | TestAcc=0.217 | F1=0.192 | AUC=0.583 | Time=11.80s\n","Epoch 094 | Loss=1.5963 | TestAcc=0.325 | F1=0.312 | AUC=0.611 | Time=11.93s\n","Epoch 095 | Loss=1.6284 | TestAcc=0.275 | F1=0.260 | AUC=0.666 | Time=12.04s\n","Epoch 096 | Loss=1.6603 | TestAcc=0.275 | F1=0.260 | AUC=0.641 | Time=12.16s\n","Epoch 097 | Loss=1.6576 | TestAcc=0.225 | F1=0.174 | AUC=0.604 | Time=12.27s\n","Epoch 098 | Loss=1.6067 | TestAcc=0.258 | F1=0.237 | AUC=0.619 | Time=12.38s\n","Epoch 099 | Loss=1.5950 | TestAcc=0.267 | F1=0.255 | AUC=0.624 | Time=12.50s\n","Epoch 100 | Loss=1.5829 | TestAcc=0.300 | F1=0.299 | AUC=0.654 | Time=12.61s\n","Epoch 101 | Loss=1.6025 | TestAcc=0.283 | F1=0.270 | AUC=0.643 | Time=12.73s\n","Epoch 102 | Loss=1.5932 | TestAcc=0.275 | F1=0.262 | AUC=0.641 | Time=12.85s\n","Epoch 103 | Loss=1.5968 | TestAcc=0.292 | F1=0.277 | AUC=0.640 | Time=12.96s\n","Epoch 104 | Loss=1.6003 | TestAcc=0.225 | F1=0.185 | AUC=0.613 | Time=13.07s\n","Epoch 105 | Loss=1.6211 | TestAcc=0.217 | F1=0.211 | AUC=0.593 | Time=13.19s\n","Epoch 106 | Loss=1.6339 | TestAcc=0.292 | F1=0.248 | AUC=0.623 | Time=13.31s\n","Epoch 107 | Loss=1.5919 | TestAcc=0.300 | F1=0.294 | AUC=0.632 | Time=13.42s\n","Epoch 108 | Loss=1.6179 | TestAcc=0.300 | F1=0.284 | AUC=0.611 | Time=13.54s\n","Epoch 109 | Loss=1.6458 | TestAcc=0.267 | F1=0.253 | AUC=0.587 | Time=13.65s\n","Epoch 110 | Loss=1.6385 | TestAcc=0.283 | F1=0.278 | AUC=0.592 | Time=13.78s\n","Epoch 111 | Loss=1.6129 | TestAcc=0.367 | F1=0.359 | AUC=0.661 | Time=13.89s\n","Epoch 112 | Loss=1.5805 | TestAcc=0.267 | F1=0.251 | AUC=0.608 | Time=14.01s\n","Epoch 113 | Loss=1.5953 | TestAcc=0.275 | F1=0.267 | AUC=0.591 | Time=14.12s\n","Epoch 114 | Loss=1.5587 | TestAcc=0.308 | F1=0.302 | AUC=0.644 | Time=14.23s\n","Epoch 115 | Loss=1.5787 | TestAcc=0.308 | F1=0.286 | AUC=0.620 | Time=14.34s\n","Epoch 116 | Loss=1.5021 | TestAcc=0.333 | F1=0.331 | AUC=0.673 | Time=14.46s\n","Epoch 117 | Loss=1.5620 | TestAcc=0.300 | F1=0.293 | AUC=0.639 | Time=14.58s\n","Epoch 118 | Loss=1.5461 | TestAcc=0.408 | F1=0.393 | AUC=0.693 | Time=14.70s\n","Epoch 119 | Loss=1.5306 | TestAcc=0.275 | F1=0.279 | AUC=0.636 | Time=14.82s\n","Epoch 120 | Loss=1.5490 | TestAcc=0.358 | F1=0.343 | AUC=0.678 | Time=14.93s\n","Epoch 121 | Loss=1.5058 | TestAcc=0.350 | F1=0.332 | AUC=0.653 | Time=15.05s\n","Epoch 122 | Loss=1.5073 | TestAcc=0.325 | F1=0.311 | AUC=0.669 | Time=15.17s\n","Epoch 123 | Loss=1.4628 | TestAcc=0.317 | F1=0.303 | AUC=0.675 | Time=15.29s\n","Epoch 124 | Loss=1.5139 | TestAcc=0.392 | F1=0.373 | AUC=0.697 | Time=15.41s\n","Epoch 125 | Loss=1.5207 | TestAcc=0.342 | F1=0.316 | AUC=0.667 | Time=15.52s\n","Epoch 126 | Loss=1.5515 | TestAcc=0.392 | F1=0.379 | AUC=0.660 | Time=15.64s\n","Epoch 127 | Loss=1.5969 | TestAcc=0.242 | F1=0.230 | AUC=0.606 | Time=15.77s\n","Epoch 128 | Loss=1.5633 | TestAcc=0.350 | F1=0.329 | AUC=0.641 | Time=15.89s\n","Epoch 129 | Loss=1.5337 | TestAcc=0.367 | F1=0.334 | AUC=0.652 | Time=16.01s\n","Epoch 130 | Loss=1.5147 | TestAcc=0.342 | F1=0.312 | AUC=0.648 | Time=16.12s\n","Epoch 131 | Loss=1.4568 | TestAcc=0.317 | F1=0.291 | AUC=0.650 | Time=16.24s\n","Epoch 132 | Loss=1.5500 | TestAcc=0.300 | F1=0.285 | AUC=0.644 | Time=16.35s\n","Epoch 133 | Loss=1.5173 | TestAcc=0.342 | F1=0.339 | AUC=0.674 | Time=16.47s\n","Epoch 134 | Loss=1.5219 | TestAcc=0.375 | F1=0.380 | AUC=0.676 | Time=16.59s\n","Epoch 135 | Loss=1.4700 | TestAcc=0.325 | F1=0.301 | AUC=0.629 | Time=16.71s\n","Epoch 136 | Loss=1.5837 | TestAcc=0.283 | F1=0.282 | AUC=0.640 | Time=16.84s\n","Epoch 137 | Loss=1.5630 | TestAcc=0.325 | F1=0.306 | AUC=0.616 | Time=16.95s\n","Epoch 138 | Loss=1.5161 | TestAcc=0.300 | F1=0.276 | AUC=0.636 | Time=17.07s\n","Epoch 139 | Loss=1.5152 | TestAcc=0.283 | F1=0.277 | AUC=0.584 | Time=17.18s\n","Epoch 140 | Loss=1.5430 | TestAcc=0.350 | F1=0.339 | AUC=0.633 | Time=17.30s\n","Epoch 141 | Loss=1.5304 | TestAcc=0.333 | F1=0.322 | AUC=0.627 | Time=17.42s\n","Epoch 142 | Loss=1.4846 | TestAcc=0.317 | F1=0.314 | AUC=0.642 | Time=17.53s\n","Epoch 143 | Loss=1.5309 | TestAcc=0.325 | F1=0.311 | AUC=0.599 | Time=17.65s\n","Epoch 144 | Loss=1.4532 | TestAcc=0.317 | F1=0.301 | AUC=0.669 | Time=17.77s\n","Epoch 145 | Loss=1.5140 | TestAcc=0.333 | F1=0.334 | AUC=0.661 | Time=17.89s\n","Epoch 146 | Loss=1.4759 | TestAcc=0.350 | F1=0.327 | AUC=0.668 | Time=18.01s\n","Epoch 147 | Loss=1.4663 | TestAcc=0.325 | F1=0.329 | AUC=0.655 | Time=18.13s\n","Epoch 148 | Loss=1.4803 | TestAcc=0.350 | F1=0.332 | AUC=0.667 | Time=18.24s\n","Epoch 149 | Loss=1.4382 | TestAcc=0.342 | F1=0.309 | AUC=0.640 | Time=18.36s\n","Epoch 150 | Loss=1.4410 | TestAcc=0.375 | F1=0.375 | AUC=0.670 | Time=18.47s\n","Epoch 151 | Loss=1.5111 | TestAcc=0.317 | F1=0.311 | AUC=0.638 | Time=18.59s\n","Epoch 152 | Loss=1.4671 | TestAcc=0.333 | F1=0.321 | AUC=0.643 | Time=18.70s\n","Epoch 153 | Loss=1.4257 | TestAcc=0.292 | F1=0.283 | AUC=0.666 | Time=18.83s\n","Epoch 154 | Loss=1.4823 | TestAcc=0.333 | F1=0.311 | AUC=0.649 | Time=18.95s\n","Epoch 155 | Loss=1.4718 | TestAcc=0.383 | F1=0.391 | AUC=0.648 | Time=19.07s\n","Epoch 156 | Loss=1.4881 | TestAcc=0.383 | F1=0.365 | AUC=0.701 | Time=19.19s\n","Epoch 157 | Loss=1.4511 | TestAcc=0.333 | F1=0.342 | AUC=0.659 | Time=19.31s\n","Epoch 158 | Loss=1.4565 | TestAcc=0.317 | F1=0.294 | AUC=0.673 | Time=19.42s\n","Epoch 159 | Loss=1.4725 | TestAcc=0.375 | F1=0.382 | AUC=0.691 | Time=19.54s\n","Epoch 160 | Loss=1.4684 | TestAcc=0.333 | F1=0.327 | AUC=0.674 | Time=19.66s\n","Epoch 161 | Loss=1.4297 | TestAcc=0.333 | F1=0.336 | AUC=0.630 | Time=19.77s\n","Epoch 162 | Loss=1.4238 | TestAcc=0.350 | F1=0.342 | AUC=0.652 | Time=19.90s\n","Epoch 163 | Loss=1.4214 | TestAcc=0.350 | F1=0.347 | AUC=0.669 | Time=20.02s\n","Epoch 164 | Loss=1.4164 | TestAcc=0.367 | F1=0.363 | AUC=0.705 | Time=20.14s\n","Epoch 165 | Loss=1.4158 | TestAcc=0.400 | F1=0.411 | AUC=0.688 | Time=20.26s\n","Epoch 166 | Loss=1.4533 | TestAcc=0.300 | F1=0.275 | AUC=0.646 | Time=20.37s\n","Epoch 167 | Loss=1.4756 | TestAcc=0.342 | F1=0.347 | AUC=0.662 | Time=20.49s\n","Epoch 168 | Loss=1.4684 | TestAcc=0.292 | F1=0.285 | AUC=0.653 | Time=20.60s\n","Epoch 169 | Loss=1.4498 | TestAcc=0.333 | F1=0.335 | AUC=0.679 | Time=20.71s\n","Epoch 170 | Loss=1.4236 | TestAcc=0.317 | F1=0.313 | AUC=0.629 | Time=20.83s\n","Epoch 171 | Loss=1.4470 | TestAcc=0.325 | F1=0.342 | AUC=0.655 | Time=20.95s\n","Epoch 172 | Loss=1.5027 | TestAcc=0.375 | F1=0.383 | AUC=0.671 | Time=21.07s\n","Epoch 173 | Loss=1.4566 | TestAcc=0.350 | F1=0.335 | AUC=0.634 | Time=21.19s\n","Epoch 174 | Loss=1.5144 | TestAcc=0.325 | F1=0.338 | AUC=0.666 | Time=21.31s\n","Epoch 175 | Loss=1.4713 | TestAcc=0.317 | F1=0.296 | AUC=0.680 | Time=21.50s\n","Epoch 176 | Loss=1.5228 | TestAcc=0.333 | F1=0.315 | AUC=0.671 | Time=21.66s\n","Epoch 177 | Loss=1.3878 | TestAcc=0.325 | F1=0.326 | AUC=0.693 | Time=21.81s\n","Epoch 178 | Loss=1.3764 | TestAcc=0.275 | F1=0.265 | AUC=0.668 | Time=22.00s\n","Epoch 179 | Loss=1.4209 | TestAcc=0.350 | F1=0.339 | AUC=0.672 | Time=22.14s\n","Epoch 180 | Loss=1.4151 | TestAcc=0.392 | F1=0.380 | AUC=0.666 | Time=22.29s\n","Epoch 181 | Loss=1.3910 | TestAcc=0.350 | F1=0.359 | AUC=0.657 | Time=22.45s\n","Epoch 182 | Loss=1.4595 | TestAcc=0.300 | F1=0.290 | AUC=0.645 | Time=22.62s\n","Epoch 183 | Loss=1.4439 | TestAcc=0.308 | F1=0.292 | AUC=0.636 | Time=22.78s\n","Epoch 184 | Loss=1.4101 | TestAcc=0.350 | F1=0.326 | AUC=0.660 | Time=22.94s\n","Epoch 185 | Loss=1.4672 | TestAcc=0.358 | F1=0.361 | AUC=0.676 | Time=23.11s\n","Epoch 186 | Loss=1.5311 | TestAcc=0.333 | F1=0.340 | AUC=0.698 | Time=23.26s\n","Epoch 187 | Loss=1.4637 | TestAcc=0.333 | F1=0.337 | AUC=0.667 | Time=23.41s\n","Epoch 188 | Loss=1.4641 | TestAcc=0.350 | F1=0.354 | AUC=0.688 | Time=23.56s\n","Epoch 189 | Loss=1.5196 | TestAcc=0.367 | F1=0.344 | AUC=0.672 | Time=23.71s\n","Epoch 190 | Loss=1.5584 | TestAcc=0.308 | F1=0.310 | AUC=0.638 | Time=23.88s\n","Epoch 191 | Loss=1.4372 | TestAcc=0.308 | F1=0.299 | AUC=0.643 | Time=24.04s\n","Epoch 192 | Loss=1.4479 | TestAcc=0.350 | F1=0.353 | AUC=0.673 | Time=24.22s\n","Epoch 193 | Loss=1.4650 | TestAcc=0.308 | F1=0.294 | AUC=0.625 | Time=24.41s\n","Epoch 194 | Loss=1.4609 | TestAcc=0.350 | F1=0.349 | AUC=0.660 | Time=24.56s\n","Epoch 195 | Loss=1.3969 | TestAcc=0.358 | F1=0.351 | AUC=0.665 | Time=24.68s\n","Epoch 196 | Loss=1.5384 | TestAcc=0.367 | F1=0.348 | AUC=0.659 | Time=24.79s\n","Epoch 197 | Loss=1.4999 | TestAcc=0.308 | F1=0.295 | AUC=0.669 | Time=24.90s\n","Epoch 198 | Loss=1.4111 | TestAcc=0.283 | F1=0.273 | AUC=0.673 | Time=25.02s\n","Epoch 199 | Loss=1.4312 | TestAcc=0.375 | F1=0.369 | AUC=0.682 | Time=25.14s\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:41:47,681] A new study created in memory with name: no-name-f31d47bc-a3af-4c99-a512-a0a016940ce2\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 200 | Loss=1.3775 | TestAcc=0.342 | F1=0.332 | AUC=0.683 | Time=25.26s\n","\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed  dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    43  ENZYMES                  yes                   64   \n","\n","  objective_weights  num_layers   dropout        lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           3  0.435401  0.007467      0.000015     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0          15     1.6486     1.6486    0.4167   0.4231    0.7309   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              25.26                 6.88             1440.0  \n","Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_ENZYMES_43.pth\n","Loaded dataset ENZYMES: 600 graphs, 3 node features, 6 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:41:48,354] Trial 0 finished with value: 0.3294524007720977 and parameters: {'num_layers': 5, 'dropout': 0.4554538945747439, 'lr': 0.0007963138616745652, 'weight_decay': 1.851762791900625e-05}. Best is trial 0 with value: 0.3294524007720977.\n","[I 2026-01-27 17:41:49,090] Trial 1 finished with value: 0.3220928548864769 and parameters: {'num_layers': 6, 'dropout': 0.15581551532426824, 'lr': 0.006596351407364286, 'weight_decay': 0.0002439696658539506}. Best is trial 0 with value: 0.3294524007720977.\n","[I 2026-01-27 17:41:49,600] Trial 2 finished with value: 0.34687654745122665 and parameters: {'num_layers': 3, 'dropout': 0.4036149238858609, 'lr': 0.0001319614490565822, 'weight_decay': 1.0417698860690217e-05}. Best is trial 2 with value: 0.34687654745122665.\n","[I 2026-01-27 17:41:50,232] Trial 3 finished with value: 0.21823031945072816 and parameters: {'num_layers': 5, 'dropout': 0.5602691042108918, 'lr': 0.00017023221111445692, 'weight_decay': 0.00012131277145411777}. Best is trial 2 with value: 0.34687654745122665.\n","[I 2026-01-27 17:41:50,811] Trial 4 finished with value: 0.3046584459543235 and parameters: {'num_layers': 4, 'dropout': 0.3607550985109112, 'lr': 0.00018795193819018922, 'weight_decay': 1.5816091621321565e-05}. Best is trial 2 with value: 0.34687654745122665.\n","[I 2026-01-27 17:41:51,367] Trial 5 finished with value: 0.4097893382776726 and parameters: {'num_layers': 4, 'dropout': 0.57762722320697, 'lr': 0.00706655370321506, 'weight_decay': 1.2922310221111748e-05}. Best is trial 5 with value: 0.4097893382776726.\n","[I 2026-01-27 17:41:51,886] Trial 6 finished with value: 0.37558041799410347 and parameters: {'num_layers': 3, 'dropout': 0.13532349792194504, 'lr': 0.004943379303713314, 'weight_decay': 1.8634596343177438e-06}. Best is trial 5 with value: 0.4097893382776726.\n","[I 2026-01-27 17:41:52,446] Trial 7 finished with value: 0.41523035593246105 and parameters: {'num_layers': 4, 'dropout': 0.1695997123032732, 'lr': 0.003016042378704602, 'weight_decay': 0.0005793735616898713}. Best is trial 7 with value: 0.41523035593246105.\n","[I 2026-01-27 17:41:53,079] Trial 8 finished with value: 0.23599894759764337 and parameters: {'num_layers': 5, 'dropout': 0.56950309585828, 'lr': 0.0018549041744229944, 'weight_decay': 7.383924642746918e-06}. Best is trial 7 with value: 0.41523035593246105.\n","[I 2026-01-27 17:41:53,793] Trial 9 finished with value: 0.2528803466761719 and parameters: {'num_layers': 6, 'dropout': 0.5204444767542562, 'lr': 0.000493964081570581, 'weight_decay': 9.328729498436833e-05}. Best is trial 7 with value: 0.41523035593246105.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 4, 'dropout': 0.1695997123032732, 'lr': 0.003016042378704602, 'weight_decay': 0.0005793735616898713}\n","\n","Running final training GIN...\n","{'num_layers': 4, 'dropout': 0.1695997123032732, 'lr': 0.003016042378704602, 'weight_decay': 0.0005793735616898713}\n","Epoch 001 | Loss=3.9202 | TestAcc=0.167 | F1=0.161 | AUC=0.505 | Time=0.14s\n","Epoch 002 | Loss=2.7112 | TestAcc=0.233 | F1=0.215 | AUC=0.550 | Time=0.28s\n","Epoch 003 | Loss=2.6291 | TestAcc=0.258 | F1=0.266 | AUC=0.600 | Time=0.41s\n","Epoch 004 | Loss=2.2990 | TestAcc=0.250 | F1=0.235 | AUC=0.627 | Time=0.54s\n","Epoch 005 | Loss=2.1031 | TestAcc=0.283 | F1=0.259 | AUC=0.669 | Time=0.67s\n","Epoch 006 | Loss=1.9967 | TestAcc=0.333 | F1=0.304 | AUC=0.676 | Time=0.80s\n","Epoch 007 | Loss=1.7386 | TestAcc=0.358 | F1=0.341 | AUC=0.698 | Time=0.94s\n","Epoch 008 | Loss=1.6493 | TestAcc=0.275 | F1=0.271 | AUC=0.625 | Time=1.08s\n","Epoch 009 | Loss=1.6442 | TestAcc=0.367 | F1=0.342 | AUC=0.726 | Time=1.21s\n","Epoch 010 | Loss=1.5948 | TestAcc=0.350 | F1=0.325 | AUC=0.687 | Time=1.34s\n","Epoch 011 | Loss=1.5720 | TestAcc=0.275 | F1=0.273 | AUC=0.683 | Time=1.46s\n","Epoch 012 | Loss=1.5537 | TestAcc=0.383 | F1=0.372 | AUC=0.710 | Time=1.59s\n","Epoch 013 | Loss=1.4949 | TestAcc=0.408 | F1=0.387 | AUC=0.717 | Time=1.73s\n","Epoch 014 | Loss=1.4431 | TestAcc=0.317 | F1=0.317 | AUC=0.686 | Time=1.87s\n","Epoch 015 | Loss=1.4981 | TestAcc=0.350 | F1=0.329 | AUC=0.691 | Time=2.02s\n","Epoch 016 | Loss=1.4782 | TestAcc=0.342 | F1=0.327 | AUC=0.717 | Time=2.16s\n","Epoch 017 | Loss=1.4408 | TestAcc=0.375 | F1=0.375 | AUC=0.724 | Time=2.29s\n","Epoch 018 | Loss=1.4102 | TestAcc=0.433 | F1=0.424 | AUC=0.720 | Time=2.42s\n","Epoch 019 | Loss=1.3186 | TestAcc=0.392 | F1=0.397 | AUC=0.744 | Time=2.55s\n","Epoch 020 | Loss=1.3334 | TestAcc=0.425 | F1=0.404 | AUC=0.751 | Time=2.68s\n","Epoch 021 | Loss=1.3312 | TestAcc=0.408 | F1=0.407 | AUC=0.693 | Time=2.81s\n","Epoch 022 | Loss=1.3320 | TestAcc=0.367 | F1=0.366 | AUC=0.703 | Time=2.95s\n","Epoch 023 | Loss=1.3426 | TestAcc=0.408 | F1=0.396 | AUC=0.716 | Time=3.12s\n","Epoch 024 | Loss=1.2609 | TestAcc=0.325 | F1=0.308 | AUC=0.675 | Time=3.31s\n","Epoch 025 | Loss=1.3477 | TestAcc=0.425 | F1=0.422 | AUC=0.727 | Time=3.48s\n","Epoch 026 | Loss=1.2408 | TestAcc=0.383 | F1=0.377 | AUC=0.724 | Time=3.66s\n","Epoch 027 | Loss=1.2537 | TestAcc=0.417 | F1=0.405 | AUC=0.716 | Time=3.82s\n","Epoch 028 | Loss=1.2806 | TestAcc=0.358 | F1=0.337 | AUC=0.701 | Time=4.02s\n","Epoch 029 | Loss=1.2385 | TestAcc=0.367 | F1=0.360 | AUC=0.693 | Time=4.21s\n","Epoch 030 | Loss=1.2432 | TestAcc=0.392 | F1=0.385 | AUC=0.719 | Time=4.39s\n","Epoch 031 | Loss=1.1660 | TestAcc=0.408 | F1=0.410 | AUC=0.719 | Time=4.57s\n","Epoch 032 | Loss=1.3632 | TestAcc=0.417 | F1=0.408 | AUC=0.734 | Time=4.75s\n","Epoch 033 | Loss=1.2304 | TestAcc=0.417 | F1=0.411 | AUC=0.725 | Time=4.92s\n","Epoch 034 | Loss=1.2311 | TestAcc=0.408 | F1=0.412 | AUC=0.730 | Time=5.11s\n","Epoch 035 | Loss=1.1947 | TestAcc=0.350 | F1=0.345 | AUC=0.691 | Time=5.28s\n","Epoch 036 | Loss=1.1615 | TestAcc=0.425 | F1=0.413 | AUC=0.734 | Time=5.46s\n","Epoch 037 | Loss=1.2559 | TestAcc=0.375 | F1=0.363 | AUC=0.677 | Time=5.65s\n","Epoch 038 | Loss=1.2107 | TestAcc=0.442 | F1=0.438 | AUC=0.756 | Time=5.84s\n","Epoch 039 | Loss=1.2133 | TestAcc=0.500 | F1=0.481 | AUC=0.755 | Time=6.04s\n","Epoch 040 | Loss=1.1530 | TestAcc=0.408 | F1=0.403 | AUC=0.764 | Time=6.22s\n","Epoch 041 | Loss=1.1709 | TestAcc=0.367 | F1=0.365 | AUC=0.725 | Time=6.34s\n","Epoch 042 | Loss=1.1236 | TestAcc=0.375 | F1=0.358 | AUC=0.690 | Time=6.48s\n","Epoch 043 | Loss=1.1374 | TestAcc=0.400 | F1=0.399 | AUC=0.719 | Time=6.60s\n","Epoch 044 | Loss=1.1063 | TestAcc=0.375 | F1=0.364 | AUC=0.681 | Time=6.73s\n","Epoch 045 | Loss=1.0554 | TestAcc=0.383 | F1=0.365 | AUC=0.732 | Time=6.86s\n","Epoch 046 | Loss=1.1796 | TestAcc=0.317 | F1=0.292 | AUC=0.697 | Time=6.99s\n","Epoch 047 | Loss=1.2308 | TestAcc=0.350 | F1=0.332 | AUC=0.704 | Time=7.11s\n","Epoch 048 | Loss=1.0870 | TestAcc=0.367 | F1=0.373 | AUC=0.719 | Time=7.27s\n","Epoch 049 | Loss=1.1483 | TestAcc=0.425 | F1=0.429 | AUC=0.720 | Time=7.40s\n","Epoch 050 | Loss=1.0219 | TestAcc=0.408 | F1=0.402 | AUC=0.723 | Time=7.53s\n","Epoch 051 | Loss=0.9333 | TestAcc=0.442 | F1=0.440 | AUC=0.717 | Time=7.66s\n","Epoch 052 | Loss=1.0337 | TestAcc=0.425 | F1=0.416 | AUC=0.752 | Time=7.79s\n","Epoch 053 | Loss=1.1044 | TestAcc=0.425 | F1=0.411 | AUC=0.731 | Time=7.92s\n","Epoch 054 | Loss=0.9958 | TestAcc=0.458 | F1=0.462 | AUC=0.746 | Time=8.05s\n","Epoch 055 | Loss=1.0229 | TestAcc=0.383 | F1=0.378 | AUC=0.732 | Time=8.19s\n","Epoch 056 | Loss=0.9742 | TestAcc=0.392 | F1=0.376 | AUC=0.722 | Time=8.33s\n","Epoch 057 | Loss=1.0141 | TestAcc=0.417 | F1=0.415 | AUC=0.757 | Time=8.45s\n","Epoch 058 | Loss=0.9748 | TestAcc=0.433 | F1=0.425 | AUC=0.741 | Time=8.58s\n","Epoch 059 | Loss=1.0044 | TestAcc=0.367 | F1=0.368 | AUC=0.714 | Time=8.71s\n","Epoch 060 | Loss=1.0306 | TestAcc=0.367 | F1=0.369 | AUC=0.715 | Time=8.84s\n","Epoch 061 | Loss=1.0234 | TestAcc=0.475 | F1=0.465 | AUC=0.768 | Time=8.98s\n","Epoch 062 | Loss=0.9297 | TestAcc=0.425 | F1=0.426 | AUC=0.734 | Time=9.13s\n","Epoch 063 | Loss=0.9595 | TestAcc=0.408 | F1=0.401 | AUC=0.731 | Time=9.29s\n","Epoch 064 | Loss=0.9416 | TestAcc=0.358 | F1=0.346 | AUC=0.727 | Time=9.42s\n","Epoch 065 | Loss=1.0504 | TestAcc=0.392 | F1=0.385 | AUC=0.727 | Time=9.55s\n","Epoch 066 | Loss=1.0399 | TestAcc=0.400 | F1=0.390 | AUC=0.715 | Time=9.68s\n","Epoch 067 | Loss=1.0236 | TestAcc=0.442 | F1=0.437 | AUC=0.764 | Time=9.81s\n","Epoch 068 | Loss=0.9106 | TestAcc=0.400 | F1=0.393 | AUC=0.717 | Time=9.94s\n","Epoch 069 | Loss=0.9424 | TestAcc=0.458 | F1=0.459 | AUC=0.744 | Time=10.07s\n","Epoch 070 | Loss=0.9357 | TestAcc=0.392 | F1=0.382 | AUC=0.734 | Time=10.21s\n","Epoch 071 | Loss=1.0673 | TestAcc=0.433 | F1=0.428 | AUC=0.765 | Time=10.35s\n","Epoch 072 | Loss=0.8782 | TestAcc=0.408 | F1=0.412 | AUC=0.736 | Time=10.48s\n","Epoch 073 | Loss=0.9070 | TestAcc=0.458 | F1=0.464 | AUC=0.737 | Time=10.61s\n","Epoch 074 | Loss=0.7671 | TestAcc=0.458 | F1=0.458 | AUC=0.733 | Time=10.74s\n","Epoch 075 | Loss=0.9262 | TestAcc=0.425 | F1=0.429 | AUC=0.723 | Time=10.87s\n","Epoch 076 | Loss=1.0369 | TestAcc=0.333 | F1=0.337 | AUC=0.677 | Time=11.01s\n","Epoch 077 | Loss=0.9864 | TestAcc=0.367 | F1=0.367 | AUC=0.681 | Time=11.14s\n","Epoch 078 | Loss=0.9574 | TestAcc=0.433 | F1=0.424 | AUC=0.744 | Time=11.28s\n","Epoch 079 | Loss=0.8634 | TestAcc=0.408 | F1=0.406 | AUC=0.710 | Time=11.41s\n","Epoch 080 | Loss=0.9922 | TestAcc=0.342 | F1=0.345 | AUC=0.687 | Time=11.55s\n","Epoch 081 | Loss=0.8494 | TestAcc=0.450 | F1=0.455 | AUC=0.732 | Time=11.68s\n","Epoch 082 | Loss=0.9157 | TestAcc=0.408 | F1=0.389 | AUC=0.737 | Time=11.81s\n","Epoch 083 | Loss=0.8886 | TestAcc=0.375 | F1=0.387 | AUC=0.721 | Time=11.94s\n","Epoch 084 | Loss=0.8795 | TestAcc=0.442 | F1=0.446 | AUC=0.754 | Time=12.07s\n","Epoch 085 | Loss=0.8991 | TestAcc=0.442 | F1=0.435 | AUC=0.738 | Time=12.21s\n","Epoch 086 | Loss=0.9359 | TestAcc=0.333 | F1=0.336 | AUC=0.699 | Time=12.35s\n","Epoch 087 | Loss=0.9874 | TestAcc=0.375 | F1=0.376 | AUC=0.708 | Time=12.49s\n","Epoch 088 | Loss=0.9118 | TestAcc=0.400 | F1=0.389 | AUC=0.719 | Time=12.62s\n","Epoch 089 | Loss=0.9759 | TestAcc=0.408 | F1=0.383 | AUC=0.717 | Time=12.75s\n","Epoch 090 | Loss=0.9197 | TestAcc=0.425 | F1=0.422 | AUC=0.704 | Time=12.89s\n","Epoch 091 | Loss=0.8790 | TestAcc=0.467 | F1=0.463 | AUC=0.754 | Time=13.02s\n","Epoch 092 | Loss=0.8807 | TestAcc=0.458 | F1=0.458 | AUC=0.748 | Time=13.16s\n","Epoch 093 | Loss=0.8736 | TestAcc=0.408 | F1=0.393 | AUC=0.735 | Time=13.29s\n","Epoch 094 | Loss=0.8044 | TestAcc=0.400 | F1=0.401 | AUC=0.717 | Time=13.43s\n","Epoch 095 | Loss=0.7656 | TestAcc=0.383 | F1=0.388 | AUC=0.702 | Time=13.56s\n","Epoch 096 | Loss=0.9010 | TestAcc=0.425 | F1=0.429 | AUC=0.737 | Time=13.69s\n","Epoch 097 | Loss=0.9150 | TestAcc=0.417 | F1=0.415 | AUC=0.724 | Time=13.82s\n","Epoch 098 | Loss=0.8172 | TestAcc=0.408 | F1=0.415 | AUC=0.718 | Time=13.96s\n","Epoch 099 | Loss=0.8389 | TestAcc=0.383 | F1=0.366 | AUC=0.743 | Time=14.09s\n","Epoch 100 | Loss=0.7829 | TestAcc=0.367 | F1=0.353 | AUC=0.698 | Time=14.22s\n","Epoch 101 | Loss=0.8584 | TestAcc=0.442 | F1=0.444 | AUC=0.722 | Time=14.36s\n","Epoch 102 | Loss=0.7677 | TestAcc=0.408 | F1=0.409 | AUC=0.756 | Time=14.51s\n","Epoch 103 | Loss=0.7776 | TestAcc=0.433 | F1=0.439 | AUC=0.737 | Time=14.63s\n","Epoch 104 | Loss=0.9002 | TestAcc=0.383 | F1=0.379 | AUC=0.711 | Time=14.76s\n","Epoch 105 | Loss=0.9003 | TestAcc=0.450 | F1=0.449 | AUC=0.738 | Time=14.89s\n","Epoch 106 | Loss=0.8514 | TestAcc=0.400 | F1=0.402 | AUC=0.724 | Time=15.02s\n","Epoch 107 | Loss=0.8359 | TestAcc=0.358 | F1=0.361 | AUC=0.726 | Time=15.15s\n","Epoch 108 | Loss=0.8050 | TestAcc=0.408 | F1=0.400 | AUC=0.710 | Time=15.28s\n","Epoch 109 | Loss=0.9144 | TestAcc=0.450 | F1=0.455 | AUC=0.730 | Time=15.42s\n","Epoch 110 | Loss=0.9327 | TestAcc=0.475 | F1=0.467 | AUC=0.764 | Time=15.55s\n","Epoch 111 | Loss=0.8770 | TestAcc=0.408 | F1=0.404 | AUC=0.729 | Time=15.68s\n","Epoch 112 | Loss=1.0564 | TestAcc=0.367 | F1=0.360 | AUC=0.694 | Time=15.81s\n","Epoch 113 | Loss=0.7907 | TestAcc=0.458 | F1=0.452 | AUC=0.771 | Time=15.93s\n","Epoch 114 | Loss=0.8327 | TestAcc=0.392 | F1=0.388 | AUC=0.735 | Time=16.06s\n","Epoch 115 | Loss=0.7999 | TestAcc=0.442 | F1=0.438 | AUC=0.728 | Time=16.22s\n","Epoch 116 | Loss=0.7640 | TestAcc=0.400 | F1=0.394 | AUC=0.721 | Time=16.41s\n","Epoch 117 | Loss=0.6620 | TestAcc=0.433 | F1=0.431 | AUC=0.756 | Time=16.60s\n","Epoch 118 | Loss=0.7075 | TestAcc=0.442 | F1=0.442 | AUC=0.732 | Time=16.77s\n","Epoch 119 | Loss=0.8599 | TestAcc=0.450 | F1=0.443 | AUC=0.737 | Time=16.95s\n","Epoch 120 | Loss=0.7013 | TestAcc=0.417 | F1=0.413 | AUC=0.725 | Time=17.12s\n","Epoch 121 | Loss=0.7527 | TestAcc=0.425 | F1=0.429 | AUC=0.748 | Time=17.30s\n","Epoch 122 | Loss=0.6972 | TestAcc=0.433 | F1=0.434 | AUC=0.747 | Time=17.50s\n","Epoch 123 | Loss=0.7260 | TestAcc=0.442 | F1=0.433 | AUC=0.728 | Time=17.69s\n","Epoch 124 | Loss=0.7462 | TestAcc=0.350 | F1=0.349 | AUC=0.725 | Time=17.88s\n","Epoch 125 | Loss=0.7145 | TestAcc=0.450 | F1=0.444 | AUC=0.753 | Time=18.05s\n","Epoch 126 | Loss=0.6812 | TestAcc=0.450 | F1=0.442 | AUC=0.764 | Time=18.23s\n","Epoch 127 | Loss=0.7270 | TestAcc=0.383 | F1=0.371 | AUC=0.719 | Time=18.39s\n","Epoch 128 | Loss=0.7208 | TestAcc=0.408 | F1=0.402 | AUC=0.739 | Time=18.56s\n","Epoch 129 | Loss=0.7573 | TestAcc=0.367 | F1=0.374 | AUC=0.709 | Time=18.75s\n","Epoch 130 | Loss=0.8199 | TestAcc=0.367 | F1=0.363 | AUC=0.685 | Time=18.95s\n","Epoch 131 | Loss=0.7597 | TestAcc=0.417 | F1=0.408 | AUC=0.740 | Time=19.14s\n","Epoch 132 | Loss=0.7402 | TestAcc=0.442 | F1=0.440 | AUC=0.725 | Time=19.34s\n","Epoch 133 | Loss=0.7448 | TestAcc=0.425 | F1=0.427 | AUC=0.722 | Time=19.47s\n","Epoch 134 | Loss=0.8604 | TestAcc=0.433 | F1=0.434 | AUC=0.727 | Time=19.61s\n","Epoch 135 | Loss=0.7376 | TestAcc=0.383 | F1=0.384 | AUC=0.720 | Time=19.75s\n","Epoch 136 | Loss=0.7016 | TestAcc=0.408 | F1=0.409 | AUC=0.739 | Time=19.88s\n","Epoch 137 | Loss=0.6469 | TestAcc=0.408 | F1=0.406 | AUC=0.741 | Time=20.01s\n","Epoch 138 | Loss=0.6034 | TestAcc=0.483 | F1=0.479 | AUC=0.749 | Time=20.15s\n","Epoch 139 | Loss=0.6546 | TestAcc=0.475 | F1=0.483 | AUC=0.740 | Time=20.27s\n","Epoch 140 | Loss=0.6943 | TestAcc=0.408 | F1=0.401 | AUC=0.738 | Time=20.41s\n","Epoch 141 | Loss=0.6958 | TestAcc=0.417 | F1=0.410 | AUC=0.705 | Time=20.53s\n","Epoch 142 | Loss=0.6177 | TestAcc=0.442 | F1=0.432 | AUC=0.736 | Time=20.66s\n","Epoch 143 | Loss=0.5555 | TestAcc=0.467 | F1=0.471 | AUC=0.737 | Time=20.80s\n","Epoch 144 | Loss=0.5550 | TestAcc=0.442 | F1=0.443 | AUC=0.721 | Time=20.93s\n","Epoch 145 | Loss=0.6282 | TestAcc=0.425 | F1=0.431 | AUC=0.757 | Time=21.06s\n","Epoch 146 | Loss=0.6093 | TestAcc=0.417 | F1=0.415 | AUC=0.721 | Time=21.20s\n","Epoch 147 | Loss=0.6900 | TestAcc=0.492 | F1=0.488 | AUC=0.750 | Time=21.32s\n","Epoch 148 | Loss=0.7362 | TestAcc=0.333 | F1=0.332 | AUC=0.647 | Time=21.46s\n","Epoch 149 | Loss=0.6887 | TestAcc=0.450 | F1=0.449 | AUC=0.746 | Time=21.60s\n","Epoch 150 | Loss=0.7830 | TestAcc=0.425 | F1=0.424 | AUC=0.720 | Time=21.75s\n","Epoch 151 | Loss=0.6442 | TestAcc=0.433 | F1=0.430 | AUC=0.745 | Time=21.88s\n","Epoch 152 | Loss=0.6714 | TestAcc=0.425 | F1=0.428 | AUC=0.718 | Time=22.02s\n","Epoch 153 | Loss=0.7324 | TestAcc=0.458 | F1=0.456 | AUC=0.751 | Time=22.15s\n","Epoch 154 | Loss=0.5663 | TestAcc=0.458 | F1=0.453 | AUC=0.751 | Time=22.28s\n","Epoch 155 | Loss=0.6218 | TestAcc=0.425 | F1=0.415 | AUC=0.700 | Time=22.41s\n","Epoch 156 | Loss=0.7049 | TestAcc=0.433 | F1=0.433 | AUC=0.734 | Time=22.54s\n","Epoch 157 | Loss=0.5560 | TestAcc=0.433 | F1=0.434 | AUC=0.755 | Time=22.67s\n","Epoch 158 | Loss=0.6486 | TestAcc=0.400 | F1=0.400 | AUC=0.752 | Time=22.81s\n","Epoch 159 | Loss=0.6233 | TestAcc=0.467 | F1=0.465 | AUC=0.742 | Time=22.94s\n","Epoch 160 | Loss=0.5935 | TestAcc=0.450 | F1=0.442 | AUC=0.756 | Time=23.07s\n","Epoch 161 | Loss=0.5687 | TestAcc=0.408 | F1=0.408 | AUC=0.748 | Time=23.20s\n","Epoch 162 | Loss=0.6131 | TestAcc=0.442 | F1=0.439 | AUC=0.754 | Time=23.34s\n","Epoch 163 | Loss=0.5400 | TestAcc=0.458 | F1=0.454 | AUC=0.758 | Time=23.46s\n","Epoch 164 | Loss=0.6071 | TestAcc=0.408 | F1=0.405 | AUC=0.716 | Time=23.59s\n","Epoch 165 | Loss=0.6336 | TestAcc=0.425 | F1=0.432 | AUC=0.726 | Time=23.72s\n","Epoch 166 | Loss=0.6760 | TestAcc=0.442 | F1=0.405 | AUC=0.738 | Time=23.86s\n","Epoch 167 | Loss=0.7845 | TestAcc=0.392 | F1=0.396 | AUC=0.726 | Time=23.99s\n","Epoch 168 | Loss=0.7289 | TestAcc=0.433 | F1=0.430 | AUC=0.760 | Time=24.13s\n","Epoch 169 | Loss=0.7665 | TestAcc=0.367 | F1=0.351 | AUC=0.688 | Time=24.26s\n","Epoch 170 | Loss=0.6208 | TestAcc=0.367 | F1=0.367 | AUC=0.718 | Time=24.39s\n","Epoch 171 | Loss=0.5923 | TestAcc=0.467 | F1=0.468 | AUC=0.745 | Time=24.52s\n","Epoch 172 | Loss=0.6681 | TestAcc=0.342 | F1=0.340 | AUC=0.714 | Time=24.65s\n","Epoch 173 | Loss=0.7369 | TestAcc=0.442 | F1=0.443 | AUC=0.733 | Time=24.78s\n","Epoch 174 | Loss=0.5928 | TestAcc=0.475 | F1=0.476 | AUC=0.727 | Time=24.92s\n","Epoch 175 | Loss=0.6042 | TestAcc=0.392 | F1=0.391 | AUC=0.718 | Time=25.05s\n","Epoch 176 | Loss=0.6013 | TestAcc=0.342 | F1=0.344 | AUC=0.693 | Time=25.18s\n","Epoch 177 | Loss=0.6040 | TestAcc=0.442 | F1=0.442 | AUC=0.742 | Time=25.31s\n","Epoch 178 | Loss=0.5120 | TestAcc=0.458 | F1=0.464 | AUC=0.765 | Time=25.45s\n","Epoch 179 | Loss=0.6071 | TestAcc=0.442 | F1=0.434 | AUC=0.728 | Time=25.58s\n","Epoch 180 | Loss=0.5489 | TestAcc=0.458 | F1=0.455 | AUC=0.742 | Time=25.71s\n","Epoch 181 | Loss=0.6402 | TestAcc=0.392 | F1=0.395 | AUC=0.693 | Time=25.83s\n","Epoch 182 | Loss=0.5968 | TestAcc=0.433 | F1=0.434 | AUC=0.732 | Time=25.98s\n","Epoch 183 | Loss=0.6221 | TestAcc=0.392 | F1=0.384 | AUC=0.722 | Time=26.11s\n","Epoch 184 | Loss=0.6150 | TestAcc=0.425 | F1=0.426 | AUC=0.743 | Time=26.24s\n","Epoch 185 | Loss=0.6192 | TestAcc=0.508 | F1=0.508 | AUC=0.753 | Time=26.37s\n","Epoch 186 | Loss=0.6575 | TestAcc=0.450 | F1=0.444 | AUC=0.731 | Time=26.50s\n","Epoch 187 | Loss=0.5412 | TestAcc=0.433 | F1=0.432 | AUC=0.723 | Time=26.63s\n","Epoch 188 | Loss=0.5918 | TestAcc=0.433 | F1=0.435 | AUC=0.740 | Time=26.76s\n","Epoch 189 | Loss=0.6270 | TestAcc=0.467 | F1=0.467 | AUC=0.749 | Time=26.90s\n","Epoch 190 | Loss=0.5458 | TestAcc=0.425 | F1=0.426 | AUC=0.736 | Time=27.04s\n","Epoch 191 | Loss=0.6237 | TestAcc=0.425 | F1=0.418 | AUC=0.746 | Time=27.16s\n","Epoch 192 | Loss=0.6563 | TestAcc=0.458 | F1=0.461 | AUC=0.727 | Time=27.30s\n","Epoch 193 | Loss=0.7886 | TestAcc=0.392 | F1=0.392 | AUC=0.704 | Time=27.43s\n","Epoch 194 | Loss=0.6028 | TestAcc=0.450 | F1=0.446 | AUC=0.740 | Time=27.57s\n","Epoch 195 | Loss=0.6292 | TestAcc=0.392 | F1=0.391 | AUC=0.718 | Time=27.70s\n","Epoch 196 | Loss=0.5846 | TestAcc=0.417 | F1=0.422 | AUC=0.757 | Time=27.83s\n","Epoch 197 | Loss=0.4481 | TestAcc=0.467 | F1=0.464 | AUC=0.756 | Time=27.98s\n","Epoch 198 | Loss=0.5494 | TestAcc=0.433 | F1=0.438 | AUC=0.748 | Time=28.12s\n","Epoch 199 | Loss=0.5602 | TestAcc=0.442 | F1=0.446 | AUC=0.740 | Time=28.25s\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:42:22,304] A new study created in memory with name: no-name-d9dbcd8e-3a44-4dde-969c-7eb4a7fda476\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 200 | Loss=0.5922 | TestAcc=0.442 | F1=0.445 | AUC=0.755 | Time=28.39s\n","\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed  dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    44  ENZYMES                  yes                   64   \n","\n","  objective_weights  num_layers  dropout        lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           4   0.1696  0.003016      0.000579     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0         185     2.3739     2.3739    0.5083   0.5084    0.7528   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              28.39                 6.11            1440.02  \n","Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_ENZYMES_44.pth\n","Loaded dataset MUTAG: 188 graphs, 7 node features, 2 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:42:22,543] Trial 0 finished with value: 0.7618562753036437 and parameters: {'num_layers': 5, 'dropout': 0.2480007873539216, 'lr': 0.005519380439870522, 'weight_decay': 7.749636253915167e-05}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:22,805] Trial 1 finished with value: 0.652973587815693 and parameters: {'num_layers': 6, 'dropout': 0.49973103881484837, 'lr': 0.00044192139892283315, 'weight_decay': 1.8130482056423905e-06}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:23,053] Trial 2 finished with value: 0.68189666473877 and parameters: {'num_layers': 6, 'dropout': 0.3526095357156409, 'lr': 0.0002935798515351089, 'weight_decay': 6.147739358123621e-06}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:23,388] Trial 3 finished with value: 0.3815284591569421 and parameters: {'num_layers': 6, 'dropout': 0.0047523083087558145, 'lr': 0.0010536782948178676, 'weight_decay': 1.245252942445855e-06}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:23,679] Trial 4 finished with value: 0.3517077316808039 and parameters: {'num_layers': 5, 'dropout': 0.35839637150819226, 'lr': 0.00010614867674935168, 'weight_decay': 1.0132110959171085e-05}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:24,025] Trial 5 finished with value: 0.2326053822338652 and parameters: {'num_layers': 6, 'dropout': 0.19791760617251175, 'lr': 0.001964799145830946, 'weight_decay': 0.00024688846012731473}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:24,305] Trial 6 finished with value: 0.5766658955080007 and parameters: {'num_layers': 4, 'dropout': 0.23796893340766365, 'lr': 0.00772706494440349, 'weight_decay': 3.9748747565087e-05}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:24,585] Trial 7 finished with value: 0.2535284591569421 and parameters: {'num_layers': 4, 'dropout': 0.05681249573472055, 'lr': 0.0002680702354827701, 'weight_decay': 4.580150658212966e-06}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:24,848] Trial 8 finished with value: 0.7379031407800889 and parameters: {'num_layers': 4, 'dropout': 0.38590785620401247, 'lr': 0.0026951343962554743, 'weight_decay': 3.7230064911183556e-06}. Best is trial 0 with value: 0.7618562753036437.\n","[I 2026-01-27 17:42:25,123] Trial 9 finished with value: 0.26522076684924983 and parameters: {'num_layers': 4, 'dropout': 0.5172408449704996, 'lr': 0.00047544988567011615, 'weight_decay': 0.0005775639861776684}. Best is trial 0 with value: 0.7618562753036437.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 5, 'dropout': 0.2480007873539216, 'lr': 0.005519380439870522, 'weight_decay': 7.749636253915167e-05}\n","\n","Running final training GIN...\n","{'num_layers': 5, 'dropout': 0.2480007873539216, 'lr': 0.005519380439870522, 'weight_decay': 7.749636253915167e-05}\n","Epoch 001 | Loss=0.8902 | TestAcc=0.658 | F1=0.522 | AUC=0.938 | Time=0.07s\n","Epoch 002 | Loss=0.8633 | TestAcc=0.684 | F1=0.612 | AUC=0.865 | Time=0.14s\n","Epoch 003 | Loss=0.5682 | TestAcc=0.816 | F1=0.820 | AUC=0.865 | Time=0.21s\n","Epoch 004 | Loss=0.4030 | TestAcc=0.842 | F1=0.846 | AUC=0.849 | Time=0.27s\n","Epoch 005 | Loss=0.3590 | TestAcc=0.711 | F1=0.713 | AUC=0.874 | Time=0.34s\n","Epoch 006 | Loss=0.4203 | TestAcc=0.684 | F1=0.684 | AUC=0.883 | Time=0.41s\n","Epoch 007 | Loss=0.3379 | TestAcc=0.789 | F1=0.794 | AUC=0.892 | Time=0.48s\n","Epoch 008 | Loss=0.3390 | TestAcc=0.868 | F1=0.872 | AUC=0.923 | Time=0.56s\n","Epoch 009 | Loss=0.2970 | TestAcc=0.868 | F1=0.867 | AUC=0.935 | Time=0.64s\n","Epoch 010 | Loss=0.2906 | TestAcc=0.895 | F1=0.895 | AUC=0.945 | Time=0.71s\n","Epoch 011 | Loss=0.2655 | TestAcc=0.974 | F1=0.974 | AUC=0.972 | Time=0.80s\n","Epoch 012 | Loss=0.2644 | TestAcc=0.947 | F1=0.947 | AUC=0.966 | Time=0.88s\n","Epoch 013 | Loss=0.4147 | TestAcc=0.789 | F1=0.769 | AUC=0.966 | Time=0.97s\n","Epoch 014 | Loss=0.2572 | TestAcc=0.895 | F1=0.892 | AUC=0.957 | Time=1.05s\n","Epoch 015 | Loss=0.2976 | TestAcc=0.895 | F1=0.892 | AUC=0.963 | Time=1.13s\n","Epoch 016 | Loss=0.2509 | TestAcc=0.842 | F1=0.834 | AUC=0.954 | Time=1.22s\n","Epoch 017 | Loss=0.2779 | TestAcc=0.816 | F1=0.802 | AUC=0.954 | Time=1.27s\n","Epoch 018 | Loss=0.3069 | TestAcc=0.921 | F1=0.920 | AUC=0.969 | Time=1.32s\n","Epoch 019 | Loss=0.2466 | TestAcc=0.895 | F1=0.897 | AUC=0.942 | Time=1.37s\n","Epoch 020 | Loss=0.2187 | TestAcc=0.842 | F1=0.846 | AUC=0.945 | Time=1.43s\n","Epoch 021 | Loss=0.2166 | TestAcc=0.921 | F1=0.922 | AUC=0.966 | Time=1.48s\n","Epoch 022 | Loss=0.2622 | TestAcc=0.737 | F1=0.731 | AUC=0.898 | Time=1.53s\n","Epoch 023 | Loss=0.2455 | TestAcc=0.789 | F1=0.757 | AUC=0.942 | Time=1.58s\n","Epoch 024 | Loss=0.1582 | TestAcc=0.921 | F1=0.920 | AUC=0.991 | Time=1.64s\n","Epoch 025 | Loss=0.1996 | TestAcc=0.868 | F1=0.864 | AUC=0.963 | Time=1.69s\n","Epoch 026 | Loss=0.2032 | TestAcc=0.895 | F1=0.897 | AUC=0.935 | Time=1.75s\n","Epoch 027 | Loss=0.2836 | TestAcc=0.868 | F1=0.864 | AUC=0.963 | Time=1.80s\n","Epoch 028 | Loss=0.1948 | TestAcc=0.737 | F1=0.697 | AUC=0.905 | Time=1.86s\n","Epoch 029 | Loss=0.1911 | TestAcc=0.789 | F1=0.769 | AUC=0.905 | Time=1.92s\n","Epoch 030 | Loss=0.2203 | TestAcc=0.816 | F1=0.802 | AUC=0.945 | Time=1.97s\n","Epoch 031 | Loss=0.1626 | TestAcc=0.816 | F1=0.802 | AUC=0.926 | Time=2.02s\n","Epoch 032 | Loss=0.2124 | TestAcc=0.842 | F1=0.846 | AUC=0.948 | Time=2.07s\n","Epoch 033 | Loss=0.2474 | TestAcc=0.816 | F1=0.820 | AUC=0.902 | Time=2.13s\n","Epoch 034 | Loss=0.2902 | TestAcc=0.789 | F1=0.769 | AUC=0.945 | Time=2.18s\n","Epoch 035 | Loss=0.1938 | TestAcc=0.789 | F1=0.769 | AUC=0.891 | Time=2.23s\n","Epoch 036 | Loss=0.2035 | TestAcc=0.789 | F1=0.769 | AUC=0.902 | Time=2.28s\n","Epoch 037 | Loss=0.2530 | TestAcc=0.789 | F1=0.769 | AUC=0.948 | Time=2.34s\n","Epoch 038 | Loss=0.3177 | TestAcc=0.816 | F1=0.802 | AUC=0.929 | Time=2.39s\n","Epoch 039 | Loss=0.3031 | TestAcc=0.816 | F1=0.802 | AUC=0.929 | Time=2.44s\n","Epoch 040 | Loss=0.2476 | TestAcc=0.737 | F1=0.697 | AUC=0.803 | Time=2.49s\n","Epoch 041 | Loss=0.2762 | TestAcc=0.737 | F1=0.697 | AUC=0.812 | Time=2.54s\n","Epoch 042 | Loss=0.2211 | TestAcc=0.737 | F1=0.677 | AUC=0.903 | Time=2.60s\n","Epoch 043 | Loss=0.2279 | TestAcc=0.763 | F1=0.719 | AUC=0.831 | Time=2.65s\n","Epoch 044 | Loss=0.2112 | TestAcc=0.789 | F1=0.757 | AUC=0.862 | Time=2.70s\n","Epoch 045 | Loss=0.1720 | TestAcc=0.816 | F1=0.793 | AUC=0.923 | Time=2.75s\n","Epoch 046 | Loss=0.1583 | TestAcc=0.816 | F1=0.793 | AUC=0.975 | Time=2.80s\n","Epoch 047 | Loss=0.1577 | TestAcc=0.921 | F1=0.920 | AUC=0.994 | Time=2.86s\n","Epoch 048 | Loss=0.4134 | TestAcc=0.921 | F1=0.920 | AUC=0.988 | Time=2.93s\n","Epoch 049 | Loss=0.2370 | TestAcc=0.763 | F1=0.719 | AUC=0.969 | Time=2.98s\n","Epoch 050 | Loss=0.3402 | TestAcc=0.789 | F1=0.769 | AUC=0.942 | Time=3.03s\n","Epoch 051 | Loss=0.2651 | TestAcc=0.842 | F1=0.834 | AUC=0.905 | Time=3.08s\n","Epoch 052 | Loss=0.2632 | TestAcc=0.868 | F1=0.864 | AUC=0.926 | Time=3.13s\n","Epoch 053 | Loss=0.2817 | TestAcc=0.868 | F1=0.864 | AUC=0.914 | Time=3.18s\n","Epoch 054 | Loss=0.2488 | TestAcc=0.895 | F1=0.897 | AUC=0.969 | Time=3.23s\n","Epoch 055 | Loss=0.2471 | TestAcc=0.921 | F1=0.918 | AUC=0.982 | Time=3.28s\n","Epoch 056 | Loss=0.4963 | TestAcc=0.895 | F1=0.889 | AUC=0.969 | Time=3.33s\n","Epoch 057 | Loss=0.2531 | TestAcc=0.895 | F1=0.889 | AUC=0.975 | Time=3.39s\n","Epoch 058 | Loss=0.2726 | TestAcc=0.868 | F1=0.864 | AUC=0.972 | Time=3.44s\n","Epoch 059 | Loss=0.2242 | TestAcc=0.868 | F1=0.864 | AUC=0.972 | Time=3.49s\n","Epoch 060 | Loss=0.2789 | TestAcc=0.921 | F1=0.920 | AUC=0.985 | Time=3.54s\n","Epoch 061 | Loss=0.1674 | TestAcc=0.895 | F1=0.892 | AUC=0.982 | Time=3.59s\n","Epoch 062 | Loss=0.2964 | TestAcc=0.895 | F1=0.892 | AUC=0.954 | Time=3.65s\n","Epoch 063 | Loss=0.2074 | TestAcc=0.921 | F1=0.920 | AUC=0.945 | Time=3.70s\n","Epoch 064 | Loss=0.1600 | TestAcc=0.842 | F1=0.844 | AUC=0.942 | Time=3.75s\n","Epoch 065 | Loss=0.4292 | TestAcc=0.842 | F1=0.844 | AUC=0.920 | Time=3.80s\n","Epoch 066 | Loss=0.4423 | TestAcc=0.842 | F1=0.827 | AUC=0.975 | Time=3.85s\n","Epoch 067 | Loss=0.2528 | TestAcc=0.895 | F1=0.892 | AUC=0.951 | Time=3.91s\n","Epoch 068 | Loss=0.2463 | TestAcc=0.895 | F1=0.892 | AUC=0.957 | Time=3.97s\n","Epoch 069 | Loss=0.2396 | TestAcc=0.921 | F1=0.920 | AUC=0.960 | Time=4.02s\n","Epoch 070 | Loss=0.2196 | TestAcc=0.921 | F1=0.920 | AUC=0.963 | Time=4.08s\n","Epoch 071 | Loss=0.2186 | TestAcc=0.789 | F1=0.769 | AUC=0.957 | Time=4.13s\n","Epoch 072 | Loss=0.2194 | TestAcc=0.816 | F1=0.802 | AUC=0.951 | Time=4.18s\n","Epoch 073 | Loss=0.2303 | TestAcc=0.868 | F1=0.867 | AUC=0.942 | Time=4.23s\n","Epoch 074 | Loss=0.2554 | TestAcc=0.947 | F1=0.947 | AUC=0.954 | Time=4.28s\n","Epoch 075 | Loss=0.3200 | TestAcc=0.868 | F1=0.872 | AUC=0.957 | Time=4.33s\n","Epoch 076 | Loss=0.1938 | TestAcc=0.895 | F1=0.897 | AUC=0.963 | Time=4.39s\n","Epoch 077 | Loss=0.2221 | TestAcc=0.789 | F1=0.769 | AUC=0.951 | Time=4.44s\n","Epoch 078 | Loss=0.2266 | TestAcc=0.789 | F1=0.769 | AUC=0.954 | Time=4.49s\n","Epoch 079 | Loss=0.1422 | TestAcc=0.895 | F1=0.892 | AUC=0.951 | Time=4.54s\n","Epoch 080 | Loss=0.2577 | TestAcc=0.868 | F1=0.864 | AUC=0.969 | Time=4.60s\n","Epoch 081 | Loss=0.3292 | TestAcc=0.763 | F1=0.734 | AUC=0.969 | Time=4.66s\n","Epoch 082 | Loss=0.2777 | TestAcc=0.763 | F1=0.734 | AUC=0.942 | Time=4.71s\n","Epoch 083 | Loss=0.2267 | TestAcc=0.816 | F1=0.802 | AUC=0.942 | Time=4.76s\n","Epoch 084 | Loss=0.2067 | TestAcc=0.816 | F1=0.802 | AUC=0.972 | Time=4.81s\n","Epoch 085 | Loss=0.2474 | TestAcc=0.842 | F1=0.827 | AUC=0.985 | Time=4.87s\n","Epoch 086 | Loss=0.2219 | TestAcc=0.868 | F1=0.859 | AUC=0.985 | Time=4.92s\n","Epoch 087 | Loss=0.2546 | TestAcc=0.658 | F1=0.664 | AUC=0.849 | Time=4.98s\n","Epoch 088 | Loss=0.2800 | TestAcc=0.816 | F1=0.802 | AUC=0.963 | Time=5.04s\n","Epoch 089 | Loss=0.2959 | TestAcc=0.763 | F1=0.734 | AUC=0.909 | Time=5.09s\n","Epoch 090 | Loss=0.2016 | TestAcc=0.789 | F1=0.769 | AUC=0.929 | Time=5.14s\n","Epoch 091 | Loss=0.2970 | TestAcc=0.789 | F1=0.769 | AUC=0.942 | Time=5.20s\n","Epoch 092 | Loss=0.2339 | TestAcc=0.868 | F1=0.864 | AUC=0.957 | Time=5.25s\n","Epoch 093 | Loss=0.1982 | TestAcc=0.789 | F1=0.769 | AUC=0.957 | Time=5.30s\n","Epoch 094 | Loss=0.2081 | TestAcc=0.816 | F1=0.793 | AUC=0.972 | Time=5.35s\n","Epoch 095 | Loss=0.1704 | TestAcc=0.789 | F1=0.757 | AUC=0.994 | Time=5.40s\n","Epoch 096 | Loss=0.2076 | TestAcc=0.868 | F1=0.864 | AUC=0.954 | Time=5.45s\n","Epoch 097 | Loss=0.1509 | TestAcc=0.816 | F1=0.802 | AUC=0.960 | Time=5.50s\n","Epoch 098 | Loss=0.2127 | TestAcc=0.842 | F1=0.827 | AUC=0.985 | Time=5.56s\n","Epoch 099 | Loss=0.1465 | TestAcc=0.868 | F1=0.864 | AUC=0.969 | Time=5.61s\n","Epoch 100 | Loss=0.2110 | TestAcc=0.816 | F1=0.819 | AUC=0.914 | Time=5.66s\n","Epoch 101 | Loss=0.2712 | TestAcc=0.553 | F1=0.556 | AUC=0.806 | Time=5.72s\n","Epoch 102 | Loss=0.3452 | TestAcc=0.632 | F1=0.640 | AUC=0.834 | Time=5.77s\n","Epoch 103 | Loss=0.2449 | TestAcc=0.842 | F1=0.839 | AUC=0.834 | Time=5.82s\n","Epoch 104 | Loss=0.2967 | TestAcc=0.789 | F1=0.769 | AUC=0.892 | Time=5.87s\n","Epoch 105 | Loss=0.2580 | TestAcc=0.763 | F1=0.734 | AUC=0.882 | Time=5.93s\n","Epoch 106 | Loss=0.3161 | TestAcc=0.789 | F1=0.769 | AUC=0.846 | Time=5.98s\n","Epoch 107 | Loss=0.2956 | TestAcc=0.789 | F1=0.769 | AUC=0.920 | Time=6.04s\n","Epoch 108 | Loss=0.2771 | TestAcc=0.816 | F1=0.802 | AUC=0.938 | Time=6.09s\n","Epoch 109 | Loss=0.1861 | TestAcc=0.763 | F1=0.734 | AUC=0.708 | Time=6.16s\n","Epoch 110 | Loss=0.2171 | TestAcc=0.816 | F1=0.802 | AUC=0.886 | Time=6.22s\n","Epoch 111 | Loss=0.3021 | TestAcc=0.789 | F1=0.793 | AUC=0.920 | Time=6.28s\n","Epoch 112 | Loss=0.2890 | TestAcc=0.868 | F1=0.872 | AUC=0.951 | Time=6.33s\n","Epoch 113 | Loss=0.2190 | TestAcc=0.763 | F1=0.768 | AUC=0.852 | Time=6.39s\n","Epoch 114 | Loss=0.2679 | TestAcc=0.789 | F1=0.789 | AUC=0.822 | Time=6.44s\n","Epoch 115 | Loss=0.2901 | TestAcc=0.737 | F1=0.723 | AUC=0.822 | Time=6.49s\n","Epoch 116 | Loss=0.2893 | TestAcc=0.789 | F1=0.778 | AUC=0.911 | Time=6.54s\n","Epoch 117 | Loss=0.2482 | TestAcc=0.842 | F1=0.834 | AUC=0.945 | Time=6.60s\n","Epoch 118 | Loss=0.2614 | TestAcc=0.842 | F1=0.839 | AUC=0.938 | Time=6.65s\n","Epoch 119 | Loss=0.2381 | TestAcc=0.895 | F1=0.892 | AUC=0.975 | Time=6.71s\n","Epoch 120 | Loss=0.2357 | TestAcc=0.842 | F1=0.834 | AUC=0.975 | Time=6.76s\n","Epoch 121 | Loss=0.2529 | TestAcc=0.842 | F1=0.834 | AUC=0.963 | Time=6.81s\n","Epoch 122 | Loss=0.2737 | TestAcc=0.895 | F1=0.892 | AUC=0.948 | Time=6.87s\n","Epoch 123 | Loss=0.2066 | TestAcc=0.895 | F1=0.895 | AUC=0.951 | Time=6.92s\n","Epoch 124 | Loss=0.2045 | TestAcc=0.921 | F1=0.920 | AUC=0.957 | Time=6.97s\n","Epoch 125 | Loss=0.2230 | TestAcc=0.842 | F1=0.834 | AUC=0.948 | Time=7.04s\n","Epoch 126 | Loss=0.1746 | TestAcc=0.868 | F1=0.864 | AUC=0.960 | Time=7.09s\n","Epoch 127 | Loss=0.1954 | TestAcc=0.868 | F1=0.864 | AUC=0.966 | Time=7.14s\n","Epoch 128 | Loss=0.1658 | TestAcc=0.895 | F1=0.892 | AUC=0.960 | Time=7.21s\n","Epoch 129 | Loss=0.1533 | TestAcc=0.921 | F1=0.920 | AUC=0.966 | Time=7.26s\n","Epoch 130 | Loss=0.2055 | TestAcc=0.921 | F1=0.920 | AUC=0.972 | Time=7.31s\n","Epoch 131 | Loss=0.1718 | TestAcc=0.842 | F1=0.846 | AUC=0.942 | Time=7.36s\n","Epoch 132 | Loss=0.2124 | TestAcc=0.816 | F1=0.820 | AUC=0.954 | Time=7.41s\n","Epoch 133 | Loss=0.2937 | TestAcc=0.947 | F1=0.948 | AUC=0.972 | Time=7.47s\n","Epoch 134 | Loss=0.1891 | TestAcc=0.921 | F1=0.920 | AUC=0.969 | Time=7.52s\n","Epoch 135 | Loss=0.3842 | TestAcc=0.842 | F1=0.842 | AUC=0.957 | Time=7.57s\n","Epoch 136 | Loss=0.2977 | TestAcc=0.605 | F1=0.608 | AUC=0.794 | Time=7.62s\n","Epoch 137 | Loss=0.2738 | TestAcc=0.816 | F1=0.802 | AUC=0.908 | Time=7.68s\n","Epoch 138 | Loss=0.3292 | TestAcc=0.842 | F1=0.834 | AUC=0.966 | Time=7.73s\n","Epoch 139 | Loss=0.2436 | TestAcc=0.947 | F1=0.947 | AUC=0.963 | Time=7.78s\n","Epoch 140 | Loss=0.2536 | TestAcc=0.895 | F1=0.895 | AUC=0.960 | Time=7.84s\n","Epoch 141 | Loss=0.2224 | TestAcc=0.921 | F1=0.918 | AUC=0.948 | Time=7.90s\n","Epoch 142 | Loss=0.1836 | TestAcc=0.868 | F1=0.864 | AUC=0.963 | Time=7.95s\n","Epoch 143 | Loss=0.1756 | TestAcc=0.868 | F1=0.864 | AUC=0.920 | Time=8.00s\n","Epoch 144 | Loss=0.2050 | TestAcc=0.868 | F1=0.864 | AUC=0.954 | Time=8.08s\n","Epoch 145 | Loss=0.1601 | TestAcc=0.868 | F1=0.864 | AUC=0.925 | Time=8.15s\n","Epoch 146 | Loss=0.1799 | TestAcc=0.816 | F1=0.793 | AUC=0.922 | Time=8.20s\n","Epoch 147 | Loss=0.1696 | TestAcc=0.921 | F1=0.920 | AUC=0.966 | Time=8.25s\n","Epoch 148 | Loss=0.1902 | TestAcc=0.921 | F1=0.920 | AUC=0.960 | Time=8.30s\n","Epoch 149 | Loss=0.2147 | TestAcc=0.947 | F1=0.947 | AUC=0.982 | Time=8.36s\n","Epoch 150 | Loss=0.1592 | TestAcc=0.921 | F1=0.920 | AUC=0.972 | Time=8.41s\n","Epoch 151 | Loss=0.1471 | TestAcc=0.921 | F1=0.920 | AUC=0.969 | Time=8.46s\n","Epoch 152 | Loss=0.1462 | TestAcc=0.842 | F1=0.834 | AUC=0.969 | Time=8.51s\n","Epoch 153 | Loss=0.1747 | TestAcc=0.895 | F1=0.892 | AUC=0.966 | Time=8.57s\n","Epoch 154 | Loss=0.1315 | TestAcc=0.921 | F1=0.920 | AUC=0.972 | Time=8.63s\n","Epoch 155 | Loss=0.2269 | TestAcc=0.895 | F1=0.895 | AUC=0.938 | Time=8.68s\n","Epoch 156 | Loss=0.1694 | TestAcc=0.763 | F1=0.746 | AUC=0.932 | Time=8.74s\n","Epoch 157 | Loss=0.2601 | TestAcc=0.816 | F1=0.802 | AUC=0.931 | Time=8.79s\n","Epoch 158 | Loss=0.2003 | TestAcc=0.789 | F1=0.757 | AUC=0.855 | Time=8.85s\n","Epoch 159 | Loss=0.2023 | TestAcc=0.789 | F1=0.757 | AUC=0.840 | Time=8.90s\n","Epoch 160 | Loss=0.1821 | TestAcc=0.763 | F1=0.719 | AUC=0.883 | Time=8.95s\n","Epoch 161 | Loss=0.2958 | TestAcc=0.842 | F1=0.834 | AUC=0.929 | Time=9.01s\n","Epoch 162 | Loss=0.2037 | TestAcc=0.895 | F1=0.892 | AUC=0.974 | Time=9.06s\n","Epoch 163 | Loss=0.2145 | TestAcc=0.921 | F1=0.920 | AUC=0.969 | Time=9.11s\n","Epoch 164 | Loss=0.1770 | TestAcc=0.921 | F1=0.922 | AUC=0.982 | Time=9.18s\n","Epoch 165 | Loss=0.1683 | TestAcc=0.921 | F1=0.920 | AUC=0.982 | Time=9.23s\n","Epoch 166 | Loss=0.1481 | TestAcc=0.842 | F1=0.834 | AUC=0.982 | Time=9.28s\n","Epoch 167 | Loss=0.2248 | TestAcc=0.816 | F1=0.793 | AUC=0.982 | Time=9.33s\n","Epoch 168 | Loss=0.1312 | TestAcc=0.895 | F1=0.889 | AUC=0.982 | Time=9.38s\n","Epoch 169 | Loss=0.1849 | TestAcc=0.842 | F1=0.827 | AUC=0.946 | Time=9.44s\n","Epoch 170 | Loss=0.1008 | TestAcc=0.789 | F1=0.769 | AUC=0.920 | Time=9.49s\n","Epoch 171 | Loss=0.1677 | TestAcc=0.816 | F1=0.793 | AUC=0.935 | Time=9.54s\n","Epoch 172 | Loss=0.1226 | TestAcc=0.842 | F1=0.834 | AUC=0.960 | Time=9.59s\n","Epoch 173 | Loss=0.1371 | TestAcc=0.789 | F1=0.785 | AUC=0.892 | Time=9.65s\n","Epoch 174 | Loss=0.3189 | TestAcc=0.789 | F1=0.769 | AUC=0.840 | Time=9.70s\n","Epoch 175 | Loss=0.2263 | TestAcc=0.763 | F1=0.719 | AUC=0.717 | Time=9.76s\n","Epoch 176 | Loss=0.5149 | TestAcc=0.789 | F1=0.769 | AUC=0.858 | Time=9.81s\n","Epoch 177 | Loss=0.2569 | TestAcc=0.737 | F1=0.731 | AUC=0.837 | Time=9.86s\n","Epoch 178 | Loss=0.2802 | TestAcc=0.789 | F1=0.785 | AUC=0.868 | Time=9.91s\n","Epoch 179 | Loss=0.2657 | TestAcc=0.842 | F1=0.834 | AUC=0.880 | Time=9.97s\n","Epoch 180 | Loss=0.2337 | TestAcc=0.868 | F1=0.864 | AUC=0.902 | Time=10.02s\n","Epoch 181 | Loss=0.2463 | TestAcc=0.868 | F1=0.864 | AUC=0.957 | Time=10.07s\n","Epoch 182 | Loss=0.1908 | TestAcc=0.842 | F1=0.839 | AUC=0.954 | Time=10.13s\n","Epoch 183 | Loss=0.2743 | TestAcc=0.842 | F1=0.834 | AUC=0.908 | Time=10.19s\n","Epoch 184 | Loss=0.2244 | TestAcc=0.842 | F1=0.834 | AUC=0.874 | Time=10.24s\n","Epoch 185 | Loss=0.4061 | TestAcc=0.763 | F1=0.734 | AUC=0.897 | Time=10.30s\n","Epoch 186 | Loss=0.2957 | TestAcc=0.711 | F1=0.656 | AUC=0.920 | Time=10.35s\n","Epoch 187 | Loss=0.2330 | TestAcc=0.737 | F1=0.677 | AUC=0.877 | Time=10.40s\n","Epoch 188 | Loss=0.2192 | TestAcc=0.763 | F1=0.734 | AUC=0.895 | Time=10.46s\n","Epoch 189 | Loss=0.1871 | TestAcc=0.763 | F1=0.719 | AUC=0.957 | Time=10.51s\n","Epoch 190 | Loss=0.2175 | TestAcc=0.789 | F1=0.769 | AUC=0.966 | Time=10.57s\n","Epoch 191 | Loss=0.1888 | TestAcc=0.868 | F1=0.864 | AUC=0.960 | Time=10.63s\n","Epoch 192 | Loss=0.1731 | TestAcc=0.842 | F1=0.839 | AUC=0.932 | Time=10.69s\n","Epoch 193 | Loss=0.1233 | TestAcc=0.895 | F1=0.892 | AUC=0.954 | Time=10.75s\n","Epoch 194 | Loss=0.1807 | TestAcc=0.921 | F1=0.920 | AUC=0.954 | Time=10.80s\n","Epoch 195 | Loss=0.1762 | TestAcc=0.895 | F1=0.892 | AUC=0.948 | Time=10.85s\n","Epoch 196 | Loss=0.1485 | TestAcc=0.895 | F1=0.892 | AUC=0.917 | Time=10.91s\n","Epoch 197 | Loss=0.2010 | TestAcc=0.947 | F1=0.947 | AUC=0.918 | Time=10.96s\n","Epoch 198 | Loss=0.1614 | TestAcc=0.895 | F1=0.892 | AUC=0.954 | Time=11.01s\n","Epoch 199 | Loss=0.2658 | TestAcc=0.895 | F1=0.892 | AUC=0.929 | Time=11.06s\n","Epoch 200 | Loss=0.1581 | TestAcc=0.868 | F1=0.864 | AUC=0.938 | Time=11.11s\n","\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    42   MUTAG                  yes                   64   \n","\n","  objective_weights  num_layers   dropout        lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           5  0.248001  0.005519      0.000077     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0          11      0.119      0.119    0.9737   0.9739    0.9723   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              11.11                 2.82            1440.07  \n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:42:36,329] A new study created in memory with name: no-name-3c06e9a3-652b-4649-b197-046a8b02d269\n"]},{"output_type":"stream","name":"stdout","text":["Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_MUTAG_42.pth\n","Loaded dataset MUTAG: 188 graphs, 7 node features, 2 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:42:36,685] Trial 0 finished with value: 0.2483736397270232 and parameters: {'num_layers': 5, 'dropout': 0.27082717210844004, 'lr': 0.0004444005127989369, 'weight_decay': 0.00020202073440608157}. Best is trial 0 with value: 0.2483736397270232.\n","[I 2026-01-27 17:42:37,024] Trial 1 finished with value: 0.8906928393244182 and parameters: {'num_layers': 6, 'dropout': 0.3112402384426334, 'lr': 0.005149715217118113, 'weight_decay': 4.818880269263866e-06}. Best is trial 1 with value: 0.8906928393244182.\n","[I 2026-01-27 17:42:37,303] Trial 2 finished with value: 0.6551062743013207 and parameters: {'num_layers': 5, 'dropout': 0.33177020602750074, 'lr': 0.00040355005040478736, 'weight_decay': 3.777527412467734e-05}. Best is trial 1 with value: 0.8906928393244182.\n","[I 2026-01-27 17:42:37,638] Trial 3 finished with value: 0.19248138383476732 and parameters: {'num_layers': 5, 'dropout': 0.06266289006142074, 'lr': 0.00011021042885174218, 'weight_decay': 0.00024368172266079423}. Best is trial 1 with value: 0.8906928393244182.\n","[I 2026-01-27 17:42:37,910] Trial 4 finished with value: 0.7168599626494363 and parameters: {'num_layers': 4, 'dropout': 0.13353291702136527, 'lr': 0.00334088352915636, 'weight_decay': 0.0006437806868105692}. Best is trial 1 with value: 0.8906928393244182.\n","[I 2026-01-27 17:42:38,144] Trial 5 finished with value: 0.6399394160907318 and parameters: {'num_layers': 3, 'dropout': 0.05619259235913336, 'lr': 0.0057996751784979966, 'weight_decay': 7.516103013560278e-06}. Best is trial 1 with value: 0.8906928393244182.\n","[I 2026-01-27 17:42:38,409] Trial 6 finished with value: 0.21739720875059224 and parameters: {'num_layers': 4, 'dropout': 0.14331495020182292, 'lr': 0.0006123465452920472, 'weight_decay': 5.290614139524059e-06}. Best is trial 1 with value: 0.8906928393244182.\n","[I 2026-01-27 17:42:38,732] Trial 7 finished with value: 0.5872040240461294 and parameters: {'num_layers': 6, 'dropout': 0.35532710515653454, 'lr': 0.0007395730348195672, 'weight_decay': 3.935362495735663e-06}. Best is trial 1 with value: 0.8906928393244182.\n","[I 2026-01-27 17:42:38,989] Trial 8 finished with value: 0.20594939730278078 and parameters: {'num_layers': 3, 'dropout': 0.2074775385854868, 'lr': 0.0001341952040385854, 'weight_decay': 1.388887768779937e-05}. Best is trial 1 with value: 0.8906928393244182.\n","[I 2026-01-27 17:42:39,335] Trial 9 finished with value: 0.7107993565888302 and parameters: {'num_layers': 5, 'dropout': 0.19595540425035834, 'lr': 0.00038988055776680486, 'weight_decay': 0.0002312768956605789}. Best is trial 1 with value: 0.8906928393244182.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 6, 'dropout': 0.3112402384426334, 'lr': 0.005149715217118113, 'weight_decay': 4.818880269263866e-06}\n","\n","Running final training GIN...\n","{'num_layers': 6, 'dropout': 0.3112402384426334, 'lr': 0.005149715217118113, 'weight_decay': 4.818880269263866e-06}\n","Epoch 001 | Loss=1.1756 | TestAcc=0.711 | F1=0.590 | AUC=0.946 | Time=0.09s\n","Epoch 002 | Loss=1.4412 | TestAcc=0.711 | F1=0.590 | AUC=0.323 | Time=0.17s\n","Epoch 003 | Loss=0.8649 | TestAcc=0.237 | F1=0.149 | AUC=0.155 | Time=0.23s\n","Epoch 004 | Loss=0.6916 | TestAcc=0.289 | F1=0.130 | AUC=0.283 | Time=0.29s\n","Epoch 005 | Loss=0.4023 | TestAcc=0.132 | F1=0.097 | AUC=0.030 | Time=0.35s\n","Epoch 006 | Loss=0.3244 | TestAcc=0.263 | F1=0.161 | AUC=0.047 | Time=0.41s\n","Epoch 007 | Loss=0.3382 | TestAcc=0.263 | F1=0.161 | AUC=0.273 | Time=0.47s\n","Epoch 008 | Loss=0.4263 | TestAcc=0.316 | F1=0.252 | AUC=0.458 | Time=0.53s\n","Epoch 009 | Loss=0.4223 | TestAcc=0.842 | F1=0.848 | AUC=0.889 | Time=0.59s\n","Epoch 010 | Loss=0.4245 | TestAcc=0.816 | F1=0.824 | AUC=0.855 | Time=0.65s\n","Epoch 011 | Loss=0.3639 | TestAcc=0.842 | F1=0.846 | AUC=0.865 | Time=0.71s\n","Epoch 012 | Loss=0.3080 | TestAcc=0.789 | F1=0.773 | AUC=0.822 | Time=0.77s\n","Epoch 013 | Loss=0.3690 | TestAcc=0.816 | F1=0.813 | AUC=0.916 | Time=0.82s\n","Epoch 014 | Loss=0.2545 | TestAcc=0.842 | F1=0.837 | AUC=0.916 | Time=0.88s\n","Epoch 015 | Loss=0.3818 | TestAcc=0.842 | F1=0.846 | AUC=0.886 | Time=0.94s\n","Epoch 016 | Loss=0.2745 | TestAcc=0.711 | F1=0.724 | AUC=0.862 | Time=1.00s\n","Epoch 017 | Loss=0.2941 | TestAcc=0.763 | F1=0.774 | AUC=0.896 | Time=1.05s\n","Epoch 018 | Loss=0.2528 | TestAcc=0.816 | F1=0.824 | AUC=0.872 | Time=1.11s\n","Epoch 019 | Loss=0.2961 | TestAcc=0.842 | F1=0.846 | AUC=0.882 | Time=1.17s\n","Epoch 020 | Loss=0.2221 | TestAcc=0.789 | F1=0.783 | AUC=0.923 | Time=1.24s\n","Epoch 021 | Loss=0.2541 | TestAcc=0.737 | F1=0.737 | AUC=0.832 | Time=1.29s\n","Epoch 022 | Loss=0.2618 | TestAcc=0.789 | F1=0.797 | AUC=0.842 | Time=1.35s\n","Epoch 023 | Loss=0.2742 | TestAcc=0.921 | F1=0.922 | AUC=0.960 | Time=1.41s\n","Epoch 024 | Loss=0.3102 | TestAcc=0.895 | F1=0.891 | AUC=0.960 | Time=1.47s\n","Epoch 025 | Loss=0.3190 | TestAcc=0.842 | F1=0.846 | AUC=0.963 | Time=1.53s\n","Epoch 026 | Loss=0.3107 | TestAcc=0.868 | F1=0.870 | AUC=0.909 | Time=1.60s\n","Epoch 027 | Loss=0.2087 | TestAcc=0.842 | F1=0.846 | AUC=0.879 | Time=1.66s\n","Epoch 028 | Loss=0.2739 | TestAcc=0.868 | F1=0.872 | AUC=0.869 | Time=1.72s\n","Epoch 029 | Loss=0.2060 | TestAcc=0.842 | F1=0.846 | AUC=0.875 | Time=1.78s\n","Epoch 030 | Loss=0.3363 | TestAcc=0.868 | F1=0.872 | AUC=0.923 | Time=1.83s\n","Epoch 031 | Loss=0.2240 | TestAcc=0.842 | F1=0.848 | AUC=0.916 | Time=1.89s\n","Epoch 032 | Loss=0.2013 | TestAcc=0.895 | F1=0.899 | AUC=0.926 | Time=1.95s\n","Epoch 033 | Loss=0.1966 | TestAcc=0.895 | F1=0.899 | AUC=0.923 | Time=2.01s\n","Epoch 034 | Loss=0.2306 | TestAcc=0.842 | F1=0.846 | AUC=0.892 | Time=2.06s\n","Epoch 035 | Loss=0.3081 | TestAcc=0.842 | F1=0.846 | AUC=0.909 | Time=2.12s\n","Epoch 036 | Loss=0.2084 | TestAcc=0.868 | F1=0.870 | AUC=0.929 | Time=2.19s\n","Epoch 037 | Loss=0.2327 | TestAcc=0.868 | F1=0.866 | AUC=0.936 | Time=2.26s\n","Epoch 038 | Loss=0.1945 | TestAcc=0.895 | F1=0.891 | AUC=0.953 | Time=2.31s\n","Epoch 039 | Loss=0.2129 | TestAcc=0.921 | F1=0.923 | AUC=0.923 | Time=2.37s\n","Epoch 040 | Loss=0.1859 | TestAcc=0.868 | F1=0.872 | AUC=0.929 | Time=2.43s\n","Epoch 041 | Loss=0.1679 | TestAcc=0.868 | F1=0.872 | AUC=0.909 | Time=2.48s\n","Epoch 042 | Loss=0.1464 | TestAcc=0.842 | F1=0.846 | AUC=0.946 | Time=2.54s\n","Epoch 043 | Loss=0.3177 | TestAcc=0.868 | F1=0.872 | AUC=0.956 | Time=2.60s\n","Epoch 044 | Loss=0.1939 | TestAcc=0.868 | F1=0.870 | AUC=0.933 | Time=2.65s\n","Epoch 045 | Loss=0.1960 | TestAcc=0.868 | F1=0.870 | AUC=0.943 | Time=2.71s\n","Epoch 046 | Loss=0.1717 | TestAcc=0.842 | F1=0.846 | AUC=0.933 | Time=2.77s\n","Epoch 047 | Loss=0.1726 | TestAcc=0.842 | F1=0.848 | AUC=0.909 | Time=2.82s\n","Epoch 048 | Loss=0.1297 | TestAcc=0.789 | F1=0.799 | AUC=0.896 | Time=2.89s\n","Epoch 049 | Loss=0.1794 | TestAcc=0.842 | F1=0.848 | AUC=0.855 | Time=2.94s\n","Epoch 050 | Loss=0.1827 | TestAcc=0.763 | F1=0.766 | AUC=0.869 | Time=3.00s\n","Epoch 051 | Loss=0.1688 | TestAcc=0.842 | F1=0.842 | AUC=0.892 | Time=3.05s\n","Epoch 052 | Loss=0.2340 | TestAcc=0.816 | F1=0.821 | AUC=0.886 | Time=3.11s\n","Epoch 053 | Loss=0.1570 | TestAcc=0.921 | F1=0.917 | AUC=0.973 | Time=3.17s\n","Epoch 054 | Loss=0.1830 | TestAcc=0.868 | F1=0.870 | AUC=0.936 | Time=3.22s\n","Epoch 055 | Loss=0.1910 | TestAcc=0.842 | F1=0.842 | AUC=0.936 | Time=3.29s\n","Epoch 056 | Loss=0.3074 | TestAcc=0.868 | F1=0.861 | AUC=0.939 | Time=3.35s\n","Epoch 057 | Loss=0.1496 | TestAcc=0.789 | F1=0.761 | AUC=0.956 | Time=3.40s\n","Epoch 058 | Loss=0.2223 | TestAcc=0.868 | F1=0.855 | AUC=0.966 | Time=3.47s\n","Epoch 059 | Loss=0.2165 | TestAcc=0.868 | F1=0.866 | AUC=0.936 | Time=3.53s\n","Epoch 060 | Loss=0.1764 | TestAcc=0.895 | F1=0.895 | AUC=0.963 | Time=3.59s\n","Epoch 061 | Loss=0.1635 | TestAcc=0.842 | F1=0.837 | AUC=0.960 | Time=3.65s\n","Epoch 062 | Loss=0.3709 | TestAcc=0.868 | F1=0.866 | AUC=0.943 | Time=3.71s\n","Epoch 063 | Loss=0.2121 | TestAcc=0.868 | F1=0.861 | AUC=0.960 | Time=3.77s\n","Epoch 064 | Loss=0.1433 | TestAcc=0.895 | F1=0.891 | AUC=0.956 | Time=3.83s\n","Epoch 065 | Loss=0.2911 | TestAcc=0.895 | F1=0.897 | AUC=0.960 | Time=3.89s\n","Epoch 066 | Loss=0.2070 | TestAcc=0.842 | F1=0.849 | AUC=0.892 | Time=3.95s\n","Epoch 067 | Loss=0.1457 | TestAcc=0.921 | F1=0.922 | AUC=0.939 | Time=4.01s\n","Epoch 068 | Loss=0.1633 | TestAcc=0.868 | F1=0.870 | AUC=0.919 | Time=4.06s\n","Epoch 069 | Loss=0.1713 | TestAcc=0.842 | F1=0.842 | AUC=0.909 | Time=4.12s\n","Epoch 070 | Loss=0.3008 | TestAcc=0.789 | F1=0.789 | AUC=0.892 | Time=4.18s\n","Epoch 071 | Loss=0.2151 | TestAcc=0.816 | F1=0.821 | AUC=0.872 | Time=4.23s\n","Epoch 072 | Loss=0.1720 | TestAcc=0.789 | F1=0.797 | AUC=0.869 | Time=4.30s\n","Epoch 073 | Loss=0.1777 | TestAcc=0.842 | F1=0.848 | AUC=0.855 | Time=4.36s\n","Epoch 074 | Loss=0.2084 | TestAcc=0.763 | F1=0.774 | AUC=0.848 | Time=4.42s\n","Epoch 075 | Loss=0.2178 | TestAcc=0.842 | F1=0.848 | AUC=0.916 | Time=4.48s\n","Epoch 076 | Loss=0.2008 | TestAcc=0.816 | F1=0.821 | AUC=0.923 | Time=4.54s\n","Epoch 077 | Loss=0.1569 | TestAcc=0.842 | F1=0.842 | AUC=0.906 | Time=4.60s\n","Epoch 078 | Loss=0.1514 | TestAcc=0.868 | F1=0.874 | AUC=0.875 | Time=4.65s\n","Epoch 079 | Loss=0.2371 | TestAcc=0.842 | F1=0.849 | AUC=0.896 | Time=4.72s\n","Epoch 080 | Loss=0.1801 | TestAcc=0.763 | F1=0.774 | AUC=0.902 | Time=4.77s\n","Epoch 081 | Loss=0.2037 | TestAcc=0.816 | F1=0.823 | AUC=0.855 | Time=4.83s\n","Epoch 082 | Loss=0.2843 | TestAcc=0.842 | F1=0.846 | AUC=0.906 | Time=4.89s\n","Epoch 083 | Loss=0.2564 | TestAcc=0.868 | F1=0.870 | AUC=0.909 | Time=4.95s\n","Epoch 084 | Loss=0.2293 | TestAcc=0.816 | F1=0.821 | AUC=0.906 | Time=5.02s\n","Epoch 085 | Loss=0.2411 | TestAcc=0.816 | F1=0.821 | AUC=0.923 | Time=5.08s\n","Epoch 086 | Loss=0.1826 | TestAcc=0.789 | F1=0.797 | AUC=0.912 | Time=5.15s\n","Epoch 087 | Loss=0.2197 | TestAcc=0.816 | F1=0.818 | AUC=0.896 | Time=5.21s\n","Epoch 088 | Loss=0.1677 | TestAcc=0.868 | F1=0.870 | AUC=0.943 | Time=5.28s\n","Epoch 089 | Loss=0.2868 | TestAcc=0.816 | F1=0.813 | AUC=0.946 | Time=5.36s\n","Epoch 090 | Loss=0.2226 | TestAcc=0.763 | F1=0.766 | AUC=0.862 | Time=5.42s\n","Epoch 091 | Loss=0.2307 | TestAcc=0.632 | F1=0.644 | AUC=0.774 | Time=5.49s\n","Epoch 092 | Loss=0.2107 | TestAcc=0.658 | F1=0.671 | AUC=0.801 | Time=5.55s\n","Epoch 093 | Loss=0.1736 | TestAcc=0.632 | F1=0.644 | AUC=0.808 | Time=5.61s\n","Epoch 094 | Loss=0.2221 | TestAcc=0.868 | F1=0.866 | AUC=0.943 | Time=5.67s\n","Epoch 095 | Loss=0.2884 | TestAcc=0.737 | F1=0.749 | AUC=0.842 | Time=5.73s\n","Epoch 096 | Loss=0.1791 | TestAcc=0.711 | F1=0.724 | AUC=0.832 | Time=5.78s\n","Epoch 097 | Loss=0.3018 | TestAcc=0.789 | F1=0.797 | AUC=0.892 | Time=5.84s\n","Epoch 098 | Loss=0.1983 | TestAcc=0.632 | F1=0.644 | AUC=0.785 | Time=5.90s\n","Epoch 099 | Loss=0.1443 | TestAcc=0.816 | F1=0.821 | AUC=0.879 | Time=5.96s\n","Epoch 100 | Loss=0.1507 | TestAcc=0.842 | F1=0.842 | AUC=0.949 | Time=6.01s\n","Epoch 101 | Loss=0.1778 | TestAcc=0.842 | F1=0.842 | AUC=0.963 | Time=6.07s\n","Epoch 102 | Loss=0.2367 | TestAcc=0.842 | F1=0.842 | AUC=0.946 | Time=6.13s\n","Epoch 103 | Loss=0.2040 | TestAcc=0.816 | F1=0.813 | AUC=0.956 | Time=6.19s\n","Epoch 104 | Loss=0.2304 | TestAcc=0.816 | F1=0.806 | AUC=0.953 | Time=6.25s\n","Epoch 105 | Loss=0.1737 | TestAcc=0.842 | F1=0.837 | AUC=0.949 | Time=6.31s\n","Epoch 106 | Loss=0.1783 | TestAcc=0.868 | F1=0.870 | AUC=0.929 | Time=6.38s\n","Epoch 107 | Loss=0.1814 | TestAcc=0.842 | F1=0.820 | AUC=0.889 | Time=6.44s\n","Epoch 108 | Loss=0.3061 | TestAcc=0.868 | F1=0.855 | AUC=0.892 | Time=6.50s\n","Epoch 109 | Loss=0.1914 | TestAcc=0.895 | F1=0.887 | AUC=0.923 | Time=6.55s\n","Epoch 110 | Loss=0.1556 | TestAcc=0.816 | F1=0.797 | AUC=0.936 | Time=6.61s\n","Epoch 111 | Loss=0.2094 | TestAcc=0.868 | F1=0.861 | AUC=0.946 | Time=6.67s\n","Epoch 112 | Loss=0.1322 | TestAcc=0.921 | F1=0.920 | AUC=0.946 | Time=6.72s\n","Epoch 113 | Loss=0.1303 | TestAcc=0.921 | F1=0.922 | AUC=0.960 | Time=6.78s\n","Epoch 114 | Loss=0.2452 | TestAcc=0.921 | F1=0.922 | AUC=0.943 | Time=6.84s\n","Epoch 115 | Loss=0.1406 | TestAcc=0.816 | F1=0.806 | AUC=0.892 | Time=6.89s\n","Epoch 116 | Loss=0.2097 | TestAcc=0.895 | F1=0.897 | AUC=0.919 | Time=6.96s\n","Epoch 117 | Loss=0.1493 | TestAcc=0.895 | F1=0.899 | AUC=0.912 | Time=7.01s\n","Epoch 118 | Loss=0.1543 | TestAcc=0.868 | F1=0.874 | AUC=0.892 | Time=7.07s\n","Epoch 119 | Loss=0.1275 | TestAcc=0.842 | F1=0.846 | AUC=0.912 | Time=7.13s\n","Epoch 120 | Loss=0.1752 | TestAcc=0.842 | F1=0.846 | AUC=0.892 | Time=7.19s\n","Epoch 121 | Loss=0.1360 | TestAcc=0.842 | F1=0.846 | AUC=0.886 | Time=7.24s\n","Epoch 122 | Loss=0.1159 | TestAcc=0.868 | F1=0.872 | AUC=0.896 | Time=7.30s\n","Epoch 123 | Loss=0.0892 | TestAcc=0.868 | F1=0.872 | AUC=0.929 | Time=7.36s\n","Epoch 124 | Loss=0.0912 | TestAcc=0.868 | F1=0.872 | AUC=0.926 | Time=7.43s\n","Epoch 125 | Loss=0.3902 | TestAcc=0.868 | F1=0.872 | AUC=0.896 | Time=7.49s\n","Epoch 126 | Loss=0.1947 | TestAcc=0.789 | F1=0.799 | AUC=0.855 | Time=7.56s\n","Epoch 127 | Loss=0.2067 | TestAcc=0.868 | F1=0.874 | AUC=0.943 | Time=7.62s\n","Epoch 128 | Loss=0.2116 | TestAcc=0.868 | F1=0.874 | AUC=0.939 | Time=7.67s\n","Epoch 129 | Loss=0.1796 | TestAcc=0.816 | F1=0.821 | AUC=0.936 | Time=7.73s\n","Epoch 130 | Loss=0.2324 | TestAcc=0.816 | F1=0.821 | AUC=0.933 | Time=7.79s\n","Epoch 131 | Loss=0.1668 | TestAcc=0.842 | F1=0.848 | AUC=0.923 | Time=7.85s\n","Epoch 132 | Loss=0.1586 | TestAcc=0.842 | F1=0.848 | AUC=0.909 | Time=7.91s\n","Epoch 133 | Loss=0.2264 | TestAcc=0.789 | F1=0.799 | AUC=0.869 | Time=7.96s\n","Epoch 134 | Loss=0.1651 | TestAcc=0.658 | F1=0.671 | AUC=0.751 | Time=8.02s\n","Epoch 135 | Loss=0.1703 | TestAcc=0.868 | F1=0.870 | AUC=0.892 | Time=8.08s\n","Epoch 136 | Loss=0.1849 | TestAcc=0.816 | F1=0.813 | AUC=0.875 | Time=8.13s\n","Epoch 137 | Loss=0.2440 | TestAcc=0.816 | F1=0.823 | AUC=0.859 | Time=8.19s\n","Epoch 138 | Loss=0.3457 | TestAcc=0.763 | F1=0.760 | AUC=0.845 | Time=8.25s\n","Epoch 139 | Loss=0.5594 | TestAcc=0.842 | F1=0.846 | AUC=0.949 | Time=8.31s\n","Epoch 140 | Loss=0.4119 | TestAcc=0.842 | F1=0.837 | AUC=0.889 | Time=8.36s\n","Epoch 141 | Loss=0.3361 | TestAcc=0.868 | F1=0.870 | AUC=0.916 | Time=8.42s\n","Epoch 142 | Loss=0.2611 | TestAcc=0.895 | F1=0.897 | AUC=0.939 | Time=8.49s\n","Epoch 143 | Loss=0.2675 | TestAcc=0.868 | F1=0.872 | AUC=0.943 | Time=8.55s\n","Epoch 144 | Loss=0.2254 | TestAcc=0.842 | F1=0.848 | AUC=0.949 | Time=8.61s\n","Epoch 145 | Loss=0.2746 | TestAcc=0.816 | F1=0.818 | AUC=0.943 | Time=8.67s\n","Epoch 146 | Loss=0.2888 | TestAcc=0.842 | F1=0.848 | AUC=0.923 | Time=8.73s\n","Epoch 147 | Loss=0.2683 | TestAcc=0.842 | F1=0.848 | AUC=0.916 | Time=8.79s\n","Epoch 148 | Loss=0.2155 | TestAcc=0.868 | F1=0.874 | AUC=0.889 | Time=8.84s\n","Epoch 149 | Loss=0.1899 | TestAcc=0.868 | F1=0.874 | AUC=0.896 | Time=8.90s\n","Epoch 150 | Loss=0.2468 | TestAcc=0.763 | F1=0.774 | AUC=0.791 | Time=8.96s\n","Epoch 151 | Loss=0.2580 | TestAcc=0.842 | F1=0.848 | AUC=0.919 | Time=9.01s\n","Epoch 152 | Loss=0.2101 | TestAcc=0.842 | F1=0.848 | AUC=0.946 | Time=9.07s\n","Epoch 153 | Loss=0.2023 | TestAcc=0.842 | F1=0.848 | AUC=0.923 | Time=9.13s\n","Epoch 154 | Loss=0.2239 | TestAcc=0.474 | F1=0.461 | AUC=0.552 | Time=9.19s\n","Epoch 155 | Loss=0.2289 | TestAcc=0.737 | F1=0.749 | AUC=0.768 | Time=9.25s\n","Epoch 156 | Loss=0.1838 | TestAcc=0.789 | F1=0.761 | AUC=0.926 | Time=9.30s\n","Epoch 157 | Loss=0.1390 | TestAcc=0.763 | F1=0.751 | AUC=0.923 | Time=9.36s\n","Epoch 158 | Loss=0.2945 | TestAcc=0.842 | F1=0.842 | AUC=0.916 | Time=9.42s\n","Epoch 159 | Loss=0.2117 | TestAcc=0.316 | F1=0.183 | AUC=0.478 | Time=9.49s\n","Epoch 160 | Loss=0.2097 | TestAcc=0.342 | F1=0.234 | AUC=0.862 | Time=9.54s\n","Epoch 161 | Loss=0.2145 | TestAcc=0.737 | F1=0.749 | AUC=0.886 | Time=9.60s\n","Epoch 162 | Loss=0.2253 | TestAcc=0.842 | F1=0.846 | AUC=0.953 | Time=9.66s\n","Epoch 163 | Loss=0.2282 | TestAcc=0.816 | F1=0.818 | AUC=0.899 | Time=9.71s\n","Epoch 164 | Loss=0.2538 | TestAcc=0.868 | F1=0.874 | AUC=0.896 | Time=9.77s\n","Epoch 165 | Loss=0.2087 | TestAcc=0.868 | F1=0.874 | AUC=0.919 | Time=9.83s\n","Epoch 166 | Loss=0.2506 | TestAcc=0.868 | F1=0.874 | AUC=0.899 | Time=9.88s\n","Epoch 167 | Loss=0.1794 | TestAcc=0.868 | F1=0.874 | AUC=0.909 | Time=9.94s\n","Epoch 168 | Loss=0.1379 | TestAcc=0.842 | F1=0.848 | AUC=0.923 | Time=10.00s\n","Epoch 169 | Loss=0.2864 | TestAcc=0.816 | F1=0.821 | AUC=0.916 | Time=10.06s\n","Epoch 170 | Loss=0.1842 | TestAcc=0.816 | F1=0.821 | AUC=0.939 | Time=10.12s\n","Epoch 171 | Loss=0.1873 | TestAcc=0.842 | F1=0.846 | AUC=0.953 | Time=10.20s\n","Epoch 172 | Loss=0.1619 | TestAcc=0.868 | F1=0.872 | AUC=0.926 | Time=10.29s\n","Epoch 173 | Loss=0.1921 | TestAcc=0.789 | F1=0.799 | AUC=0.909 | Time=10.37s\n","Epoch 174 | Loss=0.1744 | TestAcc=0.789 | F1=0.799 | AUC=0.906 | Time=10.45s\n","Epoch 175 | Loss=0.1971 | TestAcc=0.763 | F1=0.773 | AUC=0.842 | Time=10.54s\n","Epoch 176 | Loss=0.1992 | TestAcc=0.789 | F1=0.794 | AUC=0.872 | Time=10.62s\n","Epoch 177 | Loss=0.2372 | TestAcc=0.868 | F1=0.872 | AUC=0.939 | Time=10.70s\n","Epoch 178 | Loss=0.1810 | TestAcc=0.842 | F1=0.848 | AUC=0.966 | Time=10.78s\n","Epoch 179 | Loss=0.2220 | TestAcc=0.868 | F1=0.874 | AUC=0.953 | Time=10.86s\n","Epoch 180 | Loss=0.2253 | TestAcc=0.868 | F1=0.874 | AUC=0.955 | Time=10.93s\n","Epoch 181 | Loss=0.1834 | TestAcc=0.895 | F1=0.895 | AUC=0.929 | Time=11.00s\n","Epoch 182 | Loss=0.1993 | TestAcc=0.842 | F1=0.846 | AUC=0.966 | Time=11.08s\n","Epoch 183 | Loss=0.1889 | TestAcc=0.842 | F1=0.848 | AUC=0.970 | Time=11.16s\n","Epoch 184 | Loss=0.1776 | TestAcc=0.842 | F1=0.848 | AUC=0.966 | Time=11.24s\n","Epoch 185 | Loss=0.1496 | TestAcc=0.842 | F1=0.848 | AUC=0.973 | Time=11.33s\n","Epoch 186 | Loss=0.1492 | TestAcc=0.711 | F1=0.722 | AUC=0.875 | Time=11.41s\n","Epoch 187 | Loss=0.1376 | TestAcc=0.632 | F1=0.639 | AUC=0.838 | Time=11.50s\n","Epoch 188 | Loss=0.1517 | TestAcc=0.895 | F1=0.897 | AUC=0.960 | Time=11.59s\n","Epoch 189 | Loss=0.1471 | TestAcc=0.842 | F1=0.837 | AUC=0.936 | Time=11.67s\n","Epoch 190 | Loss=0.2426 | TestAcc=0.868 | F1=0.872 | AUC=0.936 | Time=11.75s\n","Epoch 191 | Loss=0.1623 | TestAcc=0.868 | F1=0.872 | AUC=0.963 | Time=11.83s\n","Epoch 192 | Loss=0.4369 | TestAcc=0.868 | F1=0.872 | AUC=0.960 | Time=11.91s\n","Epoch 193 | Loss=0.2259 | TestAcc=0.789 | F1=0.799 | AUC=0.845 | Time=11.98s\n","Epoch 194 | Loss=0.2495 | TestAcc=0.632 | F1=0.644 | AUC=0.768 | Time=12.07s\n","Epoch 195 | Loss=0.1671 | TestAcc=0.658 | F1=0.673 | AUC=0.808 | Time=12.15s\n","Epoch 196 | Loss=0.1935 | TestAcc=0.684 | F1=0.698 | AUC=0.801 | Time=12.23s\n","Epoch 197 | Loss=0.1510 | TestAcc=0.658 | F1=0.672 | AUC=0.768 | Time=12.31s\n","Epoch 198 | Loss=0.1465 | TestAcc=0.789 | F1=0.799 | AUC=0.909 | Time=12.38s\n","Epoch 199 | Loss=0.2346 | TestAcc=0.895 | F1=0.897 | AUC=0.970 | Time=12.45s\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:42:51,989] A new study created in memory with name: no-name-1f1c1a71-ca54-4224-a38f-1d588513eec0\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 200 | Loss=0.2939 | TestAcc=0.842 | F1=0.820 | AUC=0.966 | Time=12.54s\n","\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    43   MUTAG                  yes                   64   \n","\n","  objective_weights  num_layers  dropout       lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           6  0.31124  0.00515      0.000005     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0          23     0.3237     0.3237    0.9211    0.922    0.9596   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              12.54                 3.01            1440.09  \n","Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_MUTAG_43.pth\n","Loaded dataset MUTAG: 188 graphs, 7 node features, 2 classes\n","Running Optuna for hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:42:52,385] Trial 0 finished with value: 0.7887775998481668 and parameters: {'num_layers': 5, 'dropout': 0.23846767413995934, 'lr': 0.004767743741387555, 'weight_decay': 0.00010172329037934279}. Best is trial 0 with value: 0.7887775998481668.\n","[I 2026-01-27 17:42:52,731] Trial 1 finished with value: 0.25808779820616007 and parameters: {'num_layers': 6, 'dropout': 0.16272197158301505, 'lr': 0.0005489954961812735, 'weight_decay': 1.7990479666192114e-05}. Best is trial 0 with value: 0.7887775998481668.\n","[I 2026-01-27 17:42:52,904] Trial 2 finished with value: 0.8552833952697836 and parameters: {'num_layers': 3, 'dropout': 0.4892944312110003, 'lr': 0.002267340128662578, 'weight_decay': 0.00035419932725050293}. Best is trial 2 with value: 0.8552833952697836.\n","[I 2026-01-27 17:42:53,165] Trial 3 finished with value: 0.7621476706004159 and parameters: {'num_layers': 6, 'dropout': 0.13912176774264445, 'lr': 0.0014417392795328524, 'weight_decay': 0.00016318300583254082}. Best is trial 2 with value: 0.8552833952697836.\n","[I 2026-01-27 17:42:53,359] Trial 4 finished with value: 0.17245262213984458 and parameters: {'num_layers': 4, 'dropout': 0.06993972037590634, 'lr': 0.0003797597224563922, 'weight_decay': 0.0006150434910081172}. Best is trial 2 with value: 0.8552833952697836.\n","[I 2026-01-27 17:42:53,615] Trial 5 finished with value: 0.2390532150871186 and parameters: {'num_layers': 6, 'dropout': 0.21130710284686618, 'lr': 0.000295215473289849, 'weight_decay': 2.786572389455927e-06}. Best is trial 2 with value: 0.8552833952697836.\n","[I 2026-01-27 17:42:53,789] Trial 6 finished with value: 0.17092005509003616 and parameters: {'num_layers': 3, 'dropout': 0.5447725601482363, 'lr': 0.0003425050467072891, 'weight_decay': 1.6891707874522191e-06}. Best is trial 2 with value: 0.8552833952697836.\n","[I 2026-01-27 17:42:53,999] Trial 7 finished with value: 0.6328037809195064 and parameters: {'num_layers': 4, 'dropout': 0.4948710076924858, 'lr': 0.0029122095945882305, 'weight_decay': 2.5427414775537124e-05}. Best is trial 2 with value: 0.8552833952697836.\n","[I 2026-01-27 17:42:54,238] Trial 8 finished with value: 0.8755195695430346 and parameters: {'num_layers': 5, 'dropout': 0.5645653497395093, 'lr': 0.005290060438946103, 'weight_decay': 4.172358923310851e-06}. Best is trial 8 with value: 0.8755195695430346.\n","[I 2026-01-27 17:42:54,470] Trial 9 finished with value: 0.7837786472450718 and parameters: {'num_layers': 5, 'dropout': 0.0511156417062129, 'lr': 0.009195756999795654, 'weight_decay': 0.0009515924091009936}. Best is trial 8 with value: 0.8755195695430346.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'num_layers': 5, 'dropout': 0.5645653497395093, 'lr': 0.005290060438946103, 'weight_decay': 4.172358923310851e-06}\n","\n","Running final training GIN...\n","{'num_layers': 5, 'dropout': 0.5645653497395093, 'lr': 0.005290060438946103, 'weight_decay': 4.172358923310851e-06}\n","Epoch 001 | Loss=1.2848 | TestAcc=0.763 | F1=0.661 | AUC=0.904 | Time=0.05s\n","Epoch 002 | Loss=0.8336 | TestAcc=0.763 | F1=0.661 | AUC=0.897 | Time=0.10s\n","Epoch 003 | Loss=1.0150 | TestAcc=0.789 | F1=0.718 | AUC=0.881 | Time=0.15s\n","Epoch 004 | Loss=0.7314 | TestAcc=0.816 | F1=0.767 | AUC=0.866 | Time=0.20s\n","Epoch 005 | Loss=0.5198 | TestAcc=0.842 | F1=0.810 | AUC=0.904 | Time=0.25s\n","Epoch 006 | Loss=0.4884 | TestAcc=0.816 | F1=0.788 | AUC=0.920 | Time=0.31s\n","Epoch 007 | Loss=0.4197 | TestAcc=0.842 | F1=0.825 | AUC=0.935 | Time=0.36s\n","Epoch 008 | Loss=0.3670 | TestAcc=0.895 | F1=0.890 | AUC=0.935 | Time=0.41s\n","Epoch 009 | Loss=0.2968 | TestAcc=0.842 | F1=0.825 | AUC=0.931 | Time=0.47s\n","Epoch 010 | Loss=0.3331 | TestAcc=0.895 | F1=0.895 | AUC=0.946 | Time=0.52s\n","Epoch 011 | Loss=0.3640 | TestAcc=0.895 | F1=0.890 | AUC=0.939 | Time=0.58s\n","Epoch 012 | Loss=0.3427 | TestAcc=0.816 | F1=0.788 | AUC=0.898 | Time=0.63s\n","Epoch 013 | Loss=0.2849 | TestAcc=0.789 | F1=0.747 | AUC=0.916 | Time=0.70s\n","Epoch 014 | Loss=0.2996 | TestAcc=0.816 | F1=0.802 | AUC=0.927 | Time=0.75s\n","Epoch 015 | Loss=0.3076 | TestAcc=0.816 | F1=0.802 | AUC=0.923 | Time=0.80s\n","Epoch 016 | Loss=0.2881 | TestAcc=0.895 | F1=0.895 | AUC=0.939 | Time=0.85s\n","Epoch 017 | Loss=0.3583 | TestAcc=0.895 | F1=0.895 | AUC=0.943 | Time=0.91s\n","Epoch 018 | Loss=0.2350 | TestAcc=0.842 | F1=0.851 | AUC=0.920 | Time=0.96s\n","Epoch 019 | Loss=0.2635 | TestAcc=0.868 | F1=0.874 | AUC=0.954 | Time=1.01s\n","Epoch 020 | Loss=0.2658 | TestAcc=0.895 | F1=0.898 | AUC=0.946 | Time=1.06s\n","Epoch 021 | Loss=0.2792 | TestAcc=0.895 | F1=0.898 | AUC=0.946 | Time=1.11s\n","Epoch 022 | Loss=0.2378 | TestAcc=0.789 | F1=0.796 | AUC=0.920 | Time=1.16s\n","Epoch 023 | Loss=0.2618 | TestAcc=0.868 | F1=0.874 | AUC=0.935 | Time=1.21s\n","Epoch 024 | Loss=0.2446 | TestAcc=0.842 | F1=0.835 | AUC=0.923 | Time=1.26s\n","Epoch 025 | Loss=0.2897 | TestAcc=0.921 | F1=0.922 | AUC=0.943 | Time=1.32s\n","Epoch 026 | Loss=0.2896 | TestAcc=0.842 | F1=0.851 | AUC=0.939 | Time=1.37s\n","Epoch 027 | Loss=0.2924 | TestAcc=0.921 | F1=0.922 | AUC=0.950 | Time=1.42s\n","Epoch 028 | Loss=0.2329 | TestAcc=0.868 | F1=0.866 | AUC=0.923 | Time=1.48s\n","Epoch 029 | Loss=0.2427 | TestAcc=0.868 | F1=0.866 | AUC=0.935 | Time=1.53s\n","Epoch 030 | Loss=0.2672 | TestAcc=0.868 | F1=0.866 | AUC=0.950 | Time=1.58s\n","Epoch 031 | Loss=0.2537 | TestAcc=0.842 | F1=0.847 | AUC=0.935 | Time=1.63s\n","Epoch 032 | Loss=0.2178 | TestAcc=0.868 | F1=0.866 | AUC=0.958 | Time=1.70s\n","Epoch 033 | Loss=0.2300 | TestAcc=0.868 | F1=0.866 | AUC=0.943 | Time=1.75s\n","Epoch 034 | Loss=0.2849 | TestAcc=0.895 | F1=0.895 | AUC=0.946 | Time=1.81s\n","Epoch 035 | Loss=0.2859 | TestAcc=0.921 | F1=0.922 | AUC=0.943 | Time=1.86s\n","Epoch 036 | Loss=0.2229 | TestAcc=0.895 | F1=0.895 | AUC=0.954 | Time=1.91s\n","Epoch 037 | Loss=0.2091 | TestAcc=0.921 | F1=0.925 | AUC=0.973 | Time=1.96s\n","Epoch 038 | Loss=0.2990 | TestAcc=0.895 | F1=0.898 | AUC=0.958 | Time=2.01s\n","Epoch 039 | Loss=0.1946 | TestAcc=0.868 | F1=0.871 | AUC=0.946 | Time=2.06s\n","Epoch 040 | Loss=0.1947 | TestAcc=0.868 | F1=0.866 | AUC=0.935 | Time=2.11s\n","Epoch 041 | Loss=0.1697 | TestAcc=0.868 | F1=0.871 | AUC=0.939 | Time=2.17s\n","Epoch 042 | Loss=0.2612 | TestAcc=0.868 | F1=0.871 | AUC=0.931 | Time=2.22s\n","Epoch 043 | Loss=0.2206 | TestAcc=0.711 | F1=0.731 | AUC=0.797 | Time=2.27s\n","Epoch 044 | Loss=0.2871 | TestAcc=0.816 | F1=0.802 | AUC=0.931 | Time=2.32s\n","Epoch 045 | Loss=0.3993 | TestAcc=0.553 | F1=0.582 | AUC=0.762 | Time=2.38s\n","Epoch 046 | Loss=0.3933 | TestAcc=0.789 | F1=0.718 | AUC=0.812 | Time=2.43s\n","Epoch 047 | Loss=0.3079 | TestAcc=0.789 | F1=0.718 | AUC=0.900 | Time=2.48s\n","Epoch 048 | Loss=0.2795 | TestAcc=0.737 | F1=0.648 | AUC=0.900 | Time=2.53s\n","Epoch 049 | Loss=0.2438 | TestAcc=0.842 | F1=0.825 | AUC=0.935 | Time=2.59s\n","Epoch 050 | Loss=0.3080 | TestAcc=0.921 | F1=0.919 | AUC=0.943 | Time=2.64s\n","Epoch 051 | Loss=0.2609 | TestAcc=0.842 | F1=0.835 | AUC=0.927 | Time=2.69s\n","Epoch 052 | Loss=0.3347 | TestAcc=0.868 | F1=0.871 | AUC=0.943 | Time=2.76s\n","Epoch 053 | Loss=0.3152 | TestAcc=0.868 | F1=0.858 | AUC=0.923 | Time=2.81s\n","Epoch 054 | Loss=0.2780 | TestAcc=0.842 | F1=0.825 | AUC=0.900 | Time=2.86s\n","Epoch 055 | Loss=0.2857 | TestAcc=0.842 | F1=0.825 | AUC=0.897 | Time=2.92s\n","Epoch 056 | Loss=0.2731 | TestAcc=0.895 | F1=0.890 | AUC=0.923 | Time=2.97s\n","Epoch 057 | Loss=0.2379 | TestAcc=0.842 | F1=0.842 | AUC=0.946 | Time=3.02s\n","Epoch 058 | Loss=0.1953 | TestAcc=0.921 | F1=0.922 | AUC=0.966 | Time=3.07s\n","Epoch 059 | Loss=0.1851 | TestAcc=0.921 | F1=0.922 | AUC=0.977 | Time=3.12s\n","Epoch 060 | Loss=0.1804 | TestAcc=0.895 | F1=0.898 | AUC=0.981 | Time=3.17s\n","Epoch 061 | Loss=0.2025 | TestAcc=0.895 | F1=0.898 | AUC=0.966 | Time=3.22s\n","Epoch 062 | Loss=0.2341 | TestAcc=0.921 | F1=0.922 | AUC=0.969 | Time=3.28s\n","Epoch 063 | Loss=0.3130 | TestAcc=0.868 | F1=0.866 | AUC=0.954 | Time=3.32s\n","Epoch 064 | Loss=0.2442 | TestAcc=0.895 | F1=0.895 | AUC=0.958 | Time=3.38s\n","Epoch 065 | Loss=0.2866 | TestAcc=0.921 | F1=0.919 | AUC=0.962 | Time=3.43s\n","Epoch 066 | Loss=0.2360 | TestAcc=0.921 | F1=0.922 | AUC=0.954 | Time=3.49s\n","Epoch 067 | Loss=0.2471 | TestAcc=0.895 | F1=0.895 | AUC=0.966 | Time=3.54s\n","Epoch 068 | Loss=0.2277 | TestAcc=0.868 | F1=0.871 | AUC=0.958 | Time=3.59s\n","Epoch 069 | Loss=0.2193 | TestAcc=0.789 | F1=0.801 | AUC=0.935 | Time=3.64s\n","Epoch 070 | Loss=0.2632 | TestAcc=0.868 | F1=0.871 | AUC=0.954 | Time=3.70s\n","Epoch 071 | Loss=0.2124 | TestAcc=0.895 | F1=0.898 | AUC=0.931 | Time=3.75s\n","Epoch 072 | Loss=0.4037 | TestAcc=0.789 | F1=0.804 | AUC=0.935 | Time=3.81s\n","Epoch 073 | Loss=0.2583 | TestAcc=0.816 | F1=0.824 | AUC=0.927 | Time=3.87s\n","Epoch 074 | Loss=0.2640 | TestAcc=0.868 | F1=0.866 | AUC=0.939 | Time=3.92s\n","Epoch 075 | Loss=0.2451 | TestAcc=0.842 | F1=0.835 | AUC=0.939 | Time=3.97s\n","Epoch 076 | Loss=0.2227 | TestAcc=0.868 | F1=0.866 | AUC=0.950 | Time=4.02s\n","Epoch 077 | Loss=0.1890 | TestAcc=0.895 | F1=0.895 | AUC=0.958 | Time=4.07s\n","Epoch 078 | Loss=0.2475 | TestAcc=0.895 | F1=0.895 | AUC=0.946 | Time=4.12s\n","Epoch 079 | Loss=0.1816 | TestAcc=0.868 | F1=0.871 | AUC=0.931 | Time=4.17s\n","Epoch 080 | Loss=0.2350 | TestAcc=0.868 | F1=0.871 | AUC=0.962 | Time=4.22s\n","Epoch 081 | Loss=0.1841 | TestAcc=0.816 | F1=0.827 | AUC=0.962 | Time=4.27s\n","Epoch 082 | Loss=0.2403 | TestAcc=0.842 | F1=0.847 | AUC=0.958 | Time=4.32s\n","Epoch 083 | Loss=0.2674 | TestAcc=0.868 | F1=0.871 | AUC=0.931 | Time=4.38s\n","Epoch 084 | Loss=0.2243 | TestAcc=0.868 | F1=0.871 | AUC=0.935 | Time=4.43s\n","Epoch 085 | Loss=0.2464 | TestAcc=0.895 | F1=0.895 | AUC=0.920 | Time=4.48s\n","Epoch 086 | Loss=0.2380 | TestAcc=0.868 | F1=0.871 | AUC=0.927 | Time=4.53s\n","Epoch 087 | Loss=0.2329 | TestAcc=0.842 | F1=0.842 | AUC=0.920 | Time=4.58s\n","Epoch 088 | Loss=0.2405 | TestAcc=0.789 | F1=0.801 | AUC=0.931 | Time=4.64s\n","Epoch 089 | Loss=0.1828 | TestAcc=0.921 | F1=0.922 | AUC=0.946 | Time=4.69s\n","Epoch 090 | Loss=0.2183 | TestAcc=0.895 | F1=0.895 | AUC=0.966 | Time=4.74s\n","Epoch 091 | Loss=0.7292 | TestAcc=0.895 | F1=0.895 | AUC=0.969 | Time=4.81s\n","Epoch 092 | Loss=0.2562 | TestAcc=0.816 | F1=0.819 | AUC=0.874 | Time=4.86s\n","Epoch 093 | Loss=0.3271 | TestAcc=0.842 | F1=0.810 | AUC=0.872 | Time=4.91s\n","Epoch 094 | Loss=0.2801 | TestAcc=0.789 | F1=0.718 | AUC=0.776 | Time=4.97s\n","Epoch 095 | Loss=0.2702 | TestAcc=0.842 | F1=0.810 | AUC=0.820 | Time=5.02s\n","Epoch 096 | Loss=0.1766 | TestAcc=0.842 | F1=0.825 | AUC=0.895 | Time=5.07s\n","Epoch 097 | Loss=0.2185 | TestAcc=0.895 | F1=0.895 | AUC=0.958 | Time=5.12s\n","Epoch 098 | Loss=0.1962 | TestAcc=0.921 | F1=0.922 | AUC=0.962 | Time=5.17s\n","Epoch 099 | Loss=0.1681 | TestAcc=0.868 | F1=0.871 | AUC=0.958 | Time=5.22s\n","Epoch 100 | Loss=0.1681 | TestAcc=0.868 | F1=0.871 | AUC=0.962 | Time=5.28s\n","Epoch 101 | Loss=0.1690 | TestAcc=0.868 | F1=0.866 | AUC=0.962 | Time=5.33s\n","Epoch 102 | Loss=0.2883 | TestAcc=0.895 | F1=0.895 | AUC=0.969 | Time=5.38s\n","Epoch 103 | Loss=0.2266 | TestAcc=0.605 | F1=0.635 | AUC=0.724 | Time=5.44s\n","Epoch 104 | Loss=0.2915 | TestAcc=0.632 | F1=0.659 | AUC=0.812 | Time=5.49s\n","Epoch 105 | Loss=0.4229 | TestAcc=0.711 | F1=0.731 | AUC=0.885 | Time=5.55s\n","Epoch 106 | Loss=0.2488 | TestAcc=0.842 | F1=0.851 | AUC=0.943 | Time=5.60s\n","Epoch 107 | Loss=0.2240 | TestAcc=0.868 | F1=0.871 | AUC=0.931 | Time=5.65s\n","Epoch 108 | Loss=0.3068 | TestAcc=0.921 | F1=0.922 | AUC=0.969 | Time=5.71s\n","Epoch 109 | Loss=0.3612 | TestAcc=0.868 | F1=0.858 | AUC=0.943 | Time=5.76s\n","Epoch 110 | Loss=0.2519 | TestAcc=0.789 | F1=0.747 | AUC=0.943 | Time=5.82s\n","Epoch 111 | Loss=0.2187 | TestAcc=0.789 | F1=0.747 | AUC=0.954 | Time=5.88s\n","Epoch 112 | Loss=0.1882 | TestAcc=0.842 | F1=0.825 | AUC=0.943 | Time=5.93s\n","Epoch 113 | Loss=0.2039 | TestAcc=0.868 | F1=0.866 | AUC=0.950 | Time=5.98s\n","Epoch 114 | Loss=0.2845 | TestAcc=0.921 | F1=0.922 | AUC=0.954 | Time=6.04s\n","Epoch 115 | Loss=0.2020 | TestAcc=0.789 | F1=0.804 | AUC=0.916 | Time=6.09s\n","Epoch 116 | Loss=0.2687 | TestAcc=0.789 | F1=0.801 | AUC=0.912 | Time=6.14s\n","Epoch 117 | Loss=0.2907 | TestAcc=0.842 | F1=0.825 | AUC=0.966 | Time=6.19s\n","Epoch 118 | Loss=0.2900 | TestAcc=0.895 | F1=0.890 | AUC=0.939 | Time=6.24s\n","Epoch 119 | Loss=0.2356 | TestAcc=0.868 | F1=0.866 | AUC=0.946 | Time=6.29s\n","Epoch 120 | Loss=0.2337 | TestAcc=0.868 | F1=0.871 | AUC=0.931 | Time=6.34s\n","Epoch 121 | Loss=0.2209 | TestAcc=0.868 | F1=0.871 | AUC=0.931 | Time=6.40s\n","Epoch 122 | Loss=0.1685 | TestAcc=0.895 | F1=0.895 | AUC=0.920 | Time=6.45s\n","Epoch 123 | Loss=0.1596 | TestAcc=0.895 | F1=0.895 | AUC=0.939 | Time=6.50s\n","Epoch 124 | Loss=0.1868 | TestAcc=0.868 | F1=0.866 | AUC=0.946 | Time=6.55s\n","Epoch 125 | Loss=0.2280 | TestAcc=0.868 | F1=0.871 | AUC=0.889 | Time=6.60s\n","Epoch 126 | Loss=0.1651 | TestAcc=0.895 | F1=0.898 | AUC=0.946 | Time=6.65s\n","Epoch 127 | Loss=0.1811 | TestAcc=0.895 | F1=0.898 | AUC=0.946 | Time=6.70s\n","Epoch 128 | Loss=0.1544 | TestAcc=0.895 | F1=0.898 | AUC=0.950 | Time=6.76s\n","Epoch 129 | Loss=0.1553 | TestAcc=0.895 | F1=0.898 | AUC=0.969 | Time=6.81s\n","Epoch 130 | Loss=0.1293 | TestAcc=0.895 | F1=0.898 | AUC=0.969 | Time=6.87s\n","Epoch 131 | Loss=0.2552 | TestAcc=0.921 | F1=0.922 | AUC=0.962 | Time=6.92s\n","Epoch 132 | Loss=0.1653 | TestAcc=0.921 | F1=0.922 | AUC=0.950 | Time=6.98s\n","Epoch 133 | Loss=0.1473 | TestAcc=0.895 | F1=0.898 | AUC=0.931 | Time=7.03s\n","Epoch 134 | Loss=0.1284 | TestAcc=0.895 | F1=0.895 | AUC=0.939 | Time=7.09s\n","Epoch 135 | Loss=0.2023 | TestAcc=0.868 | F1=0.871 | AUC=0.923 | Time=7.14s\n","Epoch 136 | Loss=0.1351 | TestAcc=0.868 | F1=0.874 | AUC=0.927 | Time=7.19s\n","Epoch 137 | Loss=0.1600 | TestAcc=0.895 | F1=0.898 | AUC=0.946 | Time=7.24s\n","Epoch 138 | Loss=0.2134 | TestAcc=0.868 | F1=0.874 | AUC=0.946 | Time=7.29s\n","Epoch 139 | Loss=0.1862 | TestAcc=0.842 | F1=0.847 | AUC=0.935 | Time=7.34s\n","Epoch 140 | Loss=0.1728 | TestAcc=0.895 | F1=0.890 | AUC=0.950 | Time=7.40s\n","Epoch 141 | Loss=0.2331 | TestAcc=0.868 | F1=0.866 | AUC=0.958 | Time=7.45s\n","Epoch 142 | Loss=0.3690 | TestAcc=0.895 | F1=0.898 | AUC=0.946 | Time=7.50s\n","Epoch 143 | Loss=0.2308 | TestAcc=0.921 | F1=0.919 | AUC=0.883 | Time=7.55s\n","Epoch 144 | Loss=0.2135 | TestAcc=0.895 | F1=0.890 | AUC=0.935 | Time=7.61s\n","Epoch 145 | Loss=0.1830 | TestAcc=0.868 | F1=0.866 | AUC=0.946 | Time=7.66s\n","Epoch 146 | Loss=0.1540 | TestAcc=0.895 | F1=0.895 | AUC=0.950 | Time=7.71s\n","Epoch 147 | Loss=0.1747 | TestAcc=0.895 | F1=0.895 | AUC=0.950 | Time=7.76s\n","Epoch 148 | Loss=0.2153 | TestAcc=0.868 | F1=0.874 | AUC=0.962 | Time=7.82s\n","Epoch 149 | Loss=0.2293 | TestAcc=0.816 | F1=0.827 | AUC=0.931 | Time=7.87s\n","Epoch 150 | Loss=0.1881 | TestAcc=0.895 | F1=0.890 | AUC=0.935 | Time=7.93s\n","Epoch 151 | Loss=0.2062 | TestAcc=0.895 | F1=0.890 | AUC=0.962 | Time=7.98s\n","Epoch 152 | Loss=0.1693 | TestAcc=0.895 | F1=0.895 | AUC=0.954 | Time=8.04s\n","Epoch 153 | Loss=0.1468 | TestAcc=0.921 | F1=0.922 | AUC=0.962 | Time=8.09s\n","Epoch 154 | Loss=0.2075 | TestAcc=0.921 | F1=0.922 | AUC=0.954 | Time=8.14s\n","Epoch 155 | Loss=0.1631 | TestAcc=0.895 | F1=0.898 | AUC=0.962 | Time=8.19s\n","Epoch 156 | Loss=0.1539 | TestAcc=0.921 | F1=0.922 | AUC=0.969 | Time=8.29s\n","Epoch 157 | Loss=0.1360 | TestAcc=0.868 | F1=0.866 | AUC=0.935 | Time=8.37s\n","Epoch 158 | Loss=0.1413 | TestAcc=0.868 | F1=0.866 | AUC=0.931 | Time=8.44s\n","Epoch 159 | Loss=0.1443 | TestAcc=0.895 | F1=0.895 | AUC=0.943 | Time=8.52s\n","Epoch 160 | Loss=0.1702 | TestAcc=0.921 | F1=0.922 | AUC=0.954 | Time=8.59s\n","Epoch 161 | Loss=0.1653 | TestAcc=0.868 | F1=0.871 | AUC=0.939 | Time=8.66s\n","Epoch 162 | Loss=0.1645 | TestAcc=0.868 | F1=0.871 | AUC=0.931 | Time=8.73s\n","Epoch 163 | Loss=0.2210 | TestAcc=0.868 | F1=0.866 | AUC=0.939 | Time=8.80s\n","Epoch 164 | Loss=0.1719 | TestAcc=0.842 | F1=0.847 | AUC=0.912 | Time=8.87s\n","Epoch 165 | Loss=0.1763 | TestAcc=0.895 | F1=0.898 | AUC=0.946 | Time=8.94s\n","Epoch 166 | Loss=0.2525 | TestAcc=0.763 | F1=0.781 | AUC=0.858 | Time=9.02s\n","Epoch 167 | Loss=0.1410 | TestAcc=0.737 | F1=0.756 | AUC=0.885 | Time=9.10s\n","Epoch 168 | Loss=0.3282 | TestAcc=0.816 | F1=0.827 | AUC=0.920 | Time=9.17s\n","Epoch 169 | Loss=0.2922 | TestAcc=0.842 | F1=0.853 | AUC=0.962 | Time=9.23s\n","Epoch 170 | Loss=0.2799 | TestAcc=0.868 | F1=0.877 | AUC=0.973 | Time=9.32s\n","Epoch 171 | Loss=0.2031 | TestAcc=0.868 | F1=0.874 | AUC=0.962 | Time=9.39s\n","Epoch 172 | Loss=0.2303 | TestAcc=0.921 | F1=0.922 | AUC=0.969 | Time=9.49s\n","Epoch 173 | Loss=0.2163 | TestAcc=0.921 | F1=0.919 | AUC=0.954 | Time=9.56s\n","Epoch 174 | Loss=0.1901 | TestAcc=0.921 | F1=0.922 | AUC=0.950 | Time=9.65s\n","Epoch 175 | Loss=0.1729 | TestAcc=0.921 | F1=0.919 | AUC=0.908 | Time=9.72s\n","Epoch 176 | Loss=0.1496 | TestAcc=0.921 | F1=0.922 | AUC=0.885 | Time=9.79s\n","Epoch 177 | Loss=0.3154 | TestAcc=0.816 | F1=0.788 | AUC=0.858 | Time=9.87s\n","Epoch 178 | Loss=0.1693 | TestAcc=0.816 | F1=0.788 | AUC=0.856 | Time=9.93s\n","Epoch 179 | Loss=0.2005 | TestAcc=0.895 | F1=0.895 | AUC=0.889 | Time=10.01s\n","Epoch 180 | Loss=0.2500 | TestAcc=0.895 | F1=0.895 | AUC=0.954 | Time=10.09s\n","Epoch 181 | Loss=0.1441 | TestAcc=0.895 | F1=0.895 | AUC=0.954 | Time=10.16s\n","Epoch 182 | Loss=0.1681 | TestAcc=0.895 | F1=0.895 | AUC=0.964 | Time=10.22s\n","Epoch 183 | Loss=0.2107 | TestAcc=0.868 | F1=0.874 | AUC=0.950 | Time=10.30s\n","Epoch 184 | Loss=0.1768 | TestAcc=0.895 | F1=0.898 | AUC=0.958 | Time=10.37s\n","Epoch 185 | Loss=0.1816 | TestAcc=0.895 | F1=0.898 | AUC=0.958 | Time=10.43s\n","Epoch 186 | Loss=0.1550 | TestAcc=0.895 | F1=0.898 | AUC=0.962 | Time=10.50s\n","Epoch 187 | Loss=0.1738 | TestAcc=0.895 | F1=0.898 | AUC=0.950 | Time=10.58s\n","Epoch 188 | Loss=0.1954 | TestAcc=0.895 | F1=0.898 | AUC=0.946 | Time=10.65s\n","Epoch 189 | Loss=0.1175 | TestAcc=0.921 | F1=0.922 | AUC=0.962 | Time=10.72s\n","Epoch 190 | Loss=0.2125 | TestAcc=0.895 | F1=0.898 | AUC=0.954 | Time=10.81s\n","Epoch 191 | Loss=0.1526 | TestAcc=0.895 | F1=0.898 | AUC=0.958 | Time=10.89s\n","Epoch 192 | Loss=0.2143 | TestAcc=0.895 | F1=0.898 | AUC=0.962 | Time=10.97s\n","Epoch 193 | Loss=0.2229 | TestAcc=0.868 | F1=0.871 | AUC=0.943 | Time=11.04s\n","Epoch 194 | Loss=0.2944 | TestAcc=0.816 | F1=0.824 | AUC=0.883 | Time=11.13s\n","Epoch 195 | Loss=0.3864 | TestAcc=0.763 | F1=0.780 | AUC=0.927 | Time=11.21s\n","Epoch 196 | Loss=0.3128 | TestAcc=0.763 | F1=0.780 | AUC=0.923 | Time=11.30s\n","Epoch 197 | Loss=0.2757 | TestAcc=0.842 | F1=0.851 | AUC=0.939 | Time=11.38s\n","Epoch 198 | Loss=0.2980 | TestAcc=0.868 | F1=0.874 | AUC=0.939 | Time=11.47s\n","Epoch 199 | Loss=0.2814 | TestAcc=0.868 | F1=0.874 | AUC=0.954 | Time=11.55s\n","Epoch 200 | Loss=0.2734 | TestAcc=0.895 | F1=0.898 | AUC=0.950 | Time=11.61s\n","\n","Training summary stored in : /content/drive/MyDrive/InformationSystems/Classification/results/classification/gin.csv\n","  method  seed dataset optimization_enabled  embedding_dimension  \\\n","0    GIN    44   MUTAG                  yes                   64   \n","\n","  objective_weights  num_layers   dropout       lr  weight_decay  epochs  \\\n","0     (0.5,0.3,0.2)           5  0.564565  0.00529      0.000004     200   \n","\n","   best_epoch  best_loss  eval_loss  eval_acc  eval_f1  eval_auc  \\\n","0          25     0.2147     0.2147    0.9211   0.9224    0.9425   \n","\n","   training_time (s)  generation_time (s)  memory_usage (MB)  \n","0              11.61                 2.48            1440.09  \n","Saved model: /content/drive/MyDrive/InformationSystems/Classification/models/GIN_MUTAG_44.pth\n"]}],"source":["for dataset_name in [\"IMDB-MULTI\", \"ENZYMES\", \"MUTAG\"]:\n","  for seed in [42, 43, 44]:\n","      run_gin_pipeline(\n","          dataset_name=dataset_name,\n","          seed=seed,\n","          use_optuna=True,\n","          w_acc=0.5,\n","          w_f1=0.3,\n","          w_auc=0.2,\n","          hidden_dim=64,\n","          epochs=200,\n","          batch_size=32,\n","          n_trials=10,\n","      )"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525003,"status":"ok","timestamp":1769536311912,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"},"user_tz":-120},"id":"NUWkRRajqf-k","outputId":"1c49fa4d-05f5-4513-d072-eb07435c26a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded dataset IMDB-MULTI for Graph2Vec: 1500 graphs, 3 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:43:06,910] A new study created in memory with name: no-name-0658c69d-f2b8-4c8f-940c-48e0a2878913\n"]},{"output_type":"stream","name":"stdout","text":["Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:43:16,298] Trial 0 finished with value: 0.47770594407313155 and parameters: {'C': 10.867463624186174, 'gamma': 4.779141986996383}. Best is trial 0 with value: 0.47770594407313155.\n","[I 2026-01-27 17:43:25,952] Trial 1 finished with value: 0.446353745579119 and parameters: {'C': 65.94454809217339, 'gamma': 3.9232357221947645}. Best is trial 0 with value: 0.47770594407313155.\n","[I 2026-01-27 17:43:35,237] Trial 2 finished with value: 0.5674344070994178 and parameters: {'C': 0.3155516521751666, 'gamma': 0.0077339853580041485}. Best is trial 2 with value: 0.5674344070994178.\n","[I 2026-01-27 17:43:44,689] Trial 3 finished with value: 0.4914423534729372 and parameters: {'C': 0.20700711333234584, 'gamma': 2.8270055433898396}. Best is trial 2 with value: 0.5674344070994178.\n","[I 2026-01-27 17:43:54,009] Trial 4 finished with value: 0.5405306657072796 and parameters: {'C': 3.6792611145200764, 'gamma': 0.000633127285473922}. Best is trial 2 with value: 0.5674344070994178.\n","[I 2026-01-27 17:44:03,467] Trial 5 finished with value: 0.484693938881343 and parameters: {'C': 0.11467198818297174, 'gamma': 0.26725273273861916}. Best is trial 2 with value: 0.5674344070994178.\n","[I 2026-01-27 17:44:13,681] Trial 6 finished with value: 0.47684893003249235 and parameters: {'C': 16.264964182091013, 'gamma': 2.0610998386985586}. Best is trial 2 with value: 0.5674344070994178.\n","[I 2026-01-27 17:44:23,005] Trial 7 finished with value: 0.5050365088307327 and parameters: {'C': 6.658236060062618, 'gamma': 0.46505457087621604}. Best is trial 2 with value: 0.5674344070994178.\n","[I 2026-01-27 17:44:32,534] Trial 8 finished with value: 0.5281737985863463 and parameters: {'C': 24.64726236185749, 'gamma': 0.1324055420095448}. Best is trial 2 with value: 0.5674344070994178.\n","[I 2026-01-27 17:44:41,964] Trial 9 finished with value: 0.4700585608624638 and parameters: {'C': 0.07417463720781896, 'gamma': 0.009036170462976993}. Best is trial 2 with value: 0.5674344070994178.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 0.3155516521751666, 'gamma': 0.0077339853580041485}\n","Running final Graph2Vec embedding on train+test graphs...\n","Training final SVM on Graph2Vec embeddings...\n","Graph2Vec Results on IMDB-MULTI -> Acc: 0.450, F1: 0.421, AUC: 0.664, Score: 0.484\n","Embedding time: 11.34s | SVM training time: 1.02s | Optuna time: 95.06s | Memory usage: 1460.57 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n","Loaded dataset IMDB-MULTI for Graph2Vec: 1500 graphs, 3 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:44:55,009] A new study created in memory with name: no-name-a98c1600-5c8a-4184-ba16-31af84f2f7c1\n"]},{"output_type":"stream","name":"stdout","text":["Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:45:04,963] Trial 0 finished with value: 0.43945293859286033 and parameters: {'C': 0.03597802938158339, 'gamma': 0.002134146183770069}. Best is trial 0 with value: 0.43945293859286033.\n","[I 2026-01-27 17:45:14,562] Trial 1 finished with value: 0.5170263463314534 and parameters: {'C': 3.4746481988363778, 'gamma': 7.106851736533086}. Best is trial 1 with value: 0.5170263463314534.\n","[I 2026-01-27 17:45:23,900] Trial 2 finished with value: 0.51500885427439 and parameters: {'C': 28.833320595019316, 'gamma': 0.005690848803869117}. Best is trial 1 with value: 0.5170263463314534.\n","[I 2026-01-27 17:45:33,500] Trial 3 finished with value: 0.42188040935130694 and parameters: {'C': 0.20733486197823367, 'gamma': 0.0007820423070887074}. Best is trial 1 with value: 0.5170263463314534.\n","[I 2026-01-27 17:45:42,909] Trial 4 finished with value: 0.43290168601933093 and parameters: {'C': 0.029279026841699796, 'gamma': 0.0002803309324004197}. Best is trial 1 with value: 0.5170263463314534.\n","[I 2026-01-27 17:45:52,196] Trial 5 finished with value: 0.507331358075453 and parameters: {'C': 0.617771693209878, 'gamma': 0.7700882104288853}. Best is trial 1 with value: 0.5170263463314534.\n","[I 2026-01-27 17:46:01,577] Trial 6 finished with value: 0.4918512963095333 and parameters: {'C': 0.3689819700676038, 'gamma': 0.039759903289496544}. Best is trial 1 with value: 0.5170263463314534.\n","[I 2026-01-27 17:46:10,696] Trial 7 finished with value: 0.45376959950223483 and parameters: {'C': 0.10066935936004746, 'gamma': 5.035889633188824}. Best is trial 1 with value: 0.5170263463314534.\n","[I 2026-01-27 17:46:20,368] Trial 8 finished with value: 0.5100507240552452 and parameters: {'C': 3.206150925246048, 'gamma': 2.603870000980967}. Best is trial 1 with value: 0.5170263463314534.\n","[I 2026-01-27 17:46:29,609] Trial 9 finished with value: 0.4754483072550019 and parameters: {'C': 68.77013393008248, 'gamma': 7.237230697810522}. Best is trial 1 with value: 0.5170263463314534.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 3.4746481988363778, 'gamma': 7.106851736533086}\n","Running final Graph2Vec embedding on train+test graphs...\n","Training final SVM on Graph2Vec embeddings...\n","Graph2Vec Results on IMDB-MULTI -> Acc: 0.433, F1: 0.430, AUC: 0.590, Score: 0.464\n","Embedding time: 11.15s | SVM training time: 1.24s | Optuna time: 94.60s | Memory usage: 1471.80 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n","Loaded dataset IMDB-MULTI for Graph2Vec: 1500 graphs, 3 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:46:42,886] A new study created in memory with name: no-name-38dfd258-df72-4ad9-864c-7fce5f9a4545\n"]},{"output_type":"stream","name":"stdout","text":["Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:46:51,837] Trial 0 finished with value: 0.43986437485622265 and parameters: {'C': 0.05698841520046094, 'gamma': 0.4180560740347483}. Best is trial 0 with value: 0.43986437485622265.\n","[I 2026-01-27 17:47:01,066] Trial 1 finished with value: 0.5535732139570255 and parameters: {'C': 40.41673026445329, 'gamma': 1.4814663179322798}. Best is trial 1 with value: 0.5535732139570255.\n","[I 2026-01-27 17:47:10,452] Trial 2 finished with value: 0.5269673669127395 and parameters: {'C': 2.249545695833285, 'gamma': 0.09297721593632988}. Best is trial 1 with value: 0.5535732139570255.\n","[I 2026-01-27 17:47:19,219] Trial 3 finished with value: 0.3723607718030543 and parameters: {'C': 0.08744337672473487, 'gamma': 9.70680506005835}. Best is trial 1 with value: 0.5535732139570255.\n","[I 2026-01-27 17:47:28,293] Trial 4 finished with value: 0.5271770610754986 and parameters: {'C': 0.8581359778803447, 'gamma': 1.2530857788540548}. Best is trial 1 with value: 0.5535732139570255.\n","[I 2026-01-27 17:47:37,326] Trial 5 finished with value: 0.5047347085038617 and parameters: {'C': 0.34301341827466086, 'gamma': 0.46588274295324966}. Best is trial 1 with value: 0.5535732139570255.\n","[I 2026-01-27 17:47:46,141] Trial 6 finished with value: 0.5160517030005678 and parameters: {'C': 21.25452675689839, 'gamma': 0.12627727478521578}. Best is trial 1 with value: 0.5535732139570255.\n","[I 2026-01-27 17:47:55,295] Trial 7 finished with value: 0.3770720891744548 and parameters: {'C': 3.6112074495971096, 'gamma': 0.0001479065145403185}. Best is trial 1 with value: 0.5535732139570255.\n","[I 2026-01-27 17:48:04,301] Trial 8 finished with value: 0.5232394000488758 and parameters: {'C': 1.7767874575564961, 'gamma': 5.094360471433124}. Best is trial 1 with value: 0.5535732139570255.\n","[I 2026-01-27 17:48:13,063] Trial 9 finished with value: 0.47160499071940604 and parameters: {'C': 78.07958759777273, 'gamma': 0.00016872104138242989}. Best is trial 1 with value: 0.5535732139570255.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 40.41673026445329, 'gamma': 1.4814663179322798}\n","Running final Graph2Vec embedding on train+test graphs...\n","Training final SVM on Graph2Vec embeddings...\n","Graph2Vec Results on IMDB-MULTI -> Acc: 0.417, F1: 0.415, AUC: 0.591, Score: 0.451\n","Embedding time: 11.21s | SVM training time: 0.79s | Optuna time: 90.18s | Memory usage: 1473.54 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n","Loaded dataset ENZYMES for Graph2Vec: 600 graphs, 6 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:48:25,728] A new study created in memory with name: no-name-4469dab1-0869-4126-abf1-0763399d33d9\n"]},{"output_type":"stream","name":"stdout","text":["ENZYMES filtering: removed 1 graphs with < 3 nodes, kept 599 graphs.\n","Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:48:31,031] Trial 0 finished with value: 0.3175005307948252 and parameters: {'C': 0.028639419138244963, 'gamma': 0.25291636755107744}. Best is trial 0 with value: 0.3175005307948252.\n","[I 2026-01-27 17:48:36,125] Trial 1 finished with value: 0.2995560241599486 and parameters: {'C': 1.7706868441888195, 'gamma': 0.0017355386814643249}. Best is trial 0 with value: 0.3175005307948252.\n","[I 2026-01-27 17:48:41,163] Trial 2 finished with value: 0.15437288851351352 and parameters: {'C': 0.012698233446550343, 'gamma': 4.3356765972054845}. Best is trial 0 with value: 0.3175005307948252.\n","[I 2026-01-27 17:48:46,423] Trial 3 finished with value: 0.15129261363636365 and parameters: {'C': 0.015777265435590104, 'gamma': 1.9935324495981528}. Best is trial 0 with value: 0.3175005307948252.\n","[I 2026-01-27 17:48:51,336] Trial 4 finished with value: 0.2754628754287423 and parameters: {'C': 0.01060338812839618, 'gamma': 0.0005919846446764682}. Best is trial 0 with value: 0.3175005307948252.\n","[I 2026-01-27 17:48:56,615] Trial 5 finished with value: 0.4691481313627602 and parameters: {'C': 1.8635933862071399, 'gamma': 0.18780724178389432}. Best is trial 5 with value: 0.4691481313627602.\n","[I 2026-01-27 17:49:01,700] Trial 6 finished with value: 0.3044950293609023 and parameters: {'C': 3.028153995418854, 'gamma': 0.0008343926598524835}. Best is trial 5 with value: 0.4691481313627602.\n","[I 2026-01-27 17:49:06,658] Trial 7 finished with value: 0.16113636363636363 and parameters: {'C': 3.5194735706359195, 'gamma': 5.101342197576081}. Best is trial 5 with value: 0.4691481313627602.\n","[I 2026-01-27 17:49:12,259] Trial 8 finished with value: 0.30349361155861937 and parameters: {'C': 0.5919167854666141, 'gamma': 0.0004903990418358936}. Best is trial 5 with value: 0.4691481313627602.\n","[I 2026-01-27 17:49:17,411] Trial 9 finished with value: 0.359683009180101 and parameters: {'C': 5.817023384775457, 'gamma': 0.7992070142301813}. Best is trial 5 with value: 0.4691481313627602.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 1.8635933862071399, 'gamma': 0.18780724178389432}\n","Running final Graph2Vec embedding on train+test graphs...\n","Training final SVM on Graph2Vec embeddings...\n","Graph2Vec Results on ENZYMES -> Acc: 0.392, F1: 0.393, AUC: 0.730, Score: 0.460\n","Embedding time: 6.86s | SVM training time: 0.14s | Optuna time: 51.68s | Memory usage: 1473.60 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n","Loaded dataset ENZYMES for Graph2Vec: 600 graphs, 6 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:49:24,746] A new study created in memory with name: no-name-dbd509f9-3f94-42bf-ac8a-1bd424a2020a\n"]},{"output_type":"stream","name":"stdout","text":["ENZYMES filtering: removed 1 graphs with < 3 nodes, kept 599 graphs.\n","Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:49:29,728] Trial 0 finished with value: 0.37599187271062273 and parameters: {'C': 95.46059495937493, 'gamma': 0.00031646576010734733}. Best is trial 0 with value: 0.37599187271062273.\n","[I 2026-01-27 17:49:34,848] Trial 1 finished with value: 0.2427298078043947 and parameters: {'C': 1.6112514329880547, 'gamma': 0.0013706351008168876}. Best is trial 0 with value: 0.37599187271062273.\n","[I 2026-01-27 17:49:40,153] Trial 2 finished with value: 0.39019362469898233 and parameters: {'C': 0.7720645332446774, 'gamma': 0.20183208626826546}. Best is trial 2 with value: 0.39019362469898233.\n","[I 2026-01-27 17:49:45,110] Trial 3 finished with value: 0.4450483660438298 and parameters: {'C': 4.004333647847854, 'gamma': 0.2595466630399477}. Best is trial 3 with value: 0.4450483660438298.\n","[I 2026-01-27 17:49:50,474] Trial 4 finished with value: 0.4609305223285487 and parameters: {'C': 1.5094348948602458, 'gamma': 0.1895419485981245}. Best is trial 4 with value: 0.4609305223285487.\n","[I 2026-01-27 17:49:55,799] Trial 5 finished with value: 0.25815837311495643 and parameters: {'C': 2.3854512865274433, 'gamma': 0.00012956330542786837}. Best is trial 4 with value: 0.4609305223285487.\n","[I 2026-01-27 17:50:00,828] Trial 6 finished with value: 0.22304528732039372 and parameters: {'C': 0.024535962369510927, 'gamma': 0.5760188672186428}. Best is trial 4 with value: 0.4609305223285487.\n","[I 2026-01-27 17:50:06,240] Trial 7 finished with value: 0.23445274444290296 and parameters: {'C': 79.54497371351144, 'gamma': 3.7455718982766366}. Best is trial 4 with value: 0.4609305223285487.\n","[I 2026-01-27 17:50:11,458] Trial 8 finished with value: 0.264062903662198 and parameters: {'C': 0.011505320077373773, 'gamma': 0.02908784875068622}. Best is trial 4 with value: 0.4609305223285487.\n","[I 2026-01-27 17:50:16,967] Trial 9 finished with value: 0.2418909220885324 and parameters: {'C': 0.11606402882897714, 'gamma': 0.022118712748940506}. Best is trial 4 with value: 0.4609305223285487.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 1.5094348948602458, 'gamma': 0.1895419485981245}\n","Running final Graph2Vec embedding on train+test graphs...\n","Training final SVM on Graph2Vec embeddings...\n","Graph2Vec Results on ENZYMES -> Acc: 0.400, F1: 0.397, AUC: 0.733, Score: 0.466\n","Embedding time: 6.70s | SVM training time: 0.14s | Optuna time: 52.22s | Memory usage: 1473.60 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n","Loaded dataset ENZYMES for Graph2Vec: 600 graphs, 6 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:50:24,126] A new study created in memory with name: no-name-2ecbd273-3057-4316-90ed-dbe80120633c\n"]},{"output_type":"stream","name":"stdout","text":["ENZYMES filtering: removed 1 graphs with < 3 nodes, kept 599 graphs.\n","Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:50:29,342] Trial 0 finished with value: 0.3363530497299789 and parameters: {'C': 13.622655632171941, 'gamma': 0.007018551119933589}. Best is trial 0 with value: 0.3363530497299789.\n","[I 2026-01-27 17:50:34,766] Trial 1 finished with value: 0.2932746676632546 and parameters: {'C': 0.010092705024610049, 'gamma': 0.24798919625796587}. Best is trial 0 with value: 0.3363530497299789.\n","[I 2026-01-27 17:50:39,961] Trial 2 finished with value: 0.3365954573443798 and parameters: {'C': 80.92347210741383, 'gamma': 0.00016108893199756868}. Best is trial 2 with value: 0.3365954573443798.\n","[I 2026-01-27 17:50:45,297] Trial 3 finished with value: 0.25217453276857305 and parameters: {'C': 2.939513872715674, 'gamma': 0.00015600826633336648}. Best is trial 2 with value: 0.3365954573443798.\n","[I 2026-01-27 17:50:50,187] Trial 4 finished with value: 0.30944733037077055 and parameters: {'C': 8.535788877502526, 'gamma': 0.8780950318836974}. Best is trial 2 with value: 0.3365954573443798.\n","[I 2026-01-27 17:50:55,282] Trial 5 finished with value: 0.2596147338453356 and parameters: {'C': 0.29433126152875755, 'gamma': 0.005023823831337114}. Best is trial 2 with value: 0.3365954573443798.\n","[I 2026-01-27 17:51:00,576] Trial 6 finished with value: 0.25376912332915624 and parameters: {'C': 0.03176781538620928, 'gamma': 0.00017964907692068097}. Best is trial 2 with value: 0.3365954573443798.\n","[I 2026-01-27 17:51:05,524] Trial 7 finished with value: 0.23582224293161796 and parameters: {'C': 0.025037885426281416, 'gamma': 0.03514924421200591}. Best is trial 2 with value: 0.3365954573443798.\n","[I 2026-01-27 17:51:10,806] Trial 8 finished with value: 0.37617427174218965 and parameters: {'C': 37.43424113468544, 'gamma': 0.05742978471279611}. Best is trial 8 with value: 0.37617427174218965.\n","[I 2026-01-27 17:51:15,927] Trial 9 finished with value: 0.3165861487862496 and parameters: {'C': 49.62964188398516, 'gamma': 0.004328316814929871}. Best is trial 8 with value: 0.37617427174218965.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 37.43424113468544, 'gamma': 0.05742978471279611}\n","Running final Graph2Vec embedding on train+test graphs...\n","Training final SVM on Graph2Vec embeddings...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:51:22,821] A new study created in memory with name: no-name-1287f607-07fc-406d-8fe4-d867001c8ae9\n"]},{"output_type":"stream","name":"stdout","text":["Graph2Vec Results on ENZYMES -> Acc: 0.358, F1: 0.346, AUC: 0.724, Score: 0.428\n","Embedding time: 6.43s | SVM training time: 0.24s | Optuna time: 51.80s | Memory usage: 1473.60 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n","Loaded dataset MUTAG for Graph2Vec: 188 graphs, 2 classes\n","Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:51:23,981] Trial 0 finished with value: 0.8072272727272728 and parameters: {'C': 20.81817611857203, 'gamma': 0.061802908291554735}. Best is trial 0 with value: 0.8072272727272728.\n","[I 2026-01-27 17:51:25,065] Trial 1 finished with value: 0.6453333333333333 and parameters: {'C': 0.01778794288245111, 'gamma': 0.028802524142384277}. Best is trial 0 with value: 0.8072272727272728.\n","[I 2026-01-27 17:51:25,803] Trial 2 finished with value: 0.6823333333333332 and parameters: {'C': 0.0222603478621279, 'gamma': 4.97720981889199}. Best is trial 0 with value: 0.8072272727272728.\n","[I 2026-01-27 17:51:26,595] Trial 3 finished with value: 0.840111111111111 and parameters: {'C': 1.4893453547469757, 'gamma': 3.3492319656503327}. Best is trial 3 with value: 0.840111111111111.\n","[I 2026-01-27 17:51:27,351] Trial 4 finished with value: 0.6423333333333333 and parameters: {'C': 2.666325237654527, 'gamma': 0.011296903585200087}. Best is trial 3 with value: 0.840111111111111.\n","[I 2026-01-27 17:51:28,106] Trial 5 finished with value: 0.6383333333333333 and parameters: {'C': 0.011334718098553269, 'gamma': 0.00030716768760189595}. Best is trial 3 with value: 0.840111111111111.\n","[I 2026-01-27 17:51:28,867] Trial 6 finished with value: 0.6433333333333333 and parameters: {'C': 7.69805726529976, 'gamma': 0.0010723787347415826}. Best is trial 3 with value: 0.840111111111111.\n","[I 2026-01-27 17:51:29,611] Trial 7 finished with value: 0.9003994528043775 and parameters: {'C': 2.164886681667186, 'gamma': 1.5616813009677528}. Best is trial 7 with value: 0.9003994528043775.\n","[I 2026-01-27 17:51:30,364] Trial 8 finished with value: 0.6813333333333333 and parameters: {'C': 0.1270961176554377, 'gamma': 5.841856249112646}. Best is trial 7 with value: 0.9003994528043775.\n","[I 2026-01-27 17:51:31,102] Trial 9 finished with value: 0.6413333333333333 and parameters: {'C': 0.21388610849315084, 'gamma': 0.013916379418899841}. Best is trial 7 with value: 0.9003994528043775.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 2.164886681667186, 'gamma': 1.5616813009677528}\n","Running final Graph2Vec embedding on train+test graphs...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:51:32,110] A new study created in memory with name: no-name-c1438e64-5d8f-4bae-9ce0-a68daa6ee086\n"]},{"output_type":"stream","name":"stdout","text":["Training final SVM on Graph2Vec embeddings...\n","Graph2Vec Results on MUTAG -> Acc: 0.789, F1: 0.778, AUC: 0.868, Score: 0.802\n","Embedding time: 0.90s | SVM training time: 0.01s | Optuna time: 8.28s | Memory usage: 1473.60 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n","Loaded dataset MUTAG for Graph2Vec: 188 graphs, 2 classes\n","Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:51:32,912] Trial 0 finished with value: 0.6423333333333333 and parameters: {'C': 0.08082738610154913, 'gamma': 0.02913298242273298}. Best is trial 0 with value: 0.6423333333333333.\n","[I 2026-01-27 17:51:33,667] Trial 1 finished with value: 0.6423333333333333 and parameters: {'C': 26.174238043768984, 'gamma': 0.0009840534837662574}. Best is trial 0 with value: 0.6423333333333333.\n","[I 2026-01-27 17:51:34,440] Trial 2 finished with value: 0.6423333333333333 and parameters: {'C': 2.004236946854984, 'gamma': 0.002166521980937205}. Best is trial 0 with value: 0.6423333333333333.\n","[I 2026-01-27 17:51:35,322] Trial 3 finished with value: 0.8671515151515152 and parameters: {'C': 27.157199159073894, 'gamma': 0.17646958746853852}. Best is trial 3 with value: 0.8671515151515152.\n","[I 2026-01-27 17:51:36,459] Trial 4 finished with value: 0.6423333333333333 and parameters: {'C': 0.7645115495374762, 'gamma': 0.03445426250161034}. Best is trial 3 with value: 0.8671515151515152.\n","[I 2026-01-27 17:51:37,893] Trial 5 finished with value: 0.8631515151515152 and parameters: {'C': 5.894508542072253, 'gamma': 0.25352487184275446}. Best is trial 3 with value: 0.8671515151515152.\n","[I 2026-01-27 17:51:38,776] Trial 6 finished with value: 0.6403333333333333 and parameters: {'C': 0.1274736956062761, 'gamma': 0.006321396584598133}. Best is trial 3 with value: 0.8671515151515152.\n","[I 2026-01-27 17:51:39,536] Trial 7 finished with value: 0.8671515151515152 and parameters: {'C': 84.03883161005574, 'gamma': 0.06814667558956539}. Best is trial 3 with value: 0.8671515151515152.\n","[I 2026-01-27 17:51:40,301] Trial 8 finished with value: 0.6343333333333333 and parameters: {'C': 0.01689866309663618, 'gamma': 0.004745455196898789}. Best is trial 3 with value: 0.8671515151515152.\n","[I 2026-01-27 17:51:41,053] Trial 9 finished with value: 0.6423333333333333 and parameters: {'C': 0.016813669984319473, 'gamma': 0.16808362339343086}. Best is trial 3 with value: 0.8671515151515152.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 27.157199159073894, 'gamma': 0.17646958746853852}\n","Running final Graph2Vec embedding on train+test graphs...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:51:42,079] A new study created in memory with name: no-name-2dbfd664-bf16-40cb-9a41-dfd3d9034780\n"]},{"output_type":"stream","name":"stdout","text":["Training final SVM on Graph2Vec embeddings...\n","Graph2Vec Results on MUTAG -> Acc: 0.789, F1: 0.789, AUC: 0.880, Score: 0.808\n","Embedding time: 0.93s | SVM training time: 0.01s | Optuna time: 8.94s | Memory usage: 1470.65 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n","Loaded dataset MUTAG for Graph2Vec: 188 graphs, 2 classes\n","Running Optuna for Graph2Vec+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:51:42,827] Trial 0 finished with value: 0.793344886606761 and parameters: {'C': 3.415747094029785, 'gamma': 1.556084003590642}. Best is trial 0 with value: 0.793344886606761.\n","[I 2026-01-27 17:51:43,582] Trial 1 finished with value: 0.7945987232102144 and parameters: {'C': 0.7875087762740153, 'gamma': 3.900645092385029}. Best is trial 1 with value: 0.7945987232102144.\n","[I 2026-01-27 17:51:44,331] Trial 2 finished with value: 0.6923333333333332 and parameters: {'C': 0.4109401878386158, 'gamma': 0.011465912050758722}. Best is trial 1 with value: 0.7945987232102144.\n","[I 2026-01-27 17:51:45,090] Trial 3 finished with value: 0.6893333333333334 and parameters: {'C': 1.8958977592663582, 'gamma': 0.0013999152747740937}. Best is trial 1 with value: 0.7945987232102144.\n","[I 2026-01-27 17:51:45,839] Trial 4 finished with value: 0.6923333333333332 and parameters: {'C': 0.022890984815543306, 'gamma': 0.32112199535638775}. Best is trial 1 with value: 0.7945987232102144.\n","[I 2026-01-27 17:51:46,591] Trial 5 finished with value: 0.6883333333333334 and parameters: {'C': 1.787486915307521, 'gamma': 0.0004328976222302571}. Best is trial 1 with value: 0.7945987232102144.\n","[I 2026-01-27 17:51:47,360] Trial 6 finished with value: 0.6883333333333334 and parameters: {'C': 0.6436189158426129, 'gamma': 0.0015827734980011392}. Best is trial 1 with value: 0.7945987232102144.\n","[I 2026-01-27 17:51:48,122] Trial 7 finished with value: 0.6883333333333334 and parameters: {'C': 0.25084112710817674, 'gamma': 0.0033457062472988736}. Best is trial 1 with value: 0.7945987232102144.\n","[I 2026-01-27 17:51:49,195] Trial 8 finished with value: 0.6913333333333334 and parameters: {'C': 0.11223007714029973, 'gamma': 0.039797384537544986}. Best is trial 1 with value: 0.7945987232102144.\n","[I 2026-01-27 17:51:50,360] Trial 9 finished with value: 0.6873333333333334 and parameters: {'C': 0.04589427091264901, 'gamma': 1.877507930627569}. Best is trial 1 with value: 0.7945987232102144.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (Graph2Vec+SVM): {'C': 0.7875087762740153, 'gamma': 3.900645092385029}\n","Running final Graph2Vec embedding on train+test graphs...\n","Training final SVM on Graph2Vec embeddings...\n","Graph2Vec Results on MUTAG -> Acc: 0.789, F1: 0.789, AUC: 0.862, Score: 0.804\n","Embedding time: 1.35s | SVM training time: 0.01s | Optuna time: 8.28s | Memory usage: 1470.65 MB\n","Graph2Vec summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/g2v.csv\n"]}],"source":["for dataset_name in [\"IMDB-MULTI\", \"ENZYMES\", \"MUTAG\"]:\n","  for seed in [42, 43, 44]:\n","      run_graph2vec_pipeline(\n","          dataset_name=dataset_name,\n","          seed=seed,\n","          w_acc=0.5, w_f1=0.3, w_auc=0.2,\n","          embedding_dim=128,\n","          epochs=200,\n","          test_size=0.2,\n","          use_optuna=True,\n","          n_trials=10,\n","      )"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":248078,"status":"ok","timestamp":1769536559997,"user":{"displayName":"Angeliki Spanou-Kapantoni","userId":"03387034804000599271"},"user_tz":-120},"id":"6az0J-SNqi11","outputId":"eb7d1039-8f15-4a84-f33e-a93ae8925941"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded dataset IMDB-MULTI for NetLSD: 1500 graphs, 3 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:51:52,264] A new study created in memory with name: no-name-d84aa726-f79e-47d5-be99-bea720726354\n"]},{"output_type":"stream","name":"stdout","text":["Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:51:56,644] Trial 0 finished with value: 0.34947103262366186 and parameters: {'C': 0.04033374011187141, 'gamma': 1.54694488280316}. Best is trial 0 with value: 0.34947103262366186.\n","[I 2026-01-27 17:52:00,935] Trial 1 finished with value: 0.42135489933741077 and parameters: {'C': 0.06192663099172617, 'gamma': 0.00011326495532043095}. Best is trial 1 with value: 0.42135489933741077.\n","[I 2026-01-27 17:52:06,548] Trial 2 finished with value: 0.4225215660040774 and parameters: {'C': 0.9795645028447804, 'gamma': 0.002972120556553736}. Best is trial 2 with value: 0.4225215660040774.\n","[I 2026-01-27 17:52:10,804] Trial 3 finished with value: 0.4186047886957813 and parameters: {'C': 0.6116347303349853, 'gamma': 0.040648560150916405}. Best is trial 2 with value: 0.4225215660040774.\n","[I 2026-01-27 17:52:15,204] Trial 4 finished with value: 0.42261010767074414 and parameters: {'C': 3.460961910612948, 'gamma': 0.0004381137458508494}. Best is trial 4 with value: 0.42261010767074414.\n","[I 2026-01-27 17:52:20,685] Trial 5 finished with value: 0.4223236493374108 and parameters: {'C': 0.09545553766107186, 'gamma': 0.00035779236007528416}. Best is trial 4 with value: 0.42261010767074414.\n","[I 2026-01-27 17:52:24,962] Trial 6 finished with value: 0.4229330243374108 and parameters: {'C': 12.878696788994738, 'gamma': 0.00012925946013102904}. Best is trial 6 with value: 0.4229330243374108.\n","[I 2026-01-27 17:52:29,645] Trial 7 finished with value: 0.4222611493374108 and parameters: {'C': 3.2930563838802858, 'gamma': 0.0003131039188527072}. Best is trial 6 with value: 0.4229330243374108.\n","[I 2026-01-27 17:52:34,690] Trial 8 finished with value: 0.44249780254467763 and parameters: {'C': 9.911160566612544, 'gamma': 2.5794568691187574}. Best is trial 8 with value: 0.44249780254467763.\n","[I 2026-01-27 17:52:38,959] Trial 9 finished with value: 0.4365223207017258 and parameters: {'C': 8.81780951172971, 'gamma': 0.3780770090142946}. Best is trial 8 with value: 0.44249780254467763.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 9.911160566612544, 'gamma': 2.5794568691187574}\n","Running final NetLSD embedding on train+test graphs...\n","Training final SVM on NetLSD embeddings...\n","NetLSD Results on IMDB-MULTI -> Acc: 0.453, F1: 0.403, AUC: 0.646, Score: 0.477\n","Embedding time: 5.10s | SVM training time: 1.59s | Optuna time: 46.70s | Memory usage: 1477.66 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n","Loaded dataset IMDB-MULTI for NetLSD: 1500 graphs, 3 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:52:46,394] A new study created in memory with name: no-name-cf8c85e6-f8ad-43b9-a9d7-d73a3660406d\n"]},{"output_type":"stream","name":"stdout","text":["Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:52:51,022] Trial 0 finished with value: 0.4711949765008424 and parameters: {'C': 0.586583702636339, 'gamma': 6.008923438150466}. Best is trial 0 with value: 0.4711949765008424.\n","[I 2026-01-27 17:52:55,481] Trial 1 finished with value: 0.43387215377850386 and parameters: {'C': 0.058652341751429395, 'gamma': 0.0002456751108299386}. Best is trial 0 with value: 0.4711949765008424.\n","[I 2026-01-27 17:53:00,956] Trial 2 finished with value: 0.43321590377850383 and parameters: {'C': 0.028538291781789196, 'gamma': 0.002404335205074206}. Best is trial 0 with value: 0.4711949765008424.\n","[I 2026-01-27 17:53:05,226] Trial 3 finished with value: 0.47996932641813833 and parameters: {'C': 1.0316018465099985, 'gamma': 7.176231257413315}. Best is trial 3 with value: 0.47996932641813833.\n","[I 2026-01-27 17:53:09,985] Trial 4 finished with value: 0.4346013204451705 and parameters: {'C': 0.1278273503748476, 'gamma': 0.001589586501268075}. Best is trial 3 with value: 0.47996932641813833.\n","[I 2026-01-27 17:53:15,015] Trial 5 finished with value: 0.43452319544517054 and parameters: {'C': 0.07526238897155432, 'gamma': 0.02270686276270095}. Best is trial 3 with value: 0.47996932641813833.\n","[I 2026-01-27 17:53:19,334] Trial 6 finished with value: 0.4337263204451705 and parameters: {'C': 0.014213698026828104, 'gamma': 0.003127028616098871}. Best is trial 3 with value: 0.47996932641813833.\n","[I 2026-01-27 17:53:24,433] Trial 7 finished with value: 0.4899501426832932 and parameters: {'C': 5.7754454368047865, 'gamma': 6.530494131456295}. Best is trial 7 with value: 0.4899501426832932.\n","[I 2026-01-27 17:53:29,058] Trial 8 finished with value: 0.4187435304430727 and parameters: {'C': 0.034115271345997525, 'gamma': 0.6571108358881966}. Best is trial 7 with value: 0.4899501426832932.\n","[I 2026-01-27 17:53:33,320] Trial 9 finished with value: 0.43720499835772764 and parameters: {'C': 0.047684817514220705, 'gamma': 0.030104235343063612}. Best is trial 7 with value: 0.4899501426832932.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 5.7754454368047865, 'gamma': 6.530494131456295}\n","Running final NetLSD embedding on train+test graphs...\n","Training final SVM on NetLSD embeddings...\n","NetLSD Results on IMDB-MULTI -> Acc: 0.490, F1: 0.477, AUC: 0.648, Score: 0.518\n","Embedding time: 5.47s | SVM training time: 1.21s | Optuna time: 46.93s | Memory usage: 1479.67 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n","Loaded dataset IMDB-MULTI for NetLSD: 1500 graphs, 3 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:53:40,731] A new study created in memory with name: no-name-55ebc45b-1485-486c-8dc1-a5b426b6f0b7\n"]},{"output_type":"stream","name":"stdout","text":["Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:53:44,963] Trial 0 finished with value: 0.44470096486175115 and parameters: {'C': 44.195333187639235, 'gamma': 0.3447859467818733}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:53:49,597] Trial 1 finished with value: 0.4385924544844073 and parameters: {'C': 35.4873459682906, 'gamma': 0.03953976858210211}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:53:54,824] Trial 2 finished with value: 0.3991232408235394 and parameters: {'C': 1.9759039542081358, 'gamma': 0.0060932196090945495}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:53:59,137] Trial 3 finished with value: 0.3989409491568727 and parameters: {'C': 0.010668871121780919, 'gamma': 0.002067421903653998}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:54:04,216] Trial 4 finished with value: 0.3996336574902061 and parameters: {'C': 0.11681318888259669, 'gamma': 0.0032055386960826455}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:54:09,061] Trial 5 finished with value: 0.3986076158235394 and parameters: {'C': 8.795031282554334, 'gamma': 0.0015647302746583532}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:54:13,464] Trial 6 finished with value: 0.3997065741568727 and parameters: {'C': 4.960085527633247, 'gamma': 0.0007728671901886155}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:54:19,042] Trial 7 finished with value: 0.43922266281774064 and parameters: {'C': 15.00981531642381, 'gamma': 0.15618508896587674}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:54:23,358] Trial 8 finished with value: 0.3991832035398064 and parameters: {'C': 0.6524496111336352, 'gamma': 0.027354908217641145}. Best is trial 0 with value: 0.44470096486175115.\n","[I 2026-01-27 17:54:27,643] Trial 9 finished with value: 0.39972219915687274 and parameters: {'C': 0.4679349878466779, 'gamma': 0.004847268301618574}. Best is trial 0 with value: 0.44470096486175115.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 44.195333187639235, 'gamma': 0.3447859467818733}\n","Running final NetLSD embedding on train+test graphs...\n","Training final SVM on NetLSD embeddings...\n","NetLSD Results on IMDB-MULTI -> Acc: 0.450, F1: 0.410, AUC: 0.613, Score: 0.471\n","Embedding time: 5.56s | SVM training time: 1.32s | Optuna time: 46.91s | Memory usage: 1488.64 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n","Loaded dataset ENZYMES for NetLSD: 600 graphs, 6 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:54:35,015] A new study created in memory with name: no-name-7e74cd77-5e97-4ea6-b81e-a16df0741419\n"]},{"output_type":"stream","name":"stdout","text":["ENZYMES filtering: removed 1 graphs with < 3 nodes, kept 599 graphs.\n","Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:54:36,778] Trial 0 finished with value: 0.1935231357887608 and parameters: {'C': 0.04910320349365897, 'gamma': 1.1412298459544579}. Best is trial 0 with value: 0.1935231357887608.\n","[I 2026-01-27 17:54:38,549] Trial 1 finished with value: 0.2022274652369761 and parameters: {'C': 0.2581647654522988, 'gamma': 0.0009852452299187286}. Best is trial 1 with value: 0.2022274652369761.\n","[I 2026-01-27 17:54:40,370] Trial 2 finished with value: 0.2026180902369761 and parameters: {'C': 0.05600696906204889, 'gamma': 0.0012147157502696018}. Best is trial 2 with value: 0.2026180902369761.\n","[I 2026-01-27 17:54:42,193] Trial 3 finished with value: 0.20587329857030945 and parameters: {'C': 0.019716785264861952, 'gamma': 0.0010624371356294415}. Best is trial 3 with value: 0.20587329857030945.\n","[I 2026-01-27 17:54:44,937] Trial 4 finished with value: 0.2083926102599078 and parameters: {'C': 1.7501349443039305, 'gamma': 0.1163228715527889}. Best is trial 4 with value: 0.2083926102599078.\n","[I 2026-01-27 17:54:47,034] Trial 5 finished with value: 0.20264413190364278 and parameters: {'C': 0.35070856044700677, 'gamma': 0.0003544089019361589}. Best is trial 4 with value: 0.2083926102599078.\n","[I 2026-01-27 17:54:48,829] Trial 6 finished with value: 0.2587053927432217 and parameters: {'C': 0.21244771545059238, 'gamma': 4.659584665395062}. Best is trial 6 with value: 0.2587053927432217.\n","[I 2026-01-27 17:54:50,635] Trial 7 finished with value: 0.20269621523697612 and parameters: {'C': 1.1138940999718323, 'gamma': 0.02168983312685554}. Best is trial 6 with value: 0.2587053927432217.\n","[I 2026-01-27 17:54:52,411] Trial 8 finished with value: 0.20259204857030944 and parameters: {'C': 0.04364784914955102, 'gamma': 0.002859213858625572}. Best is trial 6 with value: 0.2587053927432217.\n","[I 2026-01-27 17:54:54,214] Trial 9 finished with value: 0.2330662771986785 and parameters: {'C': 0.023506259484911283, 'gamma': 2.666195131679258}. Best is trial 6 with value: 0.2587053927432217.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 0.21244771545059238, 'gamma': 4.659584665395062}\n","Running final NetLSD embedding on train+test graphs...\n","Training final SVM on NetLSD embeddings...\n","NetLSD Results on ENZYMES -> Acc: 0.225, F1: 0.161, AUC: 0.534, Score: 0.267\n","Embedding time: 2.36s | SVM training time: 0.35s | Optuna time: 19.20s | Memory usage: 1492.91 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n","Loaded dataset ENZYMES for NetLSD: 600 graphs, 6 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:54:57,453] A new study created in memory with name: no-name-7dae94b7-d674-4f77-b48c-117901255247\n"]},{"output_type":"stream","name":"stdout","text":["ENZYMES filtering: removed 1 graphs with < 3 nodes, kept 599 graphs.\n","Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:54:59,897] Trial 0 finished with value: 0.2767578488792821 and parameters: {'C': 34.062935527717, 'gamma': 0.6723227879566919}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:01,714] Trial 1 finished with value: 0.2680466569640677 and parameters: {'C': 66.39001280715284, 'gamma': 1.952056013199414}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:03,533] Trial 2 finished with value: 0.19830430506993008 and parameters: {'C': 63.09769142063101, 'gamma': 0.002443812505496432}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:05,330] Trial 3 finished with value: 0.22274441459276018 and parameters: {'C': 0.014859713292332677, 'gamma': 0.00036973304635345365}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:07,128] Trial 4 finished with value: 0.22183295625942684 and parameters: {'C': 1.5406950753605273, 'gamma': 0.002907485486382648}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:08,913] Trial 5 finished with value: 0.18559661345598846 and parameters: {'C': 17.365827478268898, 'gamma': 0.028550277360568744}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:11,627] Trial 6 finished with value: 0.22154649792609354 and parameters: {'C': 0.019186393145170233, 'gamma': 0.02607363830190878}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:13,829] Trial 7 finished with value: 0.22288664215686277 and parameters: {'C': 0.13641801879429308, 'gamma': 0.0001852025632465566}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:15,604] Trial 8 finished with value: 0.23589488636363637 and parameters: {'C': 19.236783249995923, 'gamma': 0.0831112714561305}. Best is trial 0 with value: 0.2767578488792821.\n","[I 2026-01-27 17:55:17,375] Trial 9 finished with value: 0.24060585068666965 and parameters: {'C': 10.666906319211133, 'gamma': 0.3308282509480769}. Best is trial 0 with value: 0.2767578488792821.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 34.062935527717, 'gamma': 0.6723227879566919}\n","Running final NetLSD embedding on train+test graphs...\n","Training final SVM on NetLSD embeddings...\n","NetLSD Results on ENZYMES -> Acc: 0.308, F1: 0.260, AUC: 0.617, Score: 0.355\n","Embedding time: 2.08s | SVM training time: 0.21s | Optuna time: 19.92s | Memory usage: 1502.93 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n","Loaded dataset ENZYMES for NetLSD: 600 graphs, 6 classes\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:55:20,363] A new study created in memory with name: no-name-67255d27-92f4-4368-9f52-53eeffe1da58\n"]},{"output_type":"stream","name":"stdout","text":["ENZYMES filtering: removed 1 graphs with < 3 nodes, kept 599 graphs.\n","Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:55:22,169] Trial 0 finished with value: 0.25084218493431854 and parameters: {'C': 1.6361892493710357, 'gamma': 0.3670573924036089}. Best is trial 0 with value: 0.25084218493431854.\n","[I 2026-01-27 17:55:24,662] Trial 1 finished with value: 0.2571930741360089 and parameters: {'C': 0.053938013285955926, 'gamma': 0.17219480409711083}. Best is trial 1 with value: 0.2571930741360089.\n","[I 2026-01-27 17:55:26,998] Trial 2 finished with value: 0.32306886068030577 and parameters: {'C': 2.157997468248909, 'gamma': 8.18011717531529}. Best is trial 2 with value: 0.32306886068030577.\n","[I 2026-01-27 17:55:28,783] Trial 3 finished with value: 0.24863920032670034 and parameters: {'C': 0.015507089297973663, 'gamma': 0.11714515389232447}. Best is trial 2 with value: 0.32306886068030577.\n","[I 2026-01-27 17:55:30,557] Trial 4 finished with value: 0.25594175279377485 and parameters: {'C': 0.35816047316493466, 'gamma': 0.0858973387435618}. Best is trial 2 with value: 0.32306886068030577.\n","[I 2026-01-27 17:55:32,343] Trial 5 finished with value: 0.25382429621384367 and parameters: {'C': 25.93750761311243, 'gamma': 0.00012349619006097798}. Best is trial 2 with value: 0.32306886068030577.\n","[I 2026-01-27 17:55:34,123] Trial 6 finished with value: 0.2568444364428079 and parameters: {'C': 0.7534410381311568, 'gamma': 0.14859503276255503}. Best is trial 2 with value: 0.32306886068030577.\n","[I 2026-01-27 17:55:35,898] Trial 7 finished with value: 0.2571758342760181 and parameters: {'C': 0.3852173707477605, 'gamma': 0.18193177262874996}. Best is trial 2 with value: 0.32306886068030577.\n","[I 2026-01-27 17:55:38,574] Trial 8 finished with value: 0.2538503378805103 and parameters: {'C': 0.1238418159520417, 'gamma': 0.00029336624646665734}. Best is trial 2 with value: 0.32306886068030577.\n","[I 2026-01-27 17:55:40,738] Trial 9 finished with value: 0.28672191550763226 and parameters: {'C': 0.010295816538358489, 'gamma': 1.057805189663651}. Best is trial 2 with value: 0.32306886068030577.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 2.157997468248909, 'gamma': 8.18011717531529}\n","Running final NetLSD embedding on train+test graphs...\n","Training final SVM on NetLSD embeddings...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:55:43,127] A new study created in memory with name: no-name-2f20c5fc-740b-4934-89ad-b8181b3de527\n"]},{"output_type":"stream","name":"stdout","text":["NetLSD Results on ENZYMES -> Acc: 0.300, F1: 0.273, AUC: 0.666, Score: 0.365\n","Embedding time: 2.05s | SVM training time: 0.19s | Optuna time: 20.38s | Memory usage: 1503.74 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n","Loaded dataset MUTAG for NetLSD: 188 graphs, 2 classes\n","Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:55:43,572] Trial 0 finished with value: 0.6733333333333333 and parameters: {'C': 0.5736573042035434, 'gamma': 0.37586349764630334}. Best is trial 0 with value: 0.6733333333333333.\n","[I 2026-01-27 17:55:44,034] Trial 1 finished with value: 0.6733333333333333 and parameters: {'C': 0.24080258028223805, 'gamma': 0.0003393178478442463}. Best is trial 0 with value: 0.6733333333333333.\n","[I 2026-01-27 17:55:44,473] Trial 2 finished with value: 0.6733333333333333 and parameters: {'C': 52.83047914438532, 'gamma': 0.00040371798888172076}. Best is trial 0 with value: 0.6733333333333333.\n","[I 2026-01-27 17:55:44,922] Trial 3 finished with value: 0.8983994528043775 and parameters: {'C': 81.09412736504882, 'gamma': 0.023884502032076024}. Best is trial 3 with value: 0.8983994528043775.\n","[I 2026-01-27 17:55:45,367] Trial 4 finished with value: 0.6733333333333333 and parameters: {'C': 0.15422667327586767, 'gamma': 0.000372296279943823}. Best is trial 3 with value: 0.8983994528043775.\n","[I 2026-01-27 17:55:45,817] Trial 5 finished with value: 0.6733333333333333 and parameters: {'C': 60.91875702050027, 'gamma': 0.0008838788535912705}. Best is trial 3 with value: 0.8983994528043775.\n","[I 2026-01-27 17:55:46,263] Trial 6 finished with value: 0.6733333333333333 and parameters: {'C': 0.10329496876555665, 'gamma': 0.0009508767562757887}. Best is trial 3 with value: 0.8983994528043775.\n","[I 2026-01-27 17:55:46,705] Trial 7 finished with value: 0.7796999454446263 and parameters: {'C': 0.6673803560171435, 'gamma': 0.7168308076262134}. Best is trial 3 with value: 0.8983994528043775.\n","[I 2026-01-27 17:55:47,162] Trial 8 finished with value: 0.6733333333333333 and parameters: {'C': 0.27884546324775716, 'gamma': 0.3416030895010989}. Best is trial 3 with value: 0.8983994528043775.\n","[I 2026-01-27 17:55:47,606] Trial 9 finished with value: 0.7466666666666666 and parameters: {'C': 5.599841609676197, 'gamma': 0.06921530439780318}. Best is trial 3 with value: 0.8983994528043775.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 81.09412736504882, 'gamma': 0.023884502032076024}\n","Running final NetLSD embedding on train+test graphs...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:55:48,274] A new study created in memory with name: no-name-815161c7-8ae8-4c07-81fd-29101a97ad23\n"]},{"output_type":"stream","name":"stdout","text":["Training final SVM on NetLSD embeddings...\n","NetLSD Results on MUTAG -> Acc: 0.763, F1: 0.754, AUC: 0.843, Score: 0.777\n","Embedding time: 0.55s | SVM training time: 0.01s | Optuna time: 4.48s | Memory usage: 1503.74 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n","Loaded dataset MUTAG for NetLSD: 188 graphs, 2 classes\n","Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:55:48,723] Trial 0 finished with value: 0.6653333333333333 and parameters: {'C': 87.66809693477025, 'gamma': 0.0016097095613621796}. Best is trial 0 with value: 0.6653333333333333.\n","[I 2026-01-27 17:55:49,233] Trial 1 finished with value: 0.878063492063492 and parameters: {'C': 32.85159638528139, 'gamma': 3.1037329792990342}. Best is trial 1 with value: 0.878063492063492.\n","[I 2026-01-27 17:55:49,703] Trial 2 finished with value: 0.6653333333333333 and parameters: {'C': 2.829792768458278, 'gamma': 0.001767861620673457}. Best is trial 1 with value: 0.878063492063492.\n","[I 2026-01-27 17:55:50,423] Trial 3 finished with value: 0.6643333333333333 and parameters: {'C': 0.7029766237901394, 'gamma': 0.002366627973957685}. Best is trial 1 with value: 0.878063492063492.\n","[I 2026-01-27 17:55:51,133] Trial 4 finished with value: 0.6643333333333333 and parameters: {'C': 0.03438253011082182, 'gamma': 0.8325788095228694}. Best is trial 1 with value: 0.878063492063492.\n","[I 2026-01-27 17:55:51,852] Trial 5 finished with value: 0.6643333333333333 and parameters: {'C': 2.5683825690273494, 'gamma': 0.0005420017439867766}. Best is trial 1 with value: 0.878063492063492.\n","[I 2026-01-27 17:55:52,551] Trial 6 finished with value: 0.6653333333333333 and parameters: {'C': 0.013138866235457984, 'gamma': 1.7284050297983315}. Best is trial 1 with value: 0.878063492063492.\n","[I 2026-01-27 17:55:53,200] Trial 7 finished with value: 0.6643333333333333 and parameters: {'C': 0.38207625262947104, 'gamma': 0.06913832522346955}. Best is trial 1 with value: 0.878063492063492.\n","[I 2026-01-27 17:55:53,656] Trial 8 finished with value: 0.8680634920634921 and parameters: {'C': 6.308443035413943, 'gamma': 1.3111091521904978}. Best is trial 1 with value: 0.878063492063492.\n","[I 2026-01-27 17:55:54,110] Trial 9 finished with value: 0.6653333333333333 and parameters: {'C': 0.05711501247312209, 'gamma': 0.0713741105859654}. Best is trial 1 with value: 0.878063492063492.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 32.85159638528139, 'gamma': 3.1037329792990342}\n","Running final NetLSD embedding on train+test graphs...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:55:54,764] A new study created in memory with name: no-name-cf686a17-11a9-4346-a0e0-36190f239937\n"]},{"output_type":"stream","name":"stdout","text":["Training final SVM on NetLSD embeddings...\n","NetLSD Results on MUTAG -> Acc: 0.789, F1: 0.778, AUC: 0.831, Score: 0.794\n","Embedding time: 0.55s | SVM training time: 0.01s | Optuna time: 5.84s | Memory usage: 1503.74 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n","Loaded dataset MUTAG for NetLSD: 188 graphs, 2 classes\n","Running Optuna for NetLSD+SVM hyperparameter tuning...\n"]},{"output_type":"stream","name":"stderr","text":["[I 2026-01-27 17:55:55,211] Trial 0 finished with value: 0.6763333333333332 and parameters: {'C': 2.149651540372503, 'gamma': 0.000773951067036475}. Best is trial 0 with value: 0.6763333333333332.\n","[I 2026-01-27 17:55:55,672] Trial 1 finished with value: 0.6763333333333332 and parameters: {'C': 0.012819520405551538, 'gamma': 0.04646265411363027}. Best is trial 0 with value: 0.6763333333333332.\n","[I 2026-01-27 17:55:56,122] Trial 2 finished with value: 0.6763333333333332 and parameters: {'C': 0.0786341955232671, 'gamma': 0.04234625504326544}. Best is trial 0 with value: 0.6763333333333332.\n","[I 2026-01-27 17:55:56,585] Trial 3 finished with value: 0.6763333333333332 and parameters: {'C': 0.3036874786054862, 'gamma': 0.11250456730688667}. Best is trial 0 with value: 0.6763333333333332.\n","[I 2026-01-27 17:55:57,034] Trial 4 finished with value: 0.8983994528043775 and parameters: {'C': 20.017512642443723, 'gamma': 0.45360797820022825}. Best is trial 4 with value: 0.8983994528043775.\n","[I 2026-01-27 17:55:57,493] Trial 5 finished with value: 0.8983994528043775 and parameters: {'C': 39.65680808988371, 'gamma': 0.2722734396546999}. Best is trial 4 with value: 0.8983994528043775.\n","[I 2026-01-27 17:55:57,939] Trial 6 finished with value: 0.8993994528043776 and parameters: {'C': 9.811077059604782, 'gamma': 1.9642985053025699}. Best is trial 6 with value: 0.8993994528043776.\n","[I 2026-01-27 17:55:58,391] Trial 7 finished with value: 0.6763333333333332 and parameters: {'C': 0.21893548556146886, 'gamma': 0.06248725969793292}. Best is trial 6 with value: 0.8993994528043776.\n","[I 2026-01-27 17:55:58,852] Trial 8 finished with value: 0.6763333333333332 and parameters: {'C': 2.4298177922493167, 'gamma': 0.002132119788780458}. Best is trial 6 with value: 0.8993994528043776.\n","[I 2026-01-27 17:55:59,295] Trial 9 finished with value: 0.6763333333333332 and parameters: {'C': 10.29847716885292, 'gamma': 0.0003805131643770771}. Best is trial 6 with value: 0.8993994528043776.\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters (NetLSD+SVM): {'C': 9.811077059604782, 'gamma': 1.9642985053025699}\n","Running final NetLSD embedding on train+test graphs...\n","Training final SVM on NetLSD embeddings...\n","NetLSD Results on MUTAG -> Acc: 0.868, F1: 0.870, AUC: 0.862, Score: 0.867\n","Embedding time: 0.55s | SVM training time: 0.01s | Optuna time: 4.53s | Memory usage: 1503.74 MB\n","NetLSD summary stored in: /content/drive/MyDrive/InformationSystems/Classification/results/classification/netlsd.csv\n"]}],"source":["for dataset_name in [\"IMDB-MULTI\", \"ENZYMES\", \"MUTAG\"]:\n","  for seed in [42, 43, 44]:\n","      run_netlsd_pipeline(\n","          dataset_name=dataset_name,\n","          seed=seed,\n","          w_acc=0.5, w_f1=0.3, w_auc=0.2,\n","          test_size=0.2,\n","          use_optuna=True,\n","          n_trials=10,\n","      )"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1762185700554}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}